{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7970d6b7",
   "metadata": {
    "id": "7970d6b7"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86pGQEx-Ak10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive # run only if runnning in colab\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d10581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['complaint_id', 'date_received', 'company', 'issue', 'sub_product',\n",
      "       'clean_text', 'word_len', 'company_response', 'timely', 'state',\n",
      "       'month'],\n",
      "      dtype='object')\n",
      "risk_flag\n",
      "0    0.951168\n",
      "1    0.048832\n",
      "Name: proportion, dtype: float64\n",
      "risk_flag\n",
      "0    11239\n",
      "1      577\n",
      "Name: count, dtype: int64\n",
      "Train: 7089 Val: 2363 Test: 2364\n",
      "Train risk ratio: 0.048808012413598535\n",
      "Val risk ratio: 0.048666948793906054\n",
      "Test risk ratio: 0.049069373942470386\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load cleaned CFPB data (local)\n",
    "# df = pd.read_csv(\"../data/interim/cfpb_mortgage_2024_clean.csv\")\n",
    "\n",
    "# Loan cleaned CFPB data (Colab)\n",
    "colab_dir = \"/content/drive/MyDrive/NLP/respect-cfpb\"\n",
    "df = pd.read_csv(os.path.join(colab_dir, \"data/interim/cfpb_mortgage_2024_clean.csv\"))\n",
    "\n",
    "# Verify expected columns\n",
    "print(df.columns)\n",
    "\n",
    "# Create binary risk flag\n",
    "RISKY = {\"Closed with monetary relief\", \"Closed with non-monetary relief\"}\n",
    "df[\"risk_flag\"] = df[\"company_response\"].isin(RISKY).astype(int)\n",
    "\n",
    "# Drop rows with missing or empty narratives\n",
    "df = df[df[\"clean_text\"].notna() & (df[\"clean_text\"].str.strip() != \"\")]\n",
    "\n",
    "# Check class balance\n",
    "print(df[\"risk_flag\"].value_counts(normalize=True))\n",
    "print(df[\"risk_flag\"].value_counts())\n",
    "\n",
    "# First split: train (60%) vs temp (40%)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.4,\n",
    "    stratify=df[\"risk_flag\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: validation (20%) and test (20%) from temp\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df[\"risk_flag\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Confirm split sizes and balance\n",
    "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
    "print(\"Train risk ratio:\", train_df[\"risk_flag\"].mean())\n",
    "print(\"Val risk ratio:\", val_df[\"risk_flag\"].mean())\n",
    "print(\"Test risk ratio:\", test_df[\"risk_flag\"].mean())\n",
    "\n",
    "# Save splits to data/splits folder (local)\n",
    "# os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "# train_df.to_csv(\"../data/processed/train.csv\", index=False)\n",
    "# val_df.to_csv(\"../data/processed/val.csv\", index=False)\n",
    "# test_df.to_csv(\"../data/processed/test.csv\", index=False)\n",
    "\n",
    "# Save splits to data/splits folder (colab)\n",
    "processed_dir = os.path.join(colab_dir, \"data/processed\")\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "train_df.to_csv(os.path.join(processed_dir, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(processed_dir, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(processed_dir, \"test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee99339",
   "metadata": {
    "id": "9ee99339"
   },
   "source": [
    "# Baseline Model: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dbdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.828     0.901      6743\n",
      "           1      0.190     0.786     0.306       346\n",
      "\n",
      "    accuracy                          0.826      7089\n",
      "   macro avg      0.588     0.807     0.603      7089\n",
      "weighted avg      0.948     0.826     0.872      7089\n",
      "\n",
      "ROC-AUC: 0.8902199154936097\n",
      "\n",
      "Validation Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.811     0.886      2248\n",
      "           1      0.147     0.635     0.238       115\n",
      "\n",
      "    accuracy                          0.802      2363\n",
      "   macro avg      0.562     0.723     0.562      2363\n",
      "weighted avg      0.937     0.802     0.855      2363\n",
      "\n",
      "ROC-AUC: 0.8033614420547733\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, confusion_matrix,\n",
    "    precision_recall_curve, auc\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load pre-split data (local)\n",
    "# train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "# val_df = pd.read_csv(\"../data/processed/val.csv\")\n",
    "# test_df = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "# Load pre-split data (Colab)\n",
    "train_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/test.csv\"))\n",
    "\n",
    "# Extract features and labels\n",
    "X_train, y_train = train_df[\"clean_text\"], train_df[\"risk_flag\"]\n",
    "X_val, y_val = val_df[\"clean_text\"], val_df[\"risk_flag\"]\n",
    "X_test, y_test = test_df[\"clean_text\"], test_df[\"risk_flag\"]\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,   # vocabulary cap for efficiency\n",
    "    ngram_range=(1,1),     # unigrams and bigrams\n",
    "    stop_words='english',\n",
    "    min_df=5               # ignore rare tokens\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Logistic Regression model with class weighting\n",
    "model = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    solver=\"liblinear\",\n",
    "    C=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate generalization between training and validation\n",
    "y_train_pred = model.predict(X_train_tfidf)\n",
    "y_train_prob = model.predict_proba(X_train_tfidf)[:, 1]\n",
    "\n",
    "y_val_pred = model.predict(X_val_tfidf)\n",
    "y_val_prob = model.predict_proba(X_val_tfidf)[:, 1]\n",
    "\n",
    "print(\"Training Results\")\n",
    "print(classification_report(y_train, y_train_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_train, y_train_prob))\n",
    "\n",
    "print(\"\\nValidation Results\")\n",
    "print(classification_report(y_val, y_val_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, y_val_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fe3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.973     0.799     0.878      2248\n",
      "           1      0.129     0.578     0.211       116\n",
      "\n",
      "    accuracy                          0.788      2364\n",
      "   macro avg      0.551     0.688     0.544      2364\n",
      "weighted avg      0.932     0.788     0.845      2364\n",
      "\n",
      "ROC-AUC: 0.7852228801079887\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGGCAYAAACNCg6xAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW/BJREFUeJzt3Xd4FFXbBvB7+6YX0kMgQIDQ0QAREAIaCEUUGwgoAQVR4BWJDQRFUYlYEFSK8tL0Q4Og8CJgEAIoTalBei8hpALpydbz/RGzsKSwWbLZlPt3XXuZnT0z8+xkzd6cOXNGIoQQICIiIqK7ktq7ACIiIqLagsGJiIiIyEIMTkREREQWYnAiIiIishCDExEREZGFGJyIiIiILMTgRERERGQhBiciIiIiCzE4EREREVmIwYmoFhs1ahSCg4Mrtc6OHTsgkUiwY8cOm9RU2/Xq1Qu9evUyPb906RIkEgmWL19ut5pqgqSkJKjVauzevdvepZh54IEH8Oabb9q7DKpHGJyIKmH58uWQSCSmh1qtRosWLTBx4kSkpaXZu7warySElDykUik8PT3Rv39/7N27197lVYm0tDS8/vrrCA0NhaOjI5ycnBAWFoYPP/wQWVlZ9i7PajNnzkR4eDi6d+9uCt+WPKrCiRMn8N577+HSpUulXnvrrbcwf/58pKamVsm+iO5Gbu8CiGqjmTNnokmTJigqKsKuXbuwcOFCbNq0CceOHYOjo2O11bF48WIYjcZKrdOzZ08UFhZCqVTaqKq7GzZsGAYMGACDwYAzZ85gwYIF6N27N/bv34927drZra57tX//fgwYMAB5eXl49tlnERYWBgA4cOAAPv74Y/z555/4/fff7Vxl5WVkZGDFihVYsWIFAKBVq1b4/vvvzdpMnToVzs7OmDZtWpXv/8SJE3j//ffRq1evUj2sjz32GFxdXbFgwQLMnDmzyvdNdCcGJyIr9O/fH506dQIAjBkzBg0aNMCcOXPwv//9D8OGDStznfz8fDg5OVVpHQqFotLrSKVSqNXqKq2jsu6//348++yzpuc9evRA//79sXDhQixYsMCOlVkvKysLjz/+OGQyGQ4fPozQ0FCz1z/66CMsXry4SvZli89SRf7v//4PcrkcgwYNAgD4+vqa/f4A4OOPP4aXl1ep5bYmlUrx1FNP4bvvvsP7779fZb1cROXhqTqiKvDQQw8BAC5evAigeOyRs7Mzzp8/jwEDBsDFxQUjRowAABiNRsydOxdt2rSBWq2Gr68vxo0bh5s3b5ba7m+//YaIiAi4uLjA1dUVnTt3xg8//GB6vawxTnFxcQgLCzOt065dO8ybN8/0enljnFavXo2wsDA4ODiYvgCTk5PN2pS8r+TkZAwePBjOzs7w9vbG66+/DoPBYPXx69GjBwDg/PnzZsuzsrLw6quvIigoCCqVCiEhIZg9e3apXjaj0Yh58+ahXbt2UKvV8Pb2Rr9+/XDgwAFTm2XLluGhhx6Cj48PVCoVWrdujYULF1pd852++eYbJCcnY86cOaVCE1AcNqZPn256LpFI8N5775VqFxwcjFGjRpmel5we/uOPPzB+/Hj4+PigYcOGWLNmjWl5WbVIJBIcO3bMtOzUqVN46qmn4OnpCbVajU6dOmH9+vUWvbd169YhPDwczs7OFrUvYenvr6LP7PLly/H0008DAHr37m06BXj757dPnz64fPkyEhMTK1UfkTXY40RUBUq+8Bs0aGBaptfrERUVhQcffBCfffaZ6RTeuHHjsHz5cowePRqvvPIKLl68iK+//hqHDx/G7t27Tb1Iy5cvx/PPP482bdpg6tSpcHd3x+HDhxEfH4/hw4eXWceWLVswbNgwPPzww5g9ezYA4OTJk9i9ezcmTZpUbv0l9XTu3BmxsbFIS0vDvHnzsHv3bhw+fBju7u6mtgaDAVFRUQgPD8dnn32GrVu34vPPP0ezZs3w8ssvW3X8SsaueHh4mJYVFBQgIiICycnJGDduHBo1aoQ9e/Zg6tSpSElJwdy5c01tX3jhBSxfvhz9+/fHmDFjoNfrsXPnTvz111+mnsGFCxeiTZs2ePTRRyGXy/Hrr79i/PjxMBqNmDBhglV13279+vVwcHDAU089dc/bKsv48ePh7e2Nd999F/n5+Rg4cCCcnZ3x008/ISIiwqztqlWr0KZNG7Rt2xYAcPz4cXTv3h2BgYGYMmUKnJyc8NNPP2Hw4MH4+eef8fjjj5e7X51Oh/3791f6d2vp7+9un9mePXvilVdewZdffom3334brVq1AgDTfwGYTonu3r0b9913X6XqJKo0QUQWW7ZsmQAgtm7dKjIyMkRSUpKIi4sTDRo0EA4ODuLq1atCCCGio6MFADFlyhSz9Xfu3CkAiJUrV5otj4+PN1uelZUlXFxcRHh4uCgsLDRrazQaTT9HR0eLxo0bm55PmjRJuLq6Cr1eX+572L59uwAgtm/fLoQQQqvVCh8fH9G2bVuzfW3YsEEAEO+++67Z/gCImTNnmm3zvvvuE2FhYeXus8TFixcFAPH++++LjIwMkZqaKnbu3Ck6d+4sAIjVq1eb2n7wwQfCyclJnDlzxmwbU6ZMETKZTFy5ckUIIcS2bdsEAPHKK6+U2t/tx6qgoKDU61FRUaJp06ZmyyIiIkRERESpmpctW1bhe/Pw8BAdOnSosM3tAIgZM2aUWt64cWMRHR1tel7ymXvwwQdL/V6HDRsmfHx8zJanpKQIqVRq9jt6+OGHRbt27URRUZFpmdFoFN26dRPNmzevsM5z584JAOKrr76qsF2bNm3Mjpulvz9LPrOrV682+8yWRalUipdffrnCGomqAk/VEVkhMjIS3t7eCAoKwjPPPANnZ2esXbsWgYGBZu3u/Ff66tWr4ebmhj59+iAzM9P0CAsLg7OzM7Zv3w6g+F/hubm5mDJlSqnxSBWN4XB3d0d+fj62bNli8Xs5cOAA0tPTMX78eLN9DRw4EKGhodi4cWOpdV566SWz5z169MCFCxcs3ueMGTPg7e0NPz8/9OjRAydPnsTnn39u1luzevVq9OjRAx4eHmbHKjIyEgaDAX/++ScA4Oeff4ZEIsGMGTNK7ef2Y+Xg4GD6OTs7G5mZmYiIiMCFCxeQnZ1tce3lycnJgYuLyz1vpzxjx46FTCYzWzZ06FCkp6ebnbZas2YNjEYjhg4dCgC4ceMGtm3bhiFDhiA3N9d0HK9fv46oqCicPXu21CnZ212/fh2AeW+gJSz9/VnzmS1LyX6IbI2n6oisMH/+fLRo0QJyuRy+vr5o2bIlpFLzf4fI5XI0bNjQbNnZs2eRnZ0NHx+fMrebnp4O4Napv5JTLZYaP348fvrpJ/Tv3x+BgYHo27cvhgwZgn79+pW7zuXLlwEALVu2LPVaaGgodu3aZbasZAzR7Tw8PMzGaGVkZJiNeXJ2djYbH/Piiy/i6aefRlFREbZt24Yvv/yy1Bips2fP4p9//im1rxK3H6uAgAB4enqW+x6B4tM4M2bMwN69e1FQUGD2WnZ2Ntzc3Cpc/25cXV2Rm5t7T9uoSJMmTUot69evH9zc3LBq1So8/PDDAIpP03Xs2BEtWrQAAJw7dw5CCLzzzjt45513ytx2enp6qdB/JyFEpeq19PdnzWe2vPo4MJyqA4MTkRW6dOliGjtTHpVKVSpMGY1G+Pj4YOXKlWWuU96XjKV8fHyQmJiIzZs347fffsNvv/2GZcuWYeTIkaZLye/Vnb0eZencubMpkAHFPUy3D4Ru3rw5IiMjAQCPPPIIZDIZpkyZgt69e5uOq9FoRJ8+fcqd3LAkGFji/PnzePjhhxEaGoo5c+YgKCgISqUSmzZtwhdffFHpKR3KEhoaisTERGi12nua6qG8Qfa395iVUKlUGDx4MNauXYsFCxYgLS0Nu3fvxqxZs0xtSt7b66+/jqioqDK3HRISUm49JeP2yrp4oSKW/v6q6jOblZUFLy+vStVIZA0GJ6Jq1KxZM2zduhXdu3cv84vw9nYAcOzYsQq/1MqiVCoxaNAgDBo0CEajEePHj8c333yDd955p8xtNW7cGABw+vRp09WBJU6fPm16vTJWrlyJwsJC0/OmTZtW2H7atGlYvHgxpk+fjvj4eADFxyAvL88UsMrTrFkzbN68GTdu3Ci31+nXX3+FRqPB+vXr0ahRI9PyklOjVWHQoEHYu3cvfv7553KnpLidh4dHqQkxtVotUlJSKrXfoUOHYsWKFUhISMDJkychhDCdpgNuHXuFQnHXY1mWRo0awcHBwXTFqKUs/f0Bd//M3q0nKTk5GVqt1mzAOJGtcIwTUTUaMmQIDAYDPvjgg1Kv6fV60xdp37594eLigtjYWBQVFZm1q+iUScl4lBJSqRTt27cHAGg0mjLX6dSpE3x8fLBo0SKzNr/99htOnjyJgQMHWvTebte9e3dERkaaHncLTu7u7hg3bhw2b95suqR8yJAh2Lt3LzZv3lyqfVZWFvR6PQDgySefhBAC77//fql2JceqpJfs9mOXnZ2NZcuWVfq9leell16Cv78/XnvtNZw5c6bU6+np6fjwww9Nz5s1a2Ya51Pi22+/rfS0DpGRkfD09MSqVauwatUqdOnSxey0no+PD3r16oVvvvmmzFCWkZFR4fYVCgU6depkNrWDJSz9/VnymS2Zs6q8mdcPHjwIAOjWrVulaiSyBnuciKpRREQExo0bh9jYWCQmJqJv375QKBQ4e/YsVq9ejXnz5uGpp56Cq6srvvjiC4wZMwadO3fG8OHD4eHhgSNHjqCgoKDcUxhjxozBjRs38NBDD6Fhw4a4fPkyvvrqK3Ts2LHcf40rFArMnj0bo0ePRkREBIYNG2aajiA4OBiTJ0+25SExmTRpEubOnYuPP/4YcXFxeOONN7B+/Xo88sgjGDVqFMLCwpCfn4+jR49izZo1uHTpEry8vNC7d28899xz+PLLL3H27Fn069cPRqMRO3fuRO/evTFx4kT07dvX1Ksxbtw45OXlYfHixfDx8al0D095PDw8sHbtWgwYMAAdO3Y0mzn80KFD+PHHH9G1a1dT+zFjxuCll17Ck08+iT59+uDIkSPYvHlzpU83KRQKPPHEE4iLi0N+fj4+++yzUm3mz5+PBx98EO3atcPYsWPRtGlTpKWlYe/evbh69SqOHDlS4T4ee+wxTJs2DTk5OXB1dbWoLkt/f5Z8Zjt27AiZTIbZs2cjOzsbKpXKNCcXUHwxRaNGjTgVAVUP+13QR1T7lFwavn///grbRUdHCycnp3Jf//bbb0VYWJhwcHAQLi4uol27duLNN98U165dM2u3fv160a1bN+Hg4CBcXV1Fly5dxI8//mi2n9unI1izZo3o27ev8PHxEUqlUjRq1EiMGzdOpKSkmNrcOR1BiVWrVon77rtPqFQq4enpKUaMGGGaXuFu72vGjBnCkj8nJZf2f/rpp2W+PmrUKCGTycS5c+eEEELk5uaKqVOnipCQEKFUKoWXl5fo1q2b+Oyzz4RWqzWtp9frxaeffipCQ0OFUqkU3t7eon///uLgwYNmx7J9+/ZCrVaL4OBgMXv2bLF06VIBQFy8eNHUztrpCEpcu3ZNTJ48WbRo0UKo1Wrh6OgowsLCxEcffSSys7NN7QwGg3jrrbeEl5eXcHR0FFFRUeLcuXPlTkdQ0Wduy5YtAoCQSCQiKSmpzDbnz58XI0eOFH5+fkKhUIjAwEDxyCOPiDVr1tz1PaWlpQm5XC6+//77ctvcOR2BEJb9/iz5zAohxOLFi0XTpk2FTCYz+/waDAbh7+8vpk+fftf3QVQVJEJU8lIJIiKqd1544QWcOXMGO3futHcpZtatW4fhw4fj/Pnz8Pf3t3c5VA8wOBER0V1duXIFLVq0QEJCArp3727vcky6du2KHj164JNPPrF3KVRPMDgRERERWYhX1RERERFZiMGJiIiIyEIMTkREREQWYnAiIiIislC9mwDTaDTi2rVrcHFx4Q0hiYiICEII5ObmIiAgoNQ9Ru9U74LTtWvXEBQUZO8yiIiIqIZJSkpCw4YNK2xT74KTi4sLgOKDY+mtA4iIiKjuysnJQVBQkCkjVKTeBaeS03Ourq4MTkRERGRiyRAeDg4nIiIishCDExEREZGFGJyIiIiILFTvxjgREZH9GAwG6HQ6e5dB9YxCoYBMJquSbTE4ERGRzQkhkJqaiqysLHuXQvWUu7s7/Pz87nkORwYnIiKyuZLQ5OPjA0dHR05ATNVGCIGCggKkp6cDAPz9/e9pewxORERkUwaDwRSaGjRoYO9yqB5ycHAAAKSnp8PHx+eeTtvZdXD4n3/+iUGDBiEgIAASiQTr1q276zo7duzA/fffD5VKhZCQECxfvtzmdRIRkfVKxjQ5OjrauRKqz0o+f/c6xs6uwSk/Px8dOnTA/PnzLWp/8eJFDBw4EL1790ZiYiJeffVVjBkzBps3b7ZxpUREdK94eo7sqao+f3Y9Vde/f3/079/f4vaLFi1CkyZN8PnnnwMAWrVqhV27duGLL75AVFSUrcokIiIiAlDL5nHau3cvIiMjzZZFRUVh79695a6j0WiQk5Nj9rCVs2m5eHD2Njw2f7fN9kFERET2U6uCU2pqKnx9fc2W+fr6IicnB4WFhWWuExsbCzc3N9MjKCjIZvVpDUZcvVmIlKyyayEiotpl1KhRkEgkkEgkUCqVCAkJwcyZM6HX6wEUj7steV0ikcDb2xsDBgzA0aNHLd5HaGgoVCoVUlNTS70WHByMuXPnllr+3nvvoWPHjmbLUlNT8Z///AdNmzaFSqVCUFAQBg0ahISEhEq958pavXo1QkNDoVar0a5dO2zatKnC9ikpKRg+fDhatGgBqVSKV199tVSbXr16mR3XksfAgQPN2p08eRKPPvoo3Nzc4OTkhM6dO+PKlStV+fZKqVXByRpTp05Fdna26ZGUlGTvkoiIqBbp168fUlJScPbsWbz22mt477338Omnn5q1OX36NFJSUrB582ZoNBoMHDgQWq32rtvetWsXCgsL8dRTT2HFihVW13jp0iWEhYVh27Zt+PTTT3H06FHEx8ejd+/emDBhgtXbvZs9e/Zg2LBheOGFF3D48GEMHjwYgwcPxrFjx8pdR6PRwNvbG9OnT0eHDh3KbPPLL78gJSXF9Dh27BhkMhmefvppU5vz58/jwQcfRGhoKHbs2IF//vkH77zzDtRqdZW/z9vVqukI/Pz8kJaWZrYsLS0Nrq6upksN76RSqaBSqaqjPCIiqoNUKhX8/PwAAC+//DLWrl2L9evXY+rUqaY2Pj4+pgkWX331VTz66KM4deoU2rdvX+G2lyxZguHDhyMiIgKTJk3CW2+9ZVWN48ePh0Qiwb59++Dk5GRa3qZNGzz//PNWbdMS8+bNQ79+/fDGG28AAD744ANs2bIFX3/9NRYtWlTmOsHBwZg3bx4AYOnSpWW28fT0NHseFxcHR0dHs+A0bdo0DBgwAJ988olpWbNmze7p/ViiVvU4de3atVSX45YtW9C1a1c7VURERNYQQqBAq7fLQwhxT7U7ODiU25uUnZ2NuLg4AIBSqaxwO7m5uVi9ejWeffZZ9OnTB9nZ2di5c2el67lx4wbi4+MxYcIEs9BUwt3dvdx1V65cCWdn5wofFdVkzdhjayxZsgTPPPOM6f0ZjUZs3LgRLVq0QFRUFHx8fBAeHm7RtEb3yq49Tnl5eTh37pzp+cWLF5GYmAhPT080atQIU6dORXJyMr777jsAwEsvvYSvv/4ab775Jp5//nls27YNP/30EzZu3Givt0BERFYo1BnQ+l37TCVzYmYUHJWV//oTQiAhIQGbN2/Gf/7zH7PXGjZsCKB4mh0AePTRRxEaGlrh9uLi4tC8eXO0adMGAPDMM89gyZIl6NGjR6XqOnfuHIQQd91fWR599FGEh4dX2CYwMLDc18obe1zWeC1r7du3D8eOHcOSJUtMy9LT05GXl4ePP/4YH374IWbPno34+Hg88cQT2L59OyIiIqps/3eya3A6cOAAevfubXoeExMDAIiOjsby5cuRkpJiNsirSZMm2LhxIyZPnox58+ahYcOG+O9//8upCIiIyGY2bNgAZ2dn6HQ6GI1GDB8+HO+9955Zm507d8LR0RF//fUXZs2aVe5pqtstXboUzz77rOn5s88+i4iICHz11VdwcXGxuL576UFzcXGp1L7sYcmSJWjXrh26dOliWmY0GgEAjz32GCZPngwA6NixI/bs2YNFixbV3eDUq1evCn/hZc0K3qtXLxw+fNiGVRERka05KGQ4MdM+/+h1UFTudhu9e/fGwoULoVQqERAQALm89FdnkyZN4O7ujpYtWyI9PR1Dhw7Fn3/+We42T5w4gb/++gv79u0zG9dkMBgQFxeHsWPHAgBcXV2RnZ1dav2srCy4ubkBAJo3bw6JRIJTp05V6n0Bxafqxo0bV2Gb3377rdxesPLGHpeMCbtX+fn5iIuLw8yZM82We3l5QS6Xo3Xr1mbLS+Z3tKVaNTiciIjqBolEYtXpMntwcnJCSEiIxe0nTJiA2NhYrF27Fo8//niZbZYsWYKePXuWunPGsmXLsGTJElNwatmyJQ4ePFhq/UOHDqFly5YAigdSR0VFYf78+XjllVdKjXPKysoqd5zTvZ6qKxl7fPuUAlU59nj16tXQaDRmPXNA8fixzp074/Tp02bLz5w5g8aNG1fJvstTOz61REREtYSjoyPGjh2LGTNmYPDgwaVu9aHT6fD9999j5syZaNu2rdlrY8aMwZw5c3D8+HG0adMGkydPRo8ePfDRRx/hiSeegMFgwI8//oi9e/diwYIFpvXmz5+P7t27o0uXLpg5cybat28PvV6PLVu2YOHChTh58mSZtd7rqbpJkyYhIiICn3/+OQYOHIi4uDgcOHAA3377ranNneOVASAxMRFA8VjnjIwMJCYmQqlUlupBWrJkCQYPHlzmzaHfeOMNDB06FD179kTv3r0RHx+PX3/9FTt27LD6/VhE1DPZ2dkCgMjOzq7ybR9LzhKN39ogOn+4pcq3TURUWxUWFooTJ06IwsJCe5dSadHR0eKxxx4r9/Xt27cLAOLmzZtmy69cuSLkcrlYtWpVqXXWrFkjpFKpSE1NLXObrVq1EpMnTzY937x5s+jevbvw8PAQDRo0EL169RJ//PFHqfWuXbsmJkyYIBo3biyUSqUIDAwUjz76qNi+fbtF79VaP/30k2jRooVQKpWiTZs2YuPGjWavR0dHi4iICLNlAEo9GjdubNbm1KlTAoD4/fffy933kiVLREhIiFCr1aJDhw5i3bp15bat6HNYmWwg+fcN1Bs5OTlwc3NDdnY2XF1dq3Tbx69lY+CXu+DjosK+aZF3X4GIqB4oKirCxYsX0aRJE5tPTkhUnoo+h5XJBrVqHiciIiIie2JwIiIiIrIQgxMRERGRhRiciIiIiCzE4ERERERkIQYnIiKqFiW3ySCyh6r6/HECTCIisimlUgmpVIpr167B29sbSqWy1KSQRLYihIBWq0VGRgakUimUSuU9bY/BiYiIbEoqlaJJkyZISUnBtWvX7F0O1VOOjo5o1KgRpNJ7O9nG4ERERDanVCrRqFEj6PV6GAwGe5dD9YxMJoNcLq+Snk4GJyIiqhYSiQQKhQIKhcLepRBZjYPDiYiIiCzE4ERERERkIQYnIiIiIgsxOBERERFZiMGJiIiIyEIMTkREREQWYnAiIiIishCDExEREZGFGJyIiIiILMTgRERERGQhBiciIiIiCzE4EREREVmIwYmIiIjIQgxORERERBZicCIiIiKyEIMTERERkYUYnIiIiIgsxOBEREREZCEGJyIiIiILMTgRERERWYjBiYiIiMhCDE5EREREFmJwIiIiIrIQgxMRERGRhRiciIiIiCzE4ERERERkIQYnIiIiIgsxOBERERFZiMGJiIiIyEIMTkREREQWsntwmj9/PoKDg6FWqxEeHo59+/ZV2H7u3Llo2bIlHBwcEBQUhMmTJ6OoqKiaqiUiIqL6zK7BadWqVYiJicGMGTNw6NAhdOjQAVFRUUhPTy+z/Q8//IApU6ZgxowZOHnyJJYsWYJVq1bh7bffrubKiYiIqD6ya3CaM2cOxo4di9GjR6N169ZYtGgRHB0dsXTp0jLb79mzB927d8fw4cMRHByMvn37YtiwYXftpSIiIiKqCnYLTlqtFgcPHkRkZOStYqRSREZGYu/evWWu061bNxw8eNAUlC5cuIBNmzZhwIAB1VIzERER1W9ye+04MzMTBoMBvr6+Zst9fX1x6tSpMtcZPnw4MjMz8eCDD0IIAb1ej5deeqnCU3UajQYajcb0PCcnp2reABEREdU7dh8cXhk7duzArFmzsGDBAhw6dAi//PILNm7ciA8++KDcdWJjY+Hm5mZ6BAUFVWPFREREVJfYrcfJy8sLMpkMaWlpZsvT0tLg5+dX5jrvvPMOnnvuOYwZMwYA0K5dO+Tn5+PFF1/EtGnTIJWWzoFTp05FTEyM6XlOTg7DExEREVnFbj1OSqUSYWFhSEhIMC0zGo1ISEhA165dy1ynoKCgVDiSyWQAACFEmeuoVCq4urqaPYiIiIisYbceJwCIiYlBdHQ0OnXqhC5dumDu3LnIz8/H6NGjAQAjR45EYGAgYmNjAQCDBg3CnDlzcN999yE8PBznzp3DO++8g0GDBpkCFBEREZGt2DU4DR06FBkZGXj33XeRmpqKjh07Ij4+3jRg/MqVK2Y9TNOnT4dEIsH06dORnJwMb29vDBo0CB999JG93gIRERHVIxJR3jmuOionJwdubm7Izs6u8tN2x69lY+CXu+DjosK+aZF3X4GIiIjsrjLZoFZdVUdERERkTwxORERERBZicCIiIiKyEIMTERERkYUYnIiIiIgsxOBEREREZCEGJyIiIiILMTgRERERWYjBiYiIiMhCDE5EREREFmJwIiIiIrIQgxMRERGRhRiciIiIiCzE4ERERERkIQYnIiIiIgsxOBERERFZiMGJiIiIyEIMTkREREQWYnAiIiIishCDExEREZGFGJyIiIiILMTgRERERGQhBiciIiIiCzE4EREREVmIwYmIiIjIQgxORERERBZicCIiIiKyEIMTERERkYUYnIiIiIgsxOBEREREZCEGJyIiIiILMTgRERERWYjBiYiIiMhCDE5EREREFmJwIiIiIrIQgxMRERGRhRiciIiIiCzE4ERERERkIQYnIiIiIgsxOBERERFZiMGJiIiIyEIMTkREREQWYnAiIiIishCDExEREZGF7B6c5s+fj+DgYKjVaoSHh2Pfvn0Vts/KysKECRPg7+8PlUqFFi1aYNOmTdVULREREdVncnvufNWqVYiJicGiRYsQHh6OuXPnIioqCqdPn4aPj0+p9lqtFn369IGPjw/WrFmDwMBAXL58Ge7u7tVfPBEREdU7dg1Oc+bMwdixYzF69GgAwKJFi7Bx40YsXboUU6ZMKdV+6dKluHHjBvbs2QOFQgEACA4Ors6SiYiIqB6z26k6rVaLgwcPIjIy8lYxUikiIyOxd+/eMtdZv349unbtigkTJsDX1xdt27bFrFmzYDAYqqtsIiIiqsfs1uOUmZkJg8EAX19fs+W+vr44depUmetcuHAB27Ztw4gRI7Bp0yacO3cO48ePh06nw4wZM8pcR6PRQKPRmJ7n5ORU3ZsgIiKiesWq4GQwGLB8+XIkJCQgPT0dRqPR7PVt27ZVSXF3MhqN8PHxwbfffguZTIawsDAkJyfj008/LTc4xcbG4v3337dJPURERFS/WBWcJk2ahOXLl2PgwIFo27YtJBJJpbfh5eUFmUyGtLQ0s+VpaWnw8/Mrcx1/f38oFArIZDLTslatWiE1NRVarRZKpbLUOlOnTkVMTIzpeU5ODoKCgipdLxEREZFVwSkuLg4//fQTBgwYYPWOlUolwsLCkJCQgMGDBwMo7lFKSEjAxIkTy1yne/fu+OGHH2A0GiGVFg/POnPmDPz9/csMTQCgUqmgUqmsrpOIiIiohFWDw5VKJUJCQu555zExMVi8eDFWrFiBkydP4uWXX0Z+fr7pKruRI0di6tSppvYvv/wybty4gUmTJuHMmTPYuHEjZs2ahQkTJtxzLURERER3Y1WP02uvvYZ58+bh66+/tuo0XYmhQ4ciIyMD7777LlJTU9GxY0fEx8ebBoxfuXLF1LMEAEFBQdi8eTMmT56M9u3bIzAwEJMmTcJbb71ldQ1ERERElpIIIURlV3r88cexfft2eHp6ok2bNqY5lUr88ssvVVZgVcvJyYGbmxuys7Ph6upapds+fi0bA7/cBR8XFfZNi7z7CkRERGR3lckGVvU4ubu74/HHH7eqOCIiIqLayqrgtGzZsqqug4iIiKjGu6cJMDMyMnD69GkAQMuWLeHt7V0lRRERERHVRFZdVZefn4/nn38e/v7+6NmzJ3r27ImAgAC88MILKCgoqOoaiYiIiGoEq4JTTEwM/vjjD/z666/IyspCVlYW/ve//+GPP/7Aa6+9VtU1EhEREdUIVp2q+/nnn7FmzRr06tXLtGzAgAFwcHDAkCFDsHDhwqqqj4iIiKjGsKrHqaCgoNTNeQHAx8eHp+qIiIiozrIqOHXt2hUzZsxAUVGRaVlhYSHef/99dO3atcqKIyIiIqpJrDpVN2/ePERFRaFhw4bo0KEDAODIkSNQq9XYvHlzlRZIREREVFNYFZzatm2Ls2fPYuXKlTh16hQAYNiwYRgxYgQcHByqtEAiIiKimsLqeZwcHR0xduzYqqyFiIiIqEazODitX78e/fv3h0KhwPr16yts++ijj95zYUREREQ1jcXBafDgwUhNTYWPjw8GDx5cbjuJRAKDwVAVtRERERHVKBYHJ6PRWObPRERERPWFVdMRlCUrK6uqNkVERERUI1kVnGbPno1Vq1aZnj/99NPw9PREYGAgjhw5UmXFEREREdUkVgWnRYsWISgoCACwZcsWbN26FfHx8ejfvz/eeOONKi2QiIiIqKawajqC1NRUU3DasGEDhgwZgr59+yI4OBjh4eFVWiARERFRTWFVj5OHhweSkpIAAPHx8YiMjAQACCF4RR0RERHVWVb1OD3xxBMYPnw4mjdvjuvXr6N///4AgMOHDyMkJKRKCyQiIiKqKawKTl988QWCg4ORlJSETz75BM7OzgCAlJQUjB8/vkoLJCIiIqoprApOCoUCr7/+eqnlkydPvueCiIiIiGoq3nKFiIiIyEK85QoRERGRhXjLFSIiIiILVdktV4iIiIjqOquC0yuvvIIvv/yy1PKvv/4ar7766r3WRERERFQjWRWcfv75Z3Tv3r3U8m7dumHNmjX3XBQRERFRTWRVcLp+/Trc3NxKLXd1dUVmZuY9F0VERERUE1kVnEJCQhAfH19q+W+//YamTZvec1FERERENZFVE2DGxMRg4sSJyMjIwEMPPQQASEhIwOeff465c+dWZX1ERERENYZVwen555+HRqPBRx99hA8++AAAEBwcjIULF2LkyJFVWiARERFRTWFVcAKAl19+GS+//DIyMjLg4OBgul8dERERUV1l9TxOer0eW7duxS+//AIhBADg2rVryMvLq7LiiIiIiGoSq3qcLl++jH79+uHKlSvQaDTo06cPXFxcMHv2bGg0GixatKiq6yQiIiKyO6t6nCZNmoROnTrh5s2bcHBwMC1//PHHkZCQUGXFEREREdUkVvU47dy5E3v27IFSqTRbHhwcjOTk5CopjIiIiKimsarHyWg0wmAwlFp+9epVuLi43HNRRERERDWRVcGpb9++ZvM1SSQS5OXlYcaMGRgwYEBV1UZERERUo1h1qu6zzz5Dv3790Lp1axQVFWH48OE4e/YsvLy88OOPP1Z1jUREREQ1glXBKSgoCEeOHMGqVatw5MgR5OXl4YUXXsCIESPMBosTERER1SWVDk46nQ6hoaHYsGEDRowYgREjRtiiLiIiIqIap9JjnBQKBYqKimxRCxEREVGNZtXg8AkTJmD27NnQ6/VVXQ8RERFRjWXVGKf9+/cjISEBv//+O9q1awcnJyez13/55ZcqKY6IiIioJrGqx8nd3R1PPvkkoqKiEBAQADc3N7NHZc2fPx/BwcFQq9UIDw/Hvn37LFovLi4OEokEgwcPrvQ+iYiIiCqrUj1ORqMRn376Kc6cOQOtVouHHnoI77333j1dSbdq1SrExMRg0aJFCA8Px9y5cxEVFYXTp0/Dx8en3PUuXbqE119/HT169LB630RERESVUakep48++ghvv/02nJ2dERgYiC+//BITJky4pwLmzJmDsWPHYvTo0WjdujUWLVoER0dHLF26tNx1DAYDRowYgffffx9Nmza9p/0TERERWapSwem7777DggULsHnzZqxbtw6//vorVq5cCaPRaNXOtVotDh48iMjIyFsFSaWIjIzE3r17y11v5syZ8PHxwQsvvHDXfWg0GuTk5Jg97EUIgenrjuK99cftVgMRERFZr1LB6cqVK2a3VImMjIREIsG1a9es2nlmZiYMBgN8fX3Nlvv6+iI1NbXMdXbt2oUlS5Zg8eLFFu0jNjbWbPxVUFCQVbVWhcw8Lf7vrytYvucStHrrwiYRERHZT6WCk16vh1qtNlumUCig0+mqtKjy5Obm4rnnnsPixYvh5eVl0TpTp05Fdna26ZGUlGTjKsuXlnNr/isBYbc6iIiIyDqVGhwuhMCoUaOgUqlMy4qKivDSSy+ZTUlg6XQEXl5ekMlkSEtLM1uelpYGPz+/Uu3Pnz+PS5cuYdCgQaZlJacJ5XI5Tp8+jWbNmpmto1KpzOq1p4xcjb1LICIiontQqeAUHR1datmzzz5r9c6VSiXCwsKQkJBgmlLAaDQiISEBEydOLNU+NDQUR48eNVs2ffp05ObmYt68eXY9DWeJ9FzOuE5ERFSbVSo4LVu2rMoLiImJQXR0NDp16oQuXbpg7ty5yM/Px+jRowEAI0eORGBgIGJjY6FWq9G2bVuz9d3d3QGg1PKaKD2HPU5ERES1mVUzh1eloUOHIiMjA++++y5SU1PRsWNHxMfHmwaMX7lyBVKpVfN01jjpPFVHRERUq9k9OAHAxIkTyzw1BwA7duyocN3ly5dXfUE2wlN1REREtVvd6MqpJdJ4qo6IiKhWY3CqRryqjoiIqHZjcKomQggGJyIiolqOwamaZBXooDVwtnAiIqLajMGpmvCKOiIiotqPwama8Io6IiKi2o/BqZpw8ksiIqLaj8GpmvBUHRERUe3H4FRNeKqOiIio9mNwqibscSIiIqr9GJyqSUY9HuP0z9UsnE7NtXcZRERE94zBqZrU11N1S3ddxKNf78Yz3+6FEMLe5RAREd2TGnGT3/qgvp2qE0Lgk82nsXDHeQDAzQIdhAAkEjsXRkREdA/Y41QN8jR6FGgN9i6j2ugNRry55h9TaKqNkm4UQM+Z3omI6A4MTtUgPaf4NF1d6W3JzNOYQoUQAvHHUnEmrXgMU5HOgJf+7yBWH7wKqQR4q1+oPUuttBPXcjBy6T70+GQ73v/1hL3LISKiGobBqRqk/Tsw3MtZZedK7t3/EpPxwKwEvLoqEUIIzNxwAi/930G8GpeIPI0eo5btw9aT6VDJpfjmuU4Y2jnI3iVb5OrNAsSsSsTAr3bizzMZAIBL1/PtXBUREdU0HONUDUoGhvu4qJBRi8c6bT+Vjtd+OgK9UeBceh4+2HASy3ZfAgCk5RRhxH//xpGkLDir5FgS3QnhTRvgRr72nvaZr9FjdvwpnErJxX9HdYKrWnFP2zMYBVbtT8K6xGS81qcFWvq5YP72c1ix57LpJsxNvZ1wIYOhiYiISmNwqgYlYcnHRYXjdq7FWvsv3cBL/3cQemPxlXGn03Jx6rYpBq7na3E9XwsPRwVWPN8F7Ru6W72vG/la3CzQIqdQh1dXJeLy9QIAwNGr2ege4lXp7Z1Jy8WWE2kI8nTEgu3nTHW/vfYoMnI1yCnSAwC6Nm2AqQNCcT4jD5NXHSl3e4eu3MT//XUZPZp74fH7GlrxDomIqLZicKoG6abgpLZzJdY5cS0Hzy/fD43eiAA3Na5lF6FkZoFnOgchbn8SgOJg+H9jwtHC16XcbQkhsP7INQgBDL4vsNTr8cdS8NL/HSpnXcvq1RuMSMkugquDAnO3njH1it3p/L+9SqF+Lnirfyh6tfCGRCLB+Yw8s3aXMvMRtz8JLmo5/rpwHTvPZgIAjiRllRmcinQGbD6eCl9XNR5o2sCyoomIqFZgcKoGJYPDfVxrxxinrAIt3BwUkEgkuHw9HyOX7kNukR6dgz0wvlcIRi/fDwD4cHBbRLXxwy+HkuHjqsLKMeFo3MCp3O0W6Q2YtvYY1h5OhkwqQZ/WvnBSFX8ENXoDZm08iRV7L5utM6hDAP65mmXqdbpTvkaPeQlnsff8dXw17D6k52rwxpoj5bYf1S0YAe5qzNp0CgFuasT0bYnH7wuETFp65P71PC1e++kIfj50tcxtGYzmSS67QIf/+/sylu2+hMw8DVzVcvzzXlS5x4OIiGofBqdqkH7bqbqa7oe/r2D6uqOY+FBzRHdtjOil+5CZp0Erf1f8N7ozHBQyjOzaGJ2DPTGoQwAAYPeUh+CilkOtkFW47We+/Qv/XM0GUBw6dP+OKbp8PR8TfziMo8nZprbOKjk+GNwGgzsGov+8nWbbuXK9AKdScyCXSfDOuuNIzioEADy/Yn+psUnNvJ0wvlcIUrILEdXGD819XSCEQNemXmju61xhzSdScnAiJcds2fDwRugS7IlXVyWaliVnFWLprov4cd8Vs2kn8uvRFBRERPUFg1M1KAlO3jX8VN1fF67j3f8dg1EAiUlZ+PNMBi5dL0CguwNWjO4MN4figdkzH2trtp63hYHwn6vZcHNQILtQZ1q26WgK3lrzD3I1eng4KvD5kA7o3dIHRoFSvUB6oxHf/HEesb+dKnP7FzLyIZEUB1SjAMb1bIrobsFQyMwvHpVIJGjX0K3cOh2Vt/636NXSG69GtoAQAv5uDvBzU+PApRsAiufnmrwqEb8euWYa+xXq54Knwhriw40nLTomRERUuzA4VYPacKou6UYBXr5t8HfJJfluDsWDvX1crQt9t2eflr4uWPRcGHp/tgMAMPPXE/jlcDIAoFNjD3w57D4EuDsAAGRlzHn1+up/kJlnflXimAeb4Hq+FmsPJ6NNgCs+HNwW9zXysKrWEr1b+iD2iXYI9XOpcFuZecX7BYBuzRrgxZ5NEdHCGxm5GgYnIqI6isHJxop0BtNVWzX1VF2+Ro+x3x3AzQIdZFKJaeyOUi7Ff6M7IcTH2eptuzsqMSK8EQSAtwe0gsNtp8ZKQtPLvZohpk+LUj1Dd8rM08BFLUf3Zl6QSSV4KaIZ2jV0Q4FWj6Gdg9A52LPMsUqVpZRLMaxLo3Jfb/DvfFxSCTCgnT/G9WxWYQ8WERHVHQxONlYyFYFSLoWrw73NQWQLRqNAzE+JOJWaCy9nFYZ3CcKX285BIgHmDe2IzsGe97yPjx5vZ/r59gHVnk5K06m5ini7qHAqNReRrXzx0eNt4XtH75ejUl6tV6818XLChv88CHdHBRp6OFbbfomIyP4YnGzs9skva+IdV77efg6bj6dBKZPim+fC4Ouqwt8Xb+CpsIbo386/yvcnk0owsmtjpOdoMOPR1vB3c7jrOl8Nuw+XrhegQ0M3SGrIfWvaBrKHiYioPmJwsrH0nJp7Rd0fZzLwxdYzAIqnFghrXDyeZ9W4rjbd752Dy+/G3VGJjo5KG1VDRERkOd6rzsZq6uSXV28WYFLcYQgBDOsShCG15J5yRERE9sTgZGOmU3U16Iq6Ip0B41ceQlaBDu0C3TBjUBt7l0RERFQrMDjZWE08VTdzwwn8czUb7o4KLHz2/rtOXElERETFGJxsLK3kVJ2V8yBVtZ8PXsUPf18pvmrumft4VRgREVElMDjZmGnyyxrQ43QuPQ/T1x0DAEx6uDkiWnjbuSICim98fPRqNg5duVlum6wCbambDxMRUfXjVXU2llFDBocX6QyY+MMhFOoM6NasAf7zUHO71lNfZBfo8Mvhq/j50FX4uKixJLoTgOLbz1zP1+BsWh7WHLyKs+nFoWj3lIdwKTMfaw8nIyNXg4Ht/PH7iVT8cSYDOoPA+ond4aiUYf2RFCTdKMD0ga1ME3JaIiW7EFtOpOH342k4ePkmZgxqjWcqmOyTiIjMMTjZkM5gxPV8LQD7DQ7XGYz452oW1hy8ilOpuWjgpMTcoR2rZIZtqpjBKNBl1lZo9MZ/l+Tgy4RzWH8kGefvuBlxif5z/zTNNA8UTxlxu+eX70dmntb0vGcLLzx+X8NyaxBC4Gx6Hn4/norfT6SZbrJc4u+LN/BMl0bIKdLhVEouWge4wlnFPwtEROXhX0gbuv7vF5xMKoGnoxL5Wv1d1qhaQgg8sWAPjibf+rKcM7RjjRlvVVdJbwulGr0RLXydcSatuEepZN6sEu0buuGZzo0wZ8tpZOZpkVOkh6tabgpP3i4qDO0UhN9PpOJMWh4y87RQyCRQyqTI1xqQW6THpqMp2HQ0BefS8xD7RDtcyypC/PFU/HrkWqnaJBIgrJEHlHIp9py/jmPJ2Ri++C/su3gDeqPAyK6NKz3PFhFRfcLgZEPZhToAxTfKldqhh+eXQ8lmoemliGYc11QNvJxVeLFnU+Rr9BjSKQhtA93Q5aOtuJ6vRVhjDzwd1hDdQ7wgkcA0ON8oBPZfuoH+bf3QO9QHGr0R17IK0dLXBRKJBG0DXbH+yDVEtPBGVBs/TF6ViO2nM/Du/46b7fvxBXtK1aOUS/FgiBf6tvbFw6184e2iwn93XsCe89dxNj3PdJoQAK7eLLTtwSEiquUYnGwot6g4OLmoq/8wJ2cV4r315l+qr/VtUe111FdvD2hl9nzTpB7Q6Ixo1KDsqxiffaAxnn2gsem5Si6Dq9+texv2a+uPfm1v3QLHUXnrM9XI0xFXbhSYnjdu4Ii2gW7IKdRhWJdG6NnCu9Tpt54tvNH07yvwd1fjoVBfZBdo8eW2c9a9WSKieoTByYZy/z3dUt3ByWgUeHPNEeRq9PB2UWFIp4aI7hYMhYwXUdrLnTcmvlevR7VEhyA3dGvmhTYBrsjI02DzsVR0buJp6qWqSAtfF2x7vZfp+U/7kwAAOYU6/LQ/CTvOpONIUjbG9miCUd2bVGntRES1GYOTDeWU9DipFHdpWbW+/+sydp+7DrVCip/GdUUTL6dq3T/ZXhMvJ7zYs5npuY+LGs91Db7n7R64fBMHLt+aFmHDPykMTkREt2EXhA3Zo8fpQkYeYn87CQCY2r8VQxNZpIl38edEIgE6BrkjspWvnSsiIqqZ2ONkQ7eCU/X0OBmMAm+s+QdFOiMeDPHCc7eNmSGqSOdgT+x4vRfcHBTwcFIi/lgqtp5Mq9Q29AYj5DwdTER1HIOTDVkzOHzT0RRczMzH+F7N7jpO5U7f772Eg5dvwkkpw+yn2tvlSj6qvYLL6Z00GgVOpOQgMSkLDzT1RIiPC3KKdDh46SayC3U4n5GHvy5cR2JSFh4M8cKy0V2quXIiourD4GRDJT1OrhYGpzyNHpNXJUKjN2JQ+wA0auCIrAItrudr0czbucJ1r94swCebTwMApgxohUB3h3srngjAyZQc3P/hFmQV6EzLOgS540hSVpnt95y/Dr3BiJMpuThw+QZa+Lqge4hXNVVLRGR7DE42dKvHybJTdTtOp5tmmdYaDDAaBYYv/hun03Kx883eCCgnDAkh8PbaYyjQGtAl2BMjeAsNukdqRfEpt3ytAdAazF67PTT5uKjQrVkDNPd1waebT0OjN6LjzC3I0xT/o8FRKcM/M/ryFB4R1Rk1IjjNnz8fn376KVJTU9GhQwd89dVX6NKl7O7+xYsX47vvvsOxY8U3qw0LC8OsWbPKbW9PlR0cHn8s1ez5nvPXcSIlBwCQkl1UbnD65VAy/jyTAaVcitgn2/EUHd2z7iFemNg7BCq5FN2be6G1vyveW38cOoNAt2YN0LVZA7PP4418LT7//TSMorjn1FklR55GjwKtAQYhasYfGiKiKmD3v2erVq1CTEwMFi1ahPDwcMydOxdRUVE4ffo0fHx8SrXfsWMHhg0bhm7dukGtVmP27Nno27cvjh8/jsDAQDu8g/LlVKLHqUhnwPZT6WbLvv/r0l3Xy8jVYOaGEwCAVyOb3/WUHpElFDIpXo9qabbs4yfbl9ve00mJhc+GISWrEJ2beKKhuyM6zPzd1mUSEVU7u/efz5kzB2PHjsXo0aPRunVrLFq0CI6Ojli6dGmZ7VeuXInx48ejY8eOCA0NxX//+18YjUYkJCRUc+V3V5kep11nM4tPi/wrJbsIW0+mV7BGsfd/PY7sQh3aBLhibI+m1hdLdI+i2vhhVPcmaBPgBqnd/7IQEdmGXf+8abVaHDx4EJGRkaZlUqkUkZGR2Lt3r0XbKCgogE6ng6enp63KtFplglP8cfPTdHH7kmAwigrX+fNMBjb8kwKpBJj9ZHvODE5ERGRjdj1Vl5mZCYPBAF9f88n2fH19cerUKYu28dZbbyEgIMAsfN1Oo9FAo9GYnufk5FhfcCVZeqpOZzCWmjNn8x1B6k5FOgPe/V/xOK/obsFoG+h2D5USERGRJWp1F8XHH3+MuLg4rF27Fmp12fcCi42NhZubm+kRFBRULbUZjcJ0ZdHdpiPYd/EGsgp08HRSmnqn9EYBL2cVAtzKfl/f/nkBl64XwMdFhZg+vHkvERFRdbBrcPLy8oJMJkNamnlvS1paGvz8/Cpc97PPPsPHH3+M33//He3blz9oderUqcjOzjY9kpKSqqT2u8nX6iH+PdPm6lBxj9Nvx1IAAH1b+0J22xVxw7oEQSEv/Su6fD0fX28vvpP99EdaV9vM5ERERPWdXYOTUqlEWFiY2cDukoHeXbt2LXe9Tz75BB988AHi4+PRqVOnCvehUqng6upq9qgOJeObFDIJVGWEH6B4/qVnvt2L//vrCgAgqu2tsCiVAMPKmI9JCIEZ649Dqzeie0gDDGrvb4PqiYiIqCx2n44gJiYG0dHR6NSpE7p06YK5c+ciPz8fo0ePBgCMHDkSgYGBiI2NBQDMnj0b7777Ln744QcEBwcjNbV4LJCzszOcnWvOpfi336euvFunnEvPw18Xbpied2vWwPRzZCvfMudt2nw8FTtOZ0Apk+KDx9pW+rYsRHWFzmCEzmCEo/LWnzGjUXAeMyKyKbsHp6FDhyIjIwPvvvsuUlNT0bFjR8THx5sGjF+5cgXS265tXrhwIbRaLZ566imz7cyYMQPvvfdedZZeIUvuU/fn2UzTz91DGkAll8FRIUMWdHi2jBv0FukM+GDDSQDAuIimaMo5m6iW0OqNOJOWCwelDBm5GhxLzsbR5Gz4uaoxpX8oNHojTqbk4GRKLop0Bhy7lo0T13Igk0rww5gHIJUCp1JzceJaDk5cy8HxlGycTs2FziDQOdgDaoUMJ1NyUaDVY+mozrivkTvOpefhZr4OnZt4QCWX2fsQEFEdYffgBAATJ07ExIkTy3xtx44dZs8vXbpk+4KqgCVTEew6m2H6uV+b4tN0sU+2x9WbBejRvPT9vb798wKSswoR4KbG+F4hVVwxkW08vWgvTqXmQvvv7YTutHzPJeiNotzpN+42keb+SzfNnj/z7V+QSSWm7b3zSGu88GATKyonIiqtRgSnusg0FYGq7IHbWr3R7DTdE/c3BABEtPAus31qdhEW7jgPoPgmvg5K/guaai6FTAq5VAK9UeCfq9lmr/m5qtG+oRt+P1F8UYjmtkDl7qhA52BPtA1wwxdbz5itF+CmRusAV7T2d0XrAFfkawzYeDQFAe5qtPJ3xcZ/UrDn/HUAgMEoIJEAQgApWYU2frdEVJ8wONnI3XqcDl3JQqHOAA9HBfZPi7zrTVA/33IahToDOjX24IBwqvHUChk+fbo9TqXmom2AG9o3dEOguwPyNHq4OyoBAPsv3cC+izcQ6ueCtoFu8HFRmY3ZG3xfAHaezUQTLye08neFp5Oy1H6eDGto+vmRdgHYfCIV3i4qtPJzxbLdF/HNnxds/2aJqF5hcLKR2weHl2XnmeLTdBEtvC26c/yFjHwAwLuDWnNAONUKj9/XsNSyktAEAJ2DPdE5uPwZ/xs3cELjBk4W78/NUYEhnW6bp43/mxCRDdTqCTBrsrsNDt91rnhgeI/mZZ+aK8vTYQ3RvqH7PddGRERE1mGPk42U9DiVN2v4qdRcAMCDZQwCL4uTUoY3+rW8e0MiMqM1GHEqNQfn0/NxI1+DAe380cBZZe+yiKiWYnCykVwL7lPX0tcFvq5l31KlhPLf03gTHgqBj0vFbYmotO/2XsZ3ey+bnr/zv+MY3DEAFzLzkZ6jwdQBoXisY6AdKySi2oTByUYsmY7Akt6mt/qFIjEpi5dTE1VSU69b46Nc1HLT/5MAsC7xmunnTUdTTMFJqzdC+e9M/wajwPV8DbydVRxXSEQmDE42crfB4QDKnKvpTpGtfRHZ2rfK6iKqL4Z0CkJYY0+4Osjh7azCtewizNp0Eg4KGZp6O+FyZgFWHUjC5uNpeGrhHlzMzMf1fC0AoJm3E5JuFEJrMOLpsIb49OkOdn43RFRTMDjZSM5dBocrZVKEN2lQ5mtEdO8kEglCfG7Nrh/o7oD5w+83PV97+CpWHSi+6feBy+aTaJ7/9ypWADh2LcfGlRJRbcLgZCN3O1UX1tiDk1gS2VHf1n54NbIAUokETbyc0MjTEfsu3oBaKUNwA0ekZBfhzTX/2LtMIqphGJxs5G6Dw3u0sOxqOiKyDSeVHK9GtjBb1iHI3fTzn2cyQER0JwYnGxAA8jQVT0fQI8Ty+ZuIyH4KtHqcTs1F0o0CXMjMg84goJJLcfVmIa5lFaJ3qA96t/TB1ZsFSM4qRGt/V3g5q5CcVYjkrEI09XJCc18XCCGQU6g39TSnZhchOasQXs5KNPV2RkauBslZhXBVy9Hc18XO75qIysPgZAMFGj1K7ld6e4+Ts0qODkHuUEglaBPgaqfqiKgyLl8vQNTcP8t9veSeexVp5OmI63ka5GsNFu0zrLEHVHIpUrOLoFLI8N3zXeDppERGrgZSKUxTkxTpDNAbBRwUMmTmaZCaXYQrNwqgVsiQkatBak4RinQGDOkUBIVMgtTsIuRr9XigaQM4Kkv/+S/Q6pFVoIOPiwrX87VIz9Hger4GHRq6w8NJCZ3BiBv5Wrio5cjI1SA9V4PMXA3aBLjB312N63laZORq4Oemhs5gREauBhm5GjRu4MgwSHUGg5MNlPxxlEslUCtuTc4ukUiwbnw3XtpMVAuE+DhDJZdCozfCzUEBP1c1TqflomOQOxp6OKCBkxIr/p0fSiaVwNtZhdScItP6Xs4qZOZpAABXbhSU2n7JtkvIpBIY/v0X18E7Bqt3/mir2esA4OGowM0CnUXv5dsy7tkX3bUxMvI0pnCTkVtxsPN0UuLGv1cdVpZaIcX+aZEVXmVMVFswONmQi1peKiQxNBHVDgHuDjj0Th/ojQJuDmV/4b/ZLxRZhTr4uqggl0mRr9EjPVcDfzc11AoZjiVn48S1HPi7qxHg7gB3BwVSsovg76aGp5MShToDzqblwcdVBR8XNRKTbmLDPynwclbB302NT+JPm8LY7aEJQKnQJJXA1NPd2t8V/m5qHE3ORnpucXhTK6Qo0t0KaitumxS0LLdvD0Cp0KRWSOHuoDQLi7eHO7lUAh+X4mkginRG5BTpGZyoTmBwsiHXcv7YElHt4KSq+E+kk0pu1sZJJUeT2563DXRD20A3s3Vuv92Lo1JuNiA9rLEnwhrfuvFxZGtfHLx0Ex5OSvi7qaGQSbHrXCZc1XL4uanh56rG9XwtnJRyeDkry7xh+PU8DeQyKVzVctws0OHTzadhMBrh7aKCt7MK3i7q4p//fRiMAhq9AQ2cVJBJJTiWnI0b+Vp4u6jg46KCs1oOjd4IF1XxPwyzC3S4ll0IHxcVPByVEAByCnVwc1BAKpWgxbTfoDUY8fvxVKgVMtzI1+J6nhY3C7S4nq/FjX8nGV34bBjUCuuuNBZC8B+lVG0YnGyoolnDiYjuxlWtQO9QH7Nlj3YIMHvu7qiscBu3BzVPJyVin2hnwZ5v/aPvzuAHACr5rYDj5qiAm6P5PxI9nG7VVJJn3v/1RIV7/OdqNtoFuuFGgRY384uD1Y384p+PJufA00mBPI0B2YVaZBXokFWgQ3ahDlkFWkglEnwzMgxhjT1wM18HgxAIdHew4H0SVR6/2W3IRcUeJyKq36K7BeP346nwcFKigZMSHo5KeDrf+vnz388gNacIQ77Ze0/7Gb74b7PnDZyUiGrrh5v5Wly6XoCGHg5o5OmImwVaFOkMeOHBJma9e0SWYnCyIfY4EVF99/aAVnh7QKtyX//9RBpST9waJ6WUSeHhpICHY3GwyszTINjLCQ09HODuoIS7o+LfhxLuDgqsPZyM5Xsuldru9Xwtfvj7iun5yRTzGeANRoFvnvOEwShQpDOYTrkKIVCkMyJXo0NukR65RXoUaPRoE+hW7lg3ql/4zW5DHAhJRFSx+cPvx9n0XLiqFfB0UsJRKavUeKX2Dd3w7AONIJNK4emoRIFOj0U7zgMoPmVoFMCusxkI8XGGh5MSlzMLEH88FZuPp6HjzN+RXaiD+HcQvIejArlFeujvGIhf4qmwhsgq0CGnSIe+rX0xpkfTe37/VPswONkQe5yIiCqmlEvRJqD0OCpLFd+T8NYcUW5Q4P3H2pq1ielza4b43ecyEX88FQCQdceVibdfqSiRFM+9V3L7LABYc/Cq6ed9F28gNbsI2YXFQeqBpg0wunsTq98H1R78Zreh8mYNJyIi++jWrAE2/OdBFOoM8HBUwM1Biev5GuRrDHBRy/99KOB0W8/Xyr8v48qNArg5KKDTC3yx9QwA4L+7Lpq2u/l4GiJb+aJQZ0BOoQ6NGjjCSSlHTlHxKT9fF3WpQfRUO/Gb3YZ4qo6IqGaRSCSlrhT0dlGV07rYiPDGZs/dHRU4lZoDV7UCKoUMXyacBQD0+GR7hduJbOUDIYpvAv9PchaGdgpCgdaA3CI9Gjgr8e6g1mZXLFLNxOBkQzxVR0RU90R3Czb9bDQKbD+VjqPJ2ZBLJXB1UJhNFnr7pKBbT6abbefOSUj/vngD7Ru6Ia9Ij6s3CzGsSxAAIFejR9KNQrQNdIXeIJCn0UMpk2JolyC48h/o1Y7f7DbEHiciorpNKpVg/cTuKNQZ4KAoPr1nMApk5Grg6iCHg0KGQ1du4o/TGXBWy+GqVuBkSg6KdEZ4OCnhopbj082nAQDn0vNwLj3PtO13/ne8wn3LZRKOq7IDBicbYo8TEVHdJ5FIzG6aLJNK4OemNj2/c0b4O/Vo7oX/JV6Dg0IGF7Uc+y/dQNKNQvi4quCskuN0aq5pmy5qOU6m5OJiZj5+PXIN3i4q5Gv0uJGvQ6hf8SD5PE3xgPbeoT5wvsvs91R5PKI2xOBERER3076hO9o3dDc9HxfRrML2b689iouZ+Th0JQuHfjhcbrtm3k6Y+FAI8jUG5Gn0uL+RB1z+vWWORmdA0b//1eiN0BuN6B7iBR8Xdbnbo2L8ZrchnqojIqKqNrhjIP65mgUAcFLKcT4jHzfyNQhu4AQnlRxHk7MBAOcz8jF51ZFKbbt7SAMUaA3I1+jRs7k3hnQuHsBeqDWgdYArJwEFg5NNcToCIiKqal2aeGLDf3qU+/rFzHxMW3sUGr0RjkoZUrKLcC49Dy4qOVQKGVRyKVQKKdRyGVQKKc6l5SH339N7u89dN23nTFqe2ZQLAPDKw81RqNWjUGdAt2ZeGNDO3zZvsgbjN7sNsceJiIiqWxMvJ/ww9gGL2wshkHAyHem5mn9nbgcmxSVCrZDCUSlHVoEWJZOpl0y9AACrD1xFvzZ+kEotn+m9LmBwshG5VAK1QmrvMoiIiCokkUgQ2drXbNljHQPNni/+8wJOp+XCUVk8z9R3ey9Dozdiy8k0aPVGFOkMEAAaeTqiSGdAkc4IpVyCAHcHaPVG00NjuPWzv5sanYJr342WGZxsxEUtr9T9loiIiGqqsT1v3Zcvq0CL7/6dg2rc9wfvabubX+2Jln4ud29YgzA42QhP0xERUV3k7qjEiPBGOHDpJtRKGRwUUvx14QYC3NRQK2VQy2U4kZIDZ5UcaoUUSpkUCnnxf5Xy4seplFwU6gyImvsnOgS5Q6Mz4ExaLp4KawhHpRwavQGuagUmPhRS475PGZxshFMREBFRXfXR4+3uaf3nlvyNnWczAQBHkrJMy386cNWsXUs/Fzxxf8N72ldV47e7jXAafCIiorLNGdIRe85nQiGTQiWX4kJGPs6l58HVQQ6VXIZNx1JwISMfMT8dwdrDydDojXBWyfH+o20Q5Olo19oZnGyEPU5ERERl83ZRmQ1Af7iV+euZeRpcyMgHAFPPFAB0bdrAbLyVPfDb3UZq2jlZIiKi2uLNfqG4r5E7hACUcimOX8uBv5saES287V0ag5OtsMeJiIjIOp5OSgzt3Mj0/In77VjMHTjRkI1w1nAiIqK6h8HJRniqjoiIqO5hcLIRnqojIiKqexicbIQ9TkRERHUPg5ONsMeJiIio7mFwshEGJyIiorqnRgSn+fPnIzg4GGq1GuHh4di3b1+F7VevXo3Q0FCo1Wq0a9cOmzZtqqZKLcdTdURERHWP3YPTqlWrEBMTgxkzZuDQoUPo0KEDoqKikJ6eXmb7PXv2YNiwYXjhhRdw+PBhDB48GIMHD8axY8equfKKcToCIiKiukcihBD2LCA8PBydO3fG119/DQAwGo0ICgrCf/7zH0yZMqVU+6FDhyI/Px8bNmwwLXvggQfQsWNHLFq06K77y8nJgZubG7Kzs+Hq6lp1bwTA8WvZGPjlLgDAyZn94KCUVen2iYiIqOpVJhvYtcdJq9Xi4MGDiIyMNC2TSqWIjIzE3r17y1xn7969Zu0BICoqqtz29iCXSqBW2L0zj4iIiKqYXc8nZWZmwmAwwNfX12y5r68vTp06VeY6qampZbZPTU0ts71Go4FGozE9z8nJuceq785FLYdEIrH5foiIiKh61flukdjYWLi5uZkeQUFBNttXiI8zOgd74Jkuje7emIiIiGoduwYnLy8vyGQypKWlmS1PS0uDn59fmev4+flVqv3UqVORnZ1teiQlJVVN8WVQyWVY/VI3vNUv1Gb7ICIiIvuxa3BSKpUICwtDQkKCaZnRaERCQgK6du1a5jpdu3Y1aw8AW7ZsKbe9SqWCq6ur2YOIiIjIGna/Zj4mJgbR0dHo1KkTunTpgrlz5yI/Px+jR48GAIwcORKBgYGIjY0FAEyaNAkRERH4/PPPMXDgQMTFxeHAgQP49ttv7fk2iIiIqB6we3AaOnQoMjIy8O677yI1NRUdO3ZEfHy8aQD4lStXIJXe6hjr1q0bfvjhB0yfPh1vv/02mjdvjnXr1qFt27b2egtERERUT9h9HqfqZst5nIiIiKj2qTXzOBERERHVJgxORERERBZicCIiIiKyEIMTERERkYUYnIiIiIgsxOBEREREZCEGJyIiIiIL2X0CzOpWMm1VTk6OnSshIiKimqAkE1gytWW9C065ubkAgKCgIDtXQkRERDVJbm4u3NzcKmxT72YONxqNuHbtGlxcXCCRSKp8+zk5OQgKCkJSUhJnJq9GPO72weNuPzz29sHjbh+2Pu5CCOTm5iIgIMDsNm9lqXc9TlKpFA0bNrT5flxdXfk/lR3wuNsHj7v98NjbB4+7fdjyuN+tp6kEB4cTERERWYjBiYiIiMhCDE5VTKVSYcaMGVCpVPYupV7hcbcPHnf74bG3Dx53+6hJx73eDQ4nIiIishZ7nIiIiIgsxOBEREREZCEGJyIiIiILMThZYf78+QgODoZarUZ4eDj27dtXYfvVq1cjNDQUarUa7dq1w6ZNm6qp0rqlMsd98eLF6NGjBzw8PODh4YHIyMi7/p6obJX9vJeIi4uDRCLB4MGDbVtgHVbZY5+VlYUJEybA398fKpUKLVq04N8bK1T2uM+dOxctW7aEg4MDgoKCMHnyZBQVFVVTtXXDn3/+iUGDBiEgIAASiQTr1q276zo7duzA/fffD5VKhZCQECxfvtzmdQIABFVKXFycUCqVYunSpeL48eNi7Nixwt3dXaSlpZXZfvfu3UImk4lPPvlEnDhxQkyfPl0oFApx9OjRaq68dqvscR8+fLiYP3++OHz4sDh58qQYNWqUcHNzE1evXq3mymu3yh73EhcvXhSBgYGiR48e4rHHHqueYuuYyh57jUYjOnXqJAYMGCB27dolLl68KHbs2CESExOrufLarbLHfeXKlUKlUomVK1eKixcvis2bNwt/f38xefLkaq68dtu0aZOYNm2a+OWXXwQAsXbt2grbX7hwQTg6OoqYmBhx4sQJ8dVXXwmZTCbi4+NtXiuDUyV16dJFTJgwwfTcYDCIgIAAERsbW2b7IUOGiIEDB5otCw8PF+PGjbNpnXVNZY/7nfR6vXBxcRErVqywVYl1kjXHXa/Xi27duon//ve/Ijo6msHJSpU99gsXLhRNmzYVWq22ukqskyp73CdMmCAeeughs2UxMTGie/fuNq2zLrMkOL355puiTZs2ZsuGDh0qoqKibFhZMZ6qqwStVouDBw8iMjLStEwqlSIyMhJ79+4tc529e/eatQeAqKiocttTadYc9zsVFBRAp9PB09PTVmXWOdYe95kzZ8LHxwcvvPBCdZRZJ1lz7NevX4+uXbtiwoQJ8PX1Rdu2bTFr1iwYDIbqKrvWs+a4d+vWDQcPHjSdzrtw4QI2bdqEAQMGVEvN9ZU9v1vr3b3q7kVmZiYMBgN8fX3Nlvv6+uLUqVNlrpOamlpm+9TUVJvVWddYc9zv9NZbbyEgIKDU/2hUPmuO+65du7BkyRIkJiZWQ4V1lzXH/sKFC9i2bRtGjBiBTZs24dy5cxg/fjx0Oh1mzJhRHWXXetYc9+HDhyMzMxMPPvgghBDQ6/V46aWX8Pbbb1dHyfVWed+tOTk5KCwshIODg832zR4nqvM+/vhjxMXFYe3atVCr1fYup87Kzc3Fc889h8WLF8PLy8ve5dQ7RqMRPj4++PbbbxEWFoahQ4di2rRpWLRokb1Lq9N27NiBWbNmYcGCBTh06BB++eUXbNy4ER988IG9SyMbYY9TJXh5eUEmkyEtLc1seVpaGvz8/Mpcx8/Pr1LtqTRrjnuJzz77DB9//DG2bt2K9u3b27LMOqeyx/38+fO4dOkSBg0aZFpmNBoBAHK5HKdPn0azZs1sW3QdYc1n3t/fHwqFAjKZzLSsVatWSE1NhVarhVKptGnNdYE1x/2dd97Bc889hzFjxgAA2rVrh/z8fLz44ouYNm0apFL2T9hCed+trq6uNu1tAtjjVClKpRJhYWFISEgwLTMajUhISEDXrl3LXKdr165m7QFgy5Yt5ban0qw57gDwySef4IMPPkB8fDw6depUHaXWKZU97qGhoTh69CgSExNNj0cffRS9e/dGYmIigoKCqrP8Ws2az3z37t1x7tw5U1gFgDNnzsDf35+hyULWHPeCgoJS4agkvAre0cxm7PrdavPh53VMXFycUKlUYvny5eLEiRPixRdfFO7u7iI1NVUIIcRzzz0npkyZYmq/e/duIZfLxWeffSZOnjwpZsyYwekIrFDZ4/7xxx8LpVIp1qxZI1JSUkyP3Nxce72FWqmyx/1OvKrOepU99leuXBEuLi5i4sSJ4vTp02LDhg3Cx8dHfPjhh/Z6C7VSZY/7jBkzhIuLi/jxxx/FhQsXxO+//y6aNWsmhgwZYq+3UCvl5uaKw4cPi8OHDwsAYs6cOeLw4cPi8uXLQgghpkyZIp577jlT+5LpCN544w1x8uRJMX/+fE5HUJN99dVXolGjRkKpVIouXbqIv/76y/RaRESEiI6ONmv/008/iRYtWgilUinatGkjNm7cWM0V1w2VOe6NGzcWAEo9ZsyYUf2F13KV/bzfjsHp3lT22O/Zs0eEh4cLlUolmjZtKj766COh1+uruerarzLHXafTiffee080a9ZMqNVqERQUJMaPHy9u3rxZ/YXXYtu3by/zb3bJsY6OjhYRERGl1unYsaNQKpWiadOmYtmyZdVSq0QI9iUSERERWYJjnIiIiIgsxOBEREREZCEGJyIiIiILMTgRERERWYjBiYiIiMhCDE5EREREFmJwIiIiIrIQgxMRERGRhRiciIgqSSKRYN26dQCAS5cuQSKRIDEx0a41EVH1YHAiolpl1KhRkEgkkEgkUCgUaNKkCd58800UFRXZuzQiqgfk9i6AiKiy+vXrh2XLlkGn0+HgwYOIjo6GRCLB7Nmz7V0aEdVx7HEiolpHpVLBz88PQUFBGDx4MCIjI7FlyxYAgNFoRGxsLJo0aQIHBwd06NABa9asMVv/+PHjeOSRR+Dq6goXFxf06NED58+fBwDs378fffr0gZeXF9zc3BAREYFDhw5V+3skopqJwYmIarVjx45hz549UCqVAIDY2Fh89913WLRoEY4fP47Jkyfj2WefxR9//AEASE5ORs+ePaFSqbBt2zYcPHgQzz//PPR6PQAgNzcX0dHR2LVrF/766y80b94cAwYMQG5urt3eIxHVHDxVR0S1zoYNG+Ds7Ay9Xg+NRgOpVIqvv/4aGo0Gs2bNwtatW9G1a1cAQNOmTbFr1y588803iIiIwPz58+Hm5oa4uDgoFAoAQIsWLUzbfuihh8z29e2338Ld3R1//PEHHnnkkep7k0RUIzE4EVGt07t3byxcuBD5+fn44osvIJfL8eSTT+L48eMoKChAnz59zNprtVrcd999AIDExET06NHDFJrulJaWhunTp2PHjh1IT0+HwWBAQUEBrly5YvP3RUQ1H4MTEdU6Tk5OCAkJAQAsXboUHTp0wJIlS9C2bVsAwMaNGxEYGGi2jkqlAgA4ODhUuO3o6Ghcv34d8+bNQ+PGjaFSqdC1a1dotVobvBMiqm0YnIioVpNKpXj77bcRExODM2fOQKVS4cqVK4iIiCizffv27bFixQrodLoye512796NBQsWYMCAAQCApKQkZGZm2vQ9EFHtwcHhRFTrPf3005DJZPjmm2/w+uuvY/LkyVixYgXOnz+PQ4cO4auvvsKKFSsAABMnTkROTg6eeeYZHDhwAGfPnsX333+P06dPAwCaN2+O77//HidPnsTff/+NESNG3LWXiojqD/Y4EVGtJ5fLMXHiRHzyySe4ePEivL29ERsbiwsXLsDd3R33338/3n77bQBAgwYNsG3bNrzxxhuIiIiATCZDx44d0b17dwDAkiVL8OKLL+L+++9HUFAQZs2ahddff92eb4+IahCJEELYuwgiIiKi2oCn6oiIiIgsxOBEREREZCEGJyIiIiILMTgRERERWYjBiYiIiMhCDE5EREREFmJwIiIiIrIQgxMRERGRhRiciIiIiCzE4ERERERkIQYnIiIiIgsxOBERERFZ6P8BWES2W57IYkcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on test set\n",
    "test_preds = model.predict(X_test_tfidf)\n",
    "test_probs = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Print performance report\n",
    "print(\"Test Results\")\n",
    "print(classification_report(y_test, test_preds, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, test_probs))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, test_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_test, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "prec, rec, _ = precision_recall_curve(y_test, test_probs)\n",
    "pr_auc = auc(rec, prec)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(rec, prec, label=f\"PR AUC = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (Test)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661da958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for later\n",
    "baseline_results = {\n",
    "    \"model_name\": \"tfidf_logreg_baseline\",\n",
    "    \"performance\": {\n",
    "        \"test\": {\n",
    "            \"roc_auc\": float(roc_auc_score(y_test, test_probs)),\n",
    "            \"precision_risk\": float(np.round(classification_report(y_test, test_preds, output_dict=True)['1']['precision'], 3)),\n",
    "            \"recall_risk\": float(np.round(classification_report(y_test, test_preds, output_dict=True)['1']['recall'], 3)),\n",
    "            \"f1_risk\": float(np.round(classification_report(y_test, test_preds, output_dict=True)['1']['f1-score'], 3)),\n",
    "            \"accuracy\": float(np.round(classification_report(y_test, test_preds, output_dict=True)['accuracy'], 3))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"../outputs/models\", exist_ok=True)\n",
    "\n",
    "# Save as JSON\n",
    "output_path = \"../outputs/models/baseline_tfidf_logreg_results.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(baseline_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e207fd9",
   "metadata": {
    "id": "7e207fd9"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Improved Model: FinBERT & LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ca595",
   "metadata": {
    "id": "ab3ca595"
   },
   "source": [
    "## Load FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "N8RSFTYDL5tI",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q evaluate>=0.4.2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e14e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae736ddf7b1474d822a708ceefad0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab0825c37e44881a6297f45e04a2ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ce6502ab74456fb59ee5f676532f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2364 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# Load pre-split training, validation, and test sets that contains clean_text and risk_flag (Colab)\n",
    "colab_dir = \"/content/drive/MyDrive/NLP/respect-cfpb\"\n",
    "train_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/test.csv\"))\n",
    "\n",
    "# Initiate and load tokenizer for FinBERT\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Convert DataFrames to Hugging Face Datasets; keep only the clean_text and risk_flag (target column)\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"clean_text\", \"risk_flag\"]]).rename_column(\"risk_flag\", \"labels\")\n",
    "val_dataset   = Dataset.from_pandas(val_df[[\"clean_text\", \"risk_flag\"]]).rename_column(\"risk_flag\", \"labels\")\n",
    "test_dataset  = Dataset.from_pandas(test_df[[\"clean_text\", \"risk_flag\"]]).rename_column(\"risk_flag\", \"labels\")\n",
    "\n",
    "# Tokenize input text\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"clean_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"clean_text\"])\n",
    "val_dataset   = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"clean_text\"])\n",
    "test_dataset  = test_dataset.map(tokenize_function, batched=True, remove_columns=[\"clean_text\"])\n",
    "\n",
    "# Tell datasets to return PyTorch tensors\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704dbde",
   "metadata": {
    "id": "b704dbde"
   },
   "source": [
    "**Skip This Section for Rerun**\n",
    "\n",
    "*This section kept for comparison only. New run uses balanced sampler below*\n",
    "\n",
    "## Class balancing - weighted cross-entropy loss function\n",
    "To address the class imbalance in our dataset, we apply a weighted cross-entropy loss function.\n",
    "This technique rebalances the contribution of each class during training by assigning higher weights to the minority class (risk), which comprises only ~5% of the complaints.\n",
    "\n",
    "Following the approach described in\n",
    "* Addressing Data Imbalance in Transformers ([arXiv:2507.11384v1](https://arxiv.org/html/2507.11384v1)), and\n",
    "* Baseline with HuggingFace ([Inagana, Kaggle, 2023](https://www.kaggle.com/code/inagana/baseline-with-huggingface-training-beginners)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([ 1.0513, 40.9769], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights from train_df\n",
    "counts = train_df[\"risk_flag\"].value_counts()\n",
    "n_total = len(train_df)\n",
    "\n",
    "# inverse frequency weighting to give rare classes higher weights\n",
    "weight_for_0 = n_total / counts[0]\n",
    "weight_for_1 = n_total / counts[1] * 2 # scale up positive class\n",
    "\n",
    "# convert to tensor and push to device\n",
    "class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float).to(device)\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Define a weighted Trainer\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # Remove labels from dictionary to allow computatio of loss manually\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Apply custom weighted loss\n",
    "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83feffd5",
   "metadata": {
    "id": "83feffd5"
   },
   "source": [
    "## LoRA Fine-Tuning\n",
    "Source: W266 Walkthrough Notebook for Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z6ubJt67PXFu",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2, # Set number of labels to 2 (1=risk, 0=no risk)\n",
    "    ignore_mismatched_sizes=True # since we are changing the num of labels\n",
    ").to(device)\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "# Inject LoRA adapters into FinBERT\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lJjTZZDsRGXQ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    precision = precision_metric.compute(predictions=preds, references=labels, average=\"binary\")[\"precision\"]\n",
    "    recall = recall_metric.compute(predictions=preds, references=labels, average=\"binary\")[\"recall\"]\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"]\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sqqkiqMzRWAp",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/NLP/respect-cfpb/models/finbert_lora_clean\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.05,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.0,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=25,\n",
    "    report_to=\"none\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5OCK7hzWR6Zp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2650450409.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1332' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1332/1332 06:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.580800</td>\n",
       "      <td>0.592036</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.635800</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.950063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.590022</td>\n",
       "      <td>0.950487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1332, training_loss=0.6194535107225985, metrics={'train_runtime': 375.8587, 'train_samples_per_second': 56.582, 'train_steps_per_second': 3.544, 'total_flos': 5614950552145920.0, 'train_loss': 0.6194535107225985, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dAZICkofNy_O",
   "metadata": {
    "id": "dAZICkofNy_O"
   },
   "source": [
    "**Ues This Section for the Rerun**\n",
    "\n",
    "## Balanced Sampling for Training in FinBERT\n",
    "In earlier experiements, we attempted to address the severe class imbalance in our training data by using a custom weighted cross-entropy loss. This approach increases the loss contribution of the minority class so the model is penalized more heavily when it misclassifies class 1 (risk flag). Although intuitive, this method was not sufficient in our case. Across many training runs, the model continued to predict the majority class almost exclusively, indicating that the minority-class signal was still being overwhelmed during gradient updates. In other words, even when the model noticed minority examples, it did not see enough of them within each batch to meaningfully adjust its internal representations.\n",
    "\n",
    "Because of this, we introduce a second technique: **balanced sampling**. Instead of modifying the loss function, balanced sampling modifies how batches are constructed. The key idea is that the model should see roughly the same number of positive and negative examples within each training batch, even if the underlying dataset is imbalanced.\n",
    "\n",
    "To implement this, we use PyTorch WeightedRandomSampler, which assigns sampling weights to each training instance based on the inverse frequency of its class. As a result:\n",
    "* Class 0 samples receive lower sampling probability\n",
    "* Class 1 samples receive higher sampling probability\n",
    "* Each batch contains a balanced mix of classes regardless of the dataset imbalance\n",
    "* No data is duplicated or discarded (unlike oversampling or undersampling)\n",
    "\n",
    "We used PyTorch's WeightedRandomSampler, which allows each batch to sample from classes in proportion of inverted class frequencies as described in:\n",
    "* https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler\n",
    "* https://medium.com/data-science/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452\n",
    "* https://github.com/pytorch/pytorch/blob/main/torch/utils/data/sampler.py#L73-L90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "t3GxtUoNNyy1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from transformers import DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wkKmsHqAXxow",
   "metadata": {
    "id": "wkKmsHqAXxow"
   },
   "source": [
    "**Build balanced weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hnD71eDiNyrb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in training set: [6743  346]\n"
     ]
    }
   ],
   "source": [
    "# Count classes in the training dataset\n",
    "train_labels = train_dataset[\"labels\"]\n",
    "class_counts = np.bincount(train_labels)\n",
    "num_samples = len(train_labels)\n",
    "\n",
    "print(\"Class counts in training set:\", class_counts)\n",
    "\n",
    "# Inverse-frequency weights for each class\n",
    "weights = 1.0 / class_counts # inverse frequency results in higher probability for minority class\n",
    "sample_weights = [weights[label] for label in train_labels] # assign per example weight based on label\n",
    "\n",
    "# Sampler that draws samples according to these weights\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=num_samples,   # same number of samples per epoch\n",
    "    replacement=True           # sampling with replacement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "YdCjl3D1NyiL",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    sampler=sampler #apply the balanced batch defined ealier\n",
    ")\n",
    "\n",
    "# Evaluation uses regular sequential loading\n",
    "eval_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# custom Trainer that uses our sampler-based dataloaders\n",
    "class BalancedTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def get_eval_dataloader(self, eval_dataset=None):\n",
    "        return eval_dataloader\n",
    "\n",
    "# metrics using threshold 0.5 during training\n",
    "def compute_metrics_balanced(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, zero_division=0)\n",
    "    recall = recall_score(labels, preds, zero_division=0)\n",
    "    f1 = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        roc_auc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5beUvYPUY19Q",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hp(config):\n",
    "    lr = config[\"lr\"]\n",
    "    r = config[\"r\"]\n",
    "    num_epochs = config[\"epochs\"]\n",
    "    run_name = config[\"name\"]\n",
    "\n",
    "    print(f\"\\n=== Training run: {run_name} | lr={lr} | r={r} | epochs={num_epochs} ===\")\n",
    "\n",
    "    # fresh base model each time\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    lora_cfg = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        r=r,\n",
    "        lora_alpha=2*r,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\"\n",
    "    )\n",
    "    model_lora = get_peft_model(base_model, lora_cfg).to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=os.path.join(\n",
    "            colab_dir, f\"models/finbert_lora_balanced_{run_name}\"\n",
    "        ),\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.05,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        logging_steps=50,\n",
    "        gradient_accumulation_steps=2,\n",
    "        seed=42,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = BalancedTrainer(\n",
    "        model=model_lora,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics_balanced,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(f\"Final val metrics for {run_name}:\")\n",
    "    print(metrics)\n",
    "\n",
    "    # keep track of what worked\n",
    "    return {\n",
    "        \"name\": run_name,\n",
    "        \"lr\": lr,\n",
    "        \"r\": r,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"metrics\": metrics,\n",
    "        \"trainer\": trainer,   # so you can later reuse the best\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cEF5_48fdrC",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"name\": \"r4_lr1e-5\",  \"r\": 4, \"lr\": 1e-5, \"epochs\": 3},\n",
    "    {\"name\": \"r8_lr1e-5\",  \"r\": 8, \"lr\": 1e-5, \"epochs\": 3},\n",
    "    {\"name\": \"r4_lr5e-6\",  \"r\": 4, \"lr\": 5e-6, \"epochs\": 3},\n",
    "    {\"name\": \"r8_lr5e-6\",  \"r\": 8, \"lr\": 5e-6, \"epochs\": 3},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "l3jZyFa7fuS1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training run: r4_lr1e-5 | lr=1e-05 | r=4 | epochs=3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-113546508.py:47: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BalancedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = BalancedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1332' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1332/1332 06:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>0.700530</td>\n",
       "      <td>0.471858</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.475994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.687095</td>\n",
       "      <td>0.548455</td>\n",
       "      <td>0.044061</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.479843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.699763</td>\n",
       "      <td>0.479475</td>\n",
       "      <td>0.045640</td>\n",
       "      <td>0.486957</td>\n",
       "      <td>0.083458</td>\n",
       "      <td>0.481127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='296' max='296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [296/296 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val metrics for r4_lr1e-5:\n",
      "{'eval_loss': 0.6997628808021545, 'eval_accuracy': 0.47947524333474395, 'eval_precision': 0.045639771801140996, 'eval_recall': 0.48695652173913045, 'eval_f1': 0.08345752608047691, 'eval_roc_auc': 0.48112718551756145, 'eval_runtime': 15.6223, 'eval_samples_per_second': 151.258, 'eval_steps_per_second': 18.947, 'epoch': 3.0}\n",
      "\n",
      "=== Training run: r8_lr1e-5 | lr=1e-05 | r=8 | epochs=3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-113546508.py:47: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BalancedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = BalancedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1332' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1332/1332 06:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.744668</td>\n",
       "      <td>0.178587</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.092567</td>\n",
       "      <td>0.501644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.715397</td>\n",
       "      <td>0.393144</td>\n",
       "      <td>0.047978</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.088945</td>\n",
       "      <td>0.492453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>0.724975</td>\n",
       "      <td>0.336860</td>\n",
       "      <td>0.047945</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.089483</td>\n",
       "      <td>0.495907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='296' max='296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [296/296 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val metrics for r8_lr1e-5:\n",
      "{'eval_loss': 0.7446680665016174, 'eval_accuracy': 0.17858654253068135, 'eval_precision': 0.04891304347826087, 'eval_recall': 0.8608695652173913, 'eval_f1': 0.09256661991584852, 'eval_roc_auc': 0.501643973386972, 'eval_runtime': 15.5794, 'eval_samples_per_second': 151.675, 'eval_steps_per_second': 18.999, 'epoch': 3.0}\n",
      "\n",
      "=== Training run: r4_lr5e-6 | lr=5e-06 | r=4 | epochs=3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-113546508.py:47: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BalancedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = BalancedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1332' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1332/1332 06:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.704600</td>\n",
       "      <td>0.844627</td>\n",
       "      <td>0.053322</td>\n",
       "      <td>0.048895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>0.534019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.738783</td>\n",
       "      <td>0.189166</td>\n",
       "      <td>0.050424</td>\n",
       "      <td>0.878261</td>\n",
       "      <td>0.095373</td>\n",
       "      <td>0.515043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.736287</td>\n",
       "      <td>0.206517</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.093765</td>\n",
       "      <td>0.511852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='296' max='296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [296/296 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val metrics for r4_lr5e-6:\n",
      "{'eval_loss': 0.7387833595275879, 'eval_accuracy': 0.18916631400761744, 'eval_precision': 0.050424363454817774, 'eval_recall': 0.8782608695652174, 'eval_f1': 0.09537299338999056, 'eval_roc_auc': 0.5150433235339625, 'eval_runtime': 15.626, 'eval_samples_per_second': 151.223, 'eval_steps_per_second': 18.943, 'epoch': 3.0}\n",
      "\n",
      "=== Training run: r8_lr5e-6 | lr=5e-06 | r=8 | epochs=3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-113546508.py:47: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `BalancedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = BalancedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1332' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1332/1332 06:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.836990</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>0.048864</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.093137</td>\n",
       "      <td>0.523948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.739903</td>\n",
       "      <td>0.172662</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.852174</td>\n",
       "      <td>0.091120</td>\n",
       "      <td>0.511183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.737879</td>\n",
       "      <td>0.188743</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.509570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='296' max='296' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [296/296 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final val metrics for r8_lr5e-6:\n",
      "{'eval_loss': 0.8369901776313782, 'eval_accuracy': 0.060516292848074485, 'eval_precision': 0.0488641234462066, 'eval_recall': 0.991304347826087, 'eval_f1': 0.09313725490196079, 'eval_roc_auc': 0.5239478570323379, 'eval_runtime': 15.5931, 'eval_samples_per_second': 151.541, 'eval_steps_per_second': 18.983, 'epoch': 3.0}\n",
      "r4_lr1e-5 | f1: 0.083 | recall: 0.487 | precision: 0.046 | roc_auc: 0.481\n",
      "r8_lr1e-5 | f1: 0.093 | recall: 0.861 | precision: 0.049 | roc_auc: 0.502\n",
      "r4_lr5e-6 | f1: 0.095 | recall: 0.878 | precision: 0.05 | roc_auc: 0.515\n",
      "r8_lr5e-6 | f1: 0.093 | recall: 0.991 | precision: 0.049 | roc_auc: 0.524\n"
     ]
    }
   ],
   "source": [
    "all_runs = []\n",
    "for cfg in configs:\n",
    "    result = train_hp(cfg)\n",
    "    all_runs.append(result)\n",
    "\n",
    "for r in all_runs:\n",
    "    m = r[\"metrics\"]\n",
    "    print(\n",
    "        r[\"name\"],\n",
    "        \"| f1:\", round(m[\"eval_f1\"], 3),\n",
    "        \"| recall:\", round(m[\"eval_recall\"], 3),\n",
    "        \"| precision:\", round(m[\"eval_precision\"], 3),\n",
    "        \"| roc_auc:\", round(m[\"eval_roc_auc\"], 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LxBNcFGffLLh",
   "metadata": {
    "id": "LxBNcFGffLLh"
   },
   "source": [
    "# Full FinBERT Fine Tuning\n",
    "\n",
    "### Why LoRA Did Not Work Reliably\n",
    "\n",
    "So far, we tried to fine tune FinBERT using LoRA together with:\n",
    "\n",
    "- Custom class weighted loss  \n",
    "- Balanced sampling with `WeightedRandomSampler`  \n",
    "- Several different hyperparameter settings\n",
    "\n",
    "Across many runs we kept seeing the same pattern:\n",
    "\n",
    "- The model often predicted almost everything as class 0  \n",
    "- When we pushed too hard on imbalance, it flipped and predicted too many class 1s  \n",
    "\n",
    "This suggests that the LoRA setup plus our imbalance handling created a model that was fragile and hard to tune in a stable way.\n",
    "\n",
    "**Possible reasons:**\n",
    "\n",
    "- **Strong class imbalance**  \n",
    "  Only about 5 percent of complaints are labeled as risky (class 1). A model can achieve high accuracy by defaulting to class 0, and it needs a strong and consistent signal to learn class 1.\n",
    "\n",
    "- **Risky and non risky complaints are linguistically similar**  \n",
    "  Many narratives look similar on the surface. The difference between risky and non risky often depends on subtle details about the outcome, harm, or regulatory context. This makes the decision boundary harder to learn.\n",
    "\n",
    "- **Extra LoRA hyperparameters make things more sensitive**  \n",
    "  LoRA introduces extra knobs such as rank `r`, `lora_alpha`, and dropout. Those hyperparameters interact with class imbalance and loss weighting. Small changes can lead to very different behavior, which we observed in practice.\n",
    "\n",
    "- **Balancing tricks can destabilize training**  \n",
    "  We tried loss weighting, oversampling, and balanced sampling. All three are designed to push the model to pay more attention to class 1. In combination they can make training unstable and can cause the model to oscillate between predicting almost all zeros and predicting too many ones.\n",
    "\n",
    "Overall, the LoRA approach became complex and difficult to control. The fact that a single good run was not reproducible is a sign that the method is not robust in this setting.\n",
    "\n",
    "---\n",
    "\n",
    "### New Plan: Full FinBERT Fine Tuning\n",
    "\n",
    "To simplify and stabilize the approach, we now switch to full FinBERT fine tuning:\n",
    "\n",
    "- We keep the same train, validation, and test splits so results are comparable.\n",
    "- We start with one imbalance strategy at a time, instead of stacking several together. For example:\n",
    "  - Class weighted cross entropy loss  \n",
    "  - No oversampling and no custom sampler in the first iteration\n",
    "\n",
    "**Why this makes sense:**\n",
    "\n",
    "- The architecture is simpler. There are no LoRA adapters and fewer moving parts, which makes debugging easier.\n",
    "- The model has more capacity to adjust to the subtle differences between risky and non risky complaints because all layers can update.\n",
    "\n",
    "\n",
    "In the next cells we will:\n",
    "\n",
    "1. Load full FinBERT with a two class classification head.  \n",
    "2. Define a simple class weighted loss via a custom `Trainer` subclass.  \n",
    "3. Train on the original training set and evaluate on the validation set.  \n",
    "4. Once results look stable, evaluate on the held out test set and compare to the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zRYhgBG5pD3y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7089, 12)\n",
      "Val shape  : (2363, 12)\n",
      "Test shape : (2364, 12)\n",
      "Train label counts:\n",
      " risk_flag\n",
      "0    6743\n",
      "1     346\n",
      "Name: count, dtype: int64\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea5f5629cf94529b44ef57ad080e921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb467bb11de4f4a810258fd31a0f214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a73e8b82100480a959026ed1079e8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea964ea016d34703b71dca7132384d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Project root in Drive\n",
    "colab_dir = \"/content/drive/MyDrive/NLP/respect-cfpb\"\n",
    "\n",
    "# Load pre-split data\n",
    "train_df = pd.read_csv(os.path.join(colab_dir, \"data/processed/train.csv\"))\n",
    "val_df   = pd.read_csv(os.path.join(colab_dir, \"data/processed/val.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(colab_dir, \"data/processed/test.csv\"))\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape  :\", val_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "print(\"Train label counts:\\n\", train_df[\"risk_flag\"].value_counts())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# FinBERT model name\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gpX6dvslpD1h",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf353d9fde01433fa98771bee09bfc81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7089 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b05db4655f4b8b8fc2ba60656edfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f36b967bfd45b5bb43d97aae30cb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2364 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 7089\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2363\n",
      "})\n",
      "Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2364\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert to Dataset and rename label column to \"labels\"\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"clean_text\", \"risk_flag\"]]\n",
    ").rename_column(\"risk_flag\", \"labels\")\n",
    "\n",
    "val_dataset = Dataset.from_pandas(\n",
    "    val_df[[\"clean_text\", \"risk_flag\"]]\n",
    ").rename_column(\"risk_flag\", \"labels\")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"clean_text\", \"risk_flag\"]]\n",
    ").rename_column(\"risk_flag\", \"labels\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"clean_text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"clean_text\"]\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"clean_text\"]\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"clean_text\"]\n",
    ")\n",
    "\n",
    "# Tell datasets to return PyTorch tensors\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "test_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aiYVj_bfpDzG",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: [6743  346]\n",
      "Class weights tensor: tensor([ 1.0513, 20.4884], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Compute class weights from *original* training labels\n",
    "train_labels = train_df[\"risk_flag\"].values\n",
    "class_counts = np.bincount(train_labels)\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "n_total = len(train_labels)\n",
    "weight_for_0 = n_total / class_counts[0]\n",
    "weight_for_1 = n_total / class_counts[1]\n",
    "\n",
    "class_weights = torch.tensor(\n",
    "    [weight_for_0, weight_for_1],\n",
    "    dtype=torch.float32,\n",
    "    device=device\n",
    ")\n",
    "print(\"Class weights tensor:\", class_weights)\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Custom loss: standard cross entropy, but with per-class weights.\n",
    "        \"\"\"\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, model.config.num_labels),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "-NSGul99pDwW",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,                # {0: non-risk, 1: risk}\n",
    "    ignore_mismatched_sizes=True # replace FinBERT's 3-class head\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model loaded on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "y5gdhIk2pDtP",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits to probabilities for class 1\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "\n",
    "    # use 0.5 threshold\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, zero_division=0)\n",
    "    recall = recall_score(labels, preds, zero_division=0)\n",
    "    f1 = f1_score(labels, preds, zero_division=0)\n",
    "\n",
    "    # ROC-AUC based on probabilities\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels, probs)\n",
    "    except ValueError:\n",
    "        roc_auc = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "VTUQwmR_uRQi",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2136468275.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = WeightedTrainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.WeightedTrainer at 0x7d66a046e8d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = os.path.join(\n",
    "    colab_dir,\n",
    "    \"models/finbert_full\"\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"roc_auc\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    gradient_accumulation_steps=2,\n",
    "    seed=42,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "RC7x4zGtuU2A",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1776' max='1776' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1776/1776 10:53, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.537000</td>\n",
       "      <td>0.582137</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.641800</td>\n",
       "      <td>0.497775</td>\n",
       "      <td>0.951333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.577900</td>\n",
       "      <td>0.638445</td>\n",
       "      <td>0.943716</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>0.248588</td>\n",
       "      <td>0.769998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>0.944139</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>0.756951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1776, training_loss=0.5669436486991676, metrics={'train_runtime': 654.3452, 'train_samples_per_second': 43.335, 'train_steps_per_second': 2.714, 'total_flos': 7460777085788160.0, 'train_loss': 0.5669436486991676, 'epoch': 4.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "Y-oYtp44wmjf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (argmax on val):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.960     0.982     0.971      2248\n",
      "           1      0.355     0.191     0.249       115\n",
      "\n",
      "    accuracy                          0.944      2363\n",
      "   macro avg      0.657     0.587     0.610      2363\n",
      "weighted avg      0.930     0.944     0.936      2363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "# Get raw predictions on validation set\n",
    "val_pred = trainer.predict(val_dataset)\n",
    "val_logits = val_pred.predictions\n",
    "val_labels = val_pred.label_ids\n",
    "\n",
    "# Argmax predictions\n",
    "val_argmax = np.argmax(val_logits, axis=1)\n",
    "\n",
    "print(\"\\nClassification report (argmax on val):\")\n",
    "print(classification_report(val_labels, val_argmax, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0YGnrZpmwpuM",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prob(class=1) on val: 0.06309678\n",
      "Min prob(class=1): 0.0054615275\n",
      "Max prob(class=1): 0.76740986\n",
      "t\tF1_1\tP_1\tR_1\n",
      "0.010\t0.119\t0.064\t0.948\n",
      "0.036\t0.195\t0.116\t0.635\n",
      "0.062\t0.230\t0.144\t0.574\n",
      "0.087\t0.229\t0.151\t0.478\n",
      "0.113\t0.248\t0.169\t0.461\n",
      "0.139\t0.249\t0.177\t0.417\n",
      "0.165\t0.255\t0.189\t0.391\n",
      "0.191\t0.260\t0.197\t0.383\n",
      "0.216\t0.276\t0.216\t0.383\n",
      "0.242\t0.270\t0.217\t0.357\n",
      "0.268\t0.278\t0.231\t0.348\n",
      "0.294\t0.290\t0.253\t0.339\n",
      "0.319\t0.293\t0.264\t0.330\n",
      "0.345\t0.303\t0.287\t0.322\n",
      "0.371\t0.304\t0.304\t0.304\n",
      "0.397\t0.314\t0.324\t0.304\n",
      "0.423\t0.315\t0.337\t0.296\n",
      "0.448\t0.317\t0.355\t0.287\n",
      "0.474\t0.281\t0.351\t0.235\n",
      "0.500\t0.249\t0.355\t0.191\n",
      "\n",
      "Best threshold on val: 0.44842105263157894 Best F1_1: 0.3173076923076923\n",
      "Val ROC-AUC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Convert logits to probability for class 1\n",
    "val_probs = torch.softmax(torch.tensor(val_logits), dim=1)[:, 1].numpy()\n",
    "\n",
    "print(\"Mean prob(class=1) on val:\", val_probs.mean())\n",
    "print(\"Min prob(class=1):\", val_probs.min())\n",
    "print(\"Max prob(class=1):\", val_probs.max())\n",
    "\n",
    "def eval_threshold(y_true, y_prob, thr):\n",
    "    preds = (y_prob >= thr).astype(int)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, preds, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    return p, r, f1\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.50, 20)\n",
    "\n",
    "best_thr = None\n",
    "best_f1 = -1\n",
    "print(\"t\\tF1_1\\tP_1\\tR_1\")\n",
    "for t in thresholds:\n",
    "    p, r, f1 = eval_threshold(val_labels, val_probs, t)\n",
    "    print(f\"{t:0.3f}\\t{f1:0.3f}\\t{p:0.3f}\\t{r:0.3f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thr = t\n",
    "\n",
    "try:\n",
    "    val_roc = roc_auc_score(val_labels, val_probs)\n",
    "except ValueError:\n",
    "    val_roc = float(\"nan\")\n",
    "\n",
    "print(\"\\nBest threshold on val:\", best_thr, \"Best F1_1:\", best_f1)\n",
    "print(\"Val ROC-AUC:\", round(val_roc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0UVB48a0BSqi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: /content/drive/MyDrive/NLP/respect-cfpb/models/finbert_full_ep4\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "save_path = \"/content/drive/MyDrive/NLP/respect-cfpb/models/finbert_full_ep4\"\n",
    "\n",
    "trainer.save_model(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(\"Model saved to:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "vf64KoYiBrS2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/NLP/respect-cfpb/models/finbert_full/checkpoint-1332\n"
     ]
    }
   ],
   "source": [
    "print(trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AGCdnI_vCSfI",
   "metadata": {
    "id": "AGCdnI_vCSfI"
   },
   "source": [
    "# Evaluate with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "MahHEK1nCUxW",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "best_ckpt = \"/content/drive/MyDrive/NLP/respect-cfpb/models/finbert_full/checkpoint-1332\"\n",
    "\n",
    "# Load best model and tokenizer\n",
    "test_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt)\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "TCdVMQ36Ca0X",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prob(class=1) on test: 0.06734595\n",
      "Min prob: 0.005443476\n",
      "Max prob: 0.7467611\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc as sk_auc\n",
    "\n",
    "# Use the test_dataset you already built\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # batch is a dict with input_ids, attention_mask, labels\n",
    "        labels = batch[\"labels\"].numpy()\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "        # Move inputs to device\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "\n",
    "        outputs = test_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]  # probability of risk_flag = 1\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"Mean prob(class=1) on test:\", all_probs.mean())\n",
    "print(\"Min prob:\", all_probs.min())\n",
    "print(\"Max prob:\", all_probs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ZKb6h5nsCree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using threshold = 0.448\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.960     0.968     0.964      2248\n",
      "           1      0.263     0.224     0.242       116\n",
      "\n",
      "    accuracy                          0.931      2364\n",
      "   macro avg      0.611     0.596     0.603      2364\n",
      "weighted avg      0.926     0.931     0.928      2364\n",
      "\n",
      "Test ROC-AUC: 0.777\n"
     ]
    }
   ],
   "source": [
    "# Threshold chosen from validation sweep\n",
    "threshold = 0.448\n",
    "\n",
    "test_preds = (all_probs >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nUsing threshold = {threshold}\")\n",
    "print(classification_report(all_labels, test_preds, digits=3))\n",
    "\n",
    "test_roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "print(\"Test ROC-AUC:\", round(test_roc_auc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "BaL3kSMk6AdO",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Counts):\n",
      "[[2175   73]\n",
      " [  90   26]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAHHCAYAAABwaWYjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYnxJREFUeJzt3XlcVFX/B/DPAA4gMCCyjCQCiqIIiksZklsqqFju5lKBYplh5k6aC2iKS2oupVnuD4ZaaT/XRHEN9MmF3ElxwRTQQkBQ1rm/P3y4eb0wMgzI4uf9et1XzLnnnPu9ODlfzzn3jEIQBAFEREREVGIGFR0AERERUVXDBIqIiIhIR0ygiIiIiHTEBIqIiIhIR0ygiIiIiHTEBIqIiIhIR0ygiIiIiHTEBIqIiIhIR0ygiIiIiHTEBIqokrp69Sp8fX1haWkJhUKBHTt2lGn/N2/ehEKhwPr168u036qsY8eO6NixY0WHQURVABMoIi0SEhIwcuRI1K9fHyYmJlCpVPDx8cHSpUvx+PHjcr12QEAAzp8/jzlz5mDTpk1o3bp1uV7vRQoMDIRCoYBKpSry93j16lUoFAooFAp8+eWXOvd/9+5dhIaGIi4urgyifXEK7/l5x+HDh/W+1qNHjxAaGqpTXzdv3sSwYcPQoEEDmJiYQK1Wo3379pg5c2apYtizZw9CQ0NL1ZaoohlVdABEldXu3bsxYMAAGBsb4/3334eHhwdyc3Nx/PhxTJo0CRcvXsTq1avL5dqPHz9GbGwsPv/8c4wePbpcruHk5ITHjx+jRo0a5dL/8xgZGeHRo0fYuXMnBg4cKDkXEREBExMTZGdnl6rvu3fvIiwsDM7OzvDy8ipxu/3795fqemVl06ZNktcbN25EVFSUrLxJkyZ6X+vRo0cICwsDgBKNul27dg2vvvoqTE1NMXz4cDg7OyMpKQlnzpzB/Pnzxb50sWfPHnz99ddMoqhKYgJFVIQbN25g0KBBcHJyQnR0NOrUqSOeCw4OxrVr17B79+5yu/79+/cBAFZWVuV2DYVCARMTk3Lr/3mMjY3h4+ODH374QZZAbd68Gf7+/vjpp59eSCyPHj1CzZo1oVQqX8j1ivPuu+9KXp84cQJRUVGy8oqwZMkSZGZmIi4uDk5OTpJz9+7dq6CoiCoOp/CIirBgwQJkZmZizZo1kuSpkKurKz799FPxdX5+PmbPno0GDRrA2NgYzs7OmDp1KnJyciTtnJ2d0bNnTxw/fhyvvfYaTExMUL9+fWzcuFGsExoaKn5ATZo0CQqFAs7OzgCeTH0V/vy00NBQKBQKSVlUVBTeeOMNWFlZwdzcHG5ubpg6dap4vrg1UNHR0WjXrh3MzMxgZWWFXr164fLly0Ve79q1awgMDISVlRUsLS0xbNgwPHr0qPhf7DOGDBmCvXv3Ii0tTSz7/fffcfXqVQwZMkRWPzU1FRMnToSnpyfMzc2hUqnQvXt3/PHHH2Kdw4cP49VXXwUADBs2TJz2KrzPjh07wsPDA6dPn0b79u1Rs2ZN8ffy7BqogIAAmJiYyO7fz88PtWrVwt27d0t8r2VFo9Hgq6++QtOmTWFiYgJ7e3uMHDkSDx48kNQ7deoU/Pz8YGNjA1NTU7i4uGD48OEAnvzZ29raAgDCwsLE35G2kaCEhATUrVtXljwBgJ2dnaxs79694vvIwsIC/v7+uHjxong+MDAQX3/9NQDp1CVRVcEEiqgIO3fuRP369dG2bdsS1R8xYgRmzJiBli1bYsmSJejQoQPCw8MxaNAgWd1r166hf//+6Nq1KxYtWoRatWohMDBQ/HDp27cvlixZAgAYPHgwNm3ahK+++kqn+C9evIiePXsiJycHs2bNwqJFi/D222/jt99+09ruwIED8PPzw7179xAaGorx48cjJiYGPj4+uHnzpqz+wIED8fDhQ4SHh2PgwIFYv369TlM5ffv2hUKhwM8//yyWbd68GY0bN0bLli1l9a9fv44dO3agZ8+eWLx4MSZNmoTz58+jQ4cOYjLTpEkTzJo1CwDw4YcfYtOmTdi0aRPat28v9vPPP/+ge/fu8PLywldffYVOnToVGd/SpUtha2uLgIAAFBQUAAC+/fZb7N+/H8uXL4eDg0OJ77WsjBw5EpMmTRLX4g0bNgwRERHw8/NDXl4egCcjQr6+vrh58yY+++wzLF++HEOHDsWJEycAALa2tli5ciUAoE+fPuLvqG/fvsVe18nJCbdv30Z0dPRzY9y0aRP8/f1hbm6O+fPnY/r06bh06RLeeOMN8X00cuRIdO3aVaxfeBBVGQIRSaSnpwsAhF69epWoflxcnABAGDFihKR84sSJAgAhOjpaLHNychIACEePHhXL7t27JxgbGwsTJkwQy27cuCEAEBYuXCjpMyAgQHBycpLFMHPmTOHp/52XLFkiABDu379fbNyF11i3bp1Y5uXlJdjZ2Qn//POPWPbHH38IBgYGwvvvvy+73vDhwyV99unTR6hdu3ax13z6PszMzARBEIT+/fsLnTt3FgRBEAoKCgS1Wi2EhYUV+TvIzs4WCgoKZPdhbGwszJo1Syz7/fffZfdWqEOHDgIAYdWqVUWe69Chg6Ts119/FQAIX3zxhXD9+nXB3Nxc6N2793PvsSwEBwdL/lyPHTsmABAiIiIk9fbt2ycp3759uwBA+P3334vt+/79+wIAYebMmSWK5cKFC4KpqakAQPDy8hI+/fRTYceOHUJWVpak3sOHDwUrKyvhgw8+kJQnJycLlpaWkvJn74+oKuEIFNEzMjIyAAAWFhYlqr9nzx4AwPjx4yXlEyZMAADZWil3d3e0a9dOfG1raws3Nzdcv3691DE/q3Dt1C+//AKNRlOiNklJSYiLi0NgYCCsra3F8mbNmqFr167ifT7to48+krxu164d/vnnH/F3WBJDhgzB4cOHkZycjOjoaCQnJxc5fQc8WTdlYPDkr62CggL8888/4vTkmTNnSnxNY2NjDBs2rER1fX19MXLkSMyaNQt9+/aFiYkJvv322xJfqyxt27YNlpaW6Nq1K/7++2/xaNWqFczNzXHo0CEA//7579q1SxyV0lfTpk0RFxeHd999Fzdv3sTSpUvRu3dv2Nvb47vvvhPrRUVFIS0tDYMHD5bEaGhoiDZt2ogxElV1TKCInqFSqQAADx8+LFH9W7duwcDAAK6urpJytVoNKysr3Lp1S1Jer149WR+1atWSrWHRxzvvvAMfHx+MGDEC9vb2GDRoELZu3ao1mSqM083NTXauSZMm+Pvvv5GVlSUpf/ZeatWqBQA63UuPHj1gYWGBLVu2ICIiAq+++qrsd1lIo9FgyZIlaNiwIYyNjWFjYwNbW1ucO3cO6enpJb7mK6+8otOC8S+//BLW1taIi4vDsmXLilzz86z79+8jOTlZdhQ+IFAaV69eRXp6Ouzs7GBrays5MjMzxcXcHTp0QL9+/RAWFgYbGxv06tUL69atk63J01WjRo2wadMm/P333zh37hzmzp0LIyMjfPjhhzhw4IAYIwC8+eabshj379/PBedUbfApPKJnqFQqODg44MKFCzq1K+kCWENDwyLLBUEo9TUK1+cUMjU1xdGjR3Ho0CHs3r0b+/btw5YtW/Dmm29i//79xcagK33upZCxsTH69u2LDRs24Pr161oXMs+dOxfTp0/H8OHDMXv2bFhbW8PAwABjx44t8Ugb8OT3o4uzZ8+KH/znz5/H4MGDn9vm1VdflSXPwJO1REWtJysJjUYDOzs7REREFHm+cGG4QqHAjz/+iBMnTmDnzp349ddfMXz4cCxatAgnTpyAubl5qa5fyNDQEJ6envD09IS3tzc6deqEiIgIdOnSRfxz2LRpE9RqtaytkRE/dqh64DuZqAg9e/bE6tWrERsbC29vb611nZycoNFocPXqVcn+PCkpKUhLSyvyqaXSqlWrluSJtUJFfVAbGBigc+fO6Ny5MxYvXoy5c+fi888/x6FDh9ClS5ci7wMA4uPjZeeuXLkCGxsbmJmZ6X8TRRgyZAjWrl0LAwODIhfeF/rxxx/RqVMnrFmzRlKelpYGGxsb8XVZPs2VlZWFYcOGwd3dHW3btsWCBQvQp08f8Um/4kRERBS5SaiuydvTGjRogAMHDsDHx6dE/bz++ut4/fXXMWfOHGzevBlDhw5FZGQkRowYUWa/o8INXpOSksQYgSdP5hX1Pnsan7qjqoxTeERFmDx5MszMzDBixAikpKTIzickJGDp0qUAnkxBAZA9Kbd48WIAgL+/f5nF1aBBA6Snp+PcuXNiWVJSErZv3y6pl5qaKmtbuKFkcdM4derUgZeXFzZs2CBJ0i5cuID9+/eL91keOnXqhNmzZ2PFihVFjloUMjQ0lI1ubdu2DXfu3JGUFSZ6RSWbugoJCUFiYiI2bNiAxYsXw9nZGQEBAc+dDvPx8UGXLl1kh4+PT6ljGThwIAoKCjB79mzZufz8fPF+Hzx4IPs9PfvnX7NmTQAl/x0dO3asyPVUhWvjCqd+/fz8oFKpMHfu3CLrPz2FWZZ/TkQvGkegiIrQoEEDbN68Ge+88w6aNGki2Yk8JiYG27ZtQ2BgIACgefPmCAgIwOrVq5GWloYOHTrgv//9LzZs2IDevXsX+4h8aQwaNAghISHo06cPxowZg0ePHmHlypVo1KiRZBH1rFmzcPToUfj7+8PJyQn37t3DN998g7p16+KNN94otv+FCxeie/fu8Pb2RlBQEB4/fozly5fD0tKyXHeLNjAwwLRp055br2fPnpg1axaGDRuGtm3b4vz584iIiED9+vUl9Ro0aAArKyusWrUKFhYWMDMzQ5s2beDi4qJTXNHR0fjmm28wc+ZMcVuFdevWoWPHjpg+fToWLFigU3/66tChA0aOHInw8HDExcXB19cXNWrUwNWrV7Ft2zYsXboU/fv3x4YNG/DNN9+gT58+aNCgAR4+fIjvvvsOKpVKTIRNTU3h7u6OLVu2oFGjRrC2toaHhwc8PDyKvPb8+fNx+vRp9O3bF82aNQMAnDlzBhs3boS1tTXGjh0L4MkU+MqVK/Hee++hZcuWGDRoEGxtbZGYmIjdu3fDx8cHK1asAAC0atUKADBmzBj4+fnB0NBQ6wgkUaVSsQ8BElVuf/75p/DBBx8Izs7OglKpFCwsLAQfHx9h+fLlQnZ2tlgvLy9PCAsLE1xcXIQaNWoIjo6OwpQpUyR1BOHJNgb+/v6y6zz7+Hxx2xgIgiDs379f8PDwEJRKpeDm5ib85z//kW1jcPDgQaFXr16Cg4ODoFQqBQcHB2Hw4MHCn3/+KbvGs4/6HzhwQPDx8RFMTU0FlUolvPXWW8KlS5ckdQqv9+w2CevWrRMACDdu3Cj2dyoI0m0MilPcNgYTJkwQ6tSpI5iamgo+Pj5CbGxskdsP/PLLL4K7u7tgZGQkuc8OHToITZs2LfKaT/eTkZEhODk5CS1bthTy8vIk9caNGycYGBgIsbGxWu9BX8U95r969WqhVatWgqmpqWBhYSF4enoKkydPFu7evSsIgiCcOXNGGDx4sFCvXj3B2NhYsLOzE3r27CmcOnVK0k9MTIzQqlUrQalUPndLg99++00IDg4WPDw8BEtLS6FGjRpCvXr1hMDAQCEhIUFW/9ChQ4Kfn59gaWkpmJiYCA0aNBACAwMlMeTn5wuffPKJYGtrKygUCm5pQFWKQhB0WO1JRERERFwDRURERKQrJlBEREREOmICRURERKQjJlBEREREOmICRURERKQjJlBEREREOuJGmi8ZjUaDu3fvwsLCgl+jQERUxQiCgIcPH8LBwQEGBuU3BpKdnY3c3Fy9+1EqlTAxMSmDiCofJlAvmbt378LR0bGiwyAiIj3cvn0bdevWLZe+s7Oz4eJkjuR7Bc+v/BxqtRo3btyolkkUE6iXjIWFBQDg1hlnqMw5g0vVU1/P1hUdAlG5yBfycCx3u/h3eXnIzc1F8r0C3DrtDJVF6T8nMh5q4NTqJnJzc5lAUdVXOG2nMjfQ638MosrMSFGjokMgKlcvYgmGuYUC5halv44G1XuZCBMoIiIikikQNCjQ48veCgRN2QVTCTGBIiIiIhkNBGhQ+gxKn7ZVAedwiIiIiHTEESgiIiKS0UADfSbh9Gtd+TGBIiIiIpkCQUCBUPppOH3aVgWcwiMiIiLSEUegiIiISIaLyLVjAkVEREQyGggoYAJVLE7hEREREemII1BEREQkwyk87ZhAERERkQyfwtOOU3hEREREOuIIFBEREclo/nfo0746YwJFREREMgV6PoWnT9uqgAkUERERyRQITw592ldnXANFREREpCOOQBEREZEM10BpxwSKiIiIZDRQoAAKvdpXZ5zCIyIiItIRR6CIiIhIRiM8OfRpX50xgSIiIiKZAj2n8PRpWxVwCo+IiIhIRxyBIiIiIhmOQGnHESgiIiKS0QgKvQ9dhIeH49VXX4WFhQXs7OzQu3dvxMfHS+pkZ2cjODgYtWvXhrm5Ofr164eUlBRJncTERPj7+6NmzZqws7PDpEmTkJ+fL6lz+PBhtGzZEsbGxnB1dcX69et1/v0wgSIiIqIKd+TIEQQHB+PEiROIiopCXl4efH19kZWVJdYZN24cdu7ciW3btuHIkSO4e/cu+vbtK54vKCiAv78/cnNzERMTgw0bNmD9+vWYMWOGWOfGjRvw9/dHp06dEBcXh7Fjx2LEiBH49ddfdYpXIQhCNV8nT0/LyMiApaUlHvxZHyoL5s9UPXVzaVPRIRCVi3whD4dytiI9PR0qlapcrlH4OXHkwisw1+NzIvOhBh087pQ61vv378POzg5HjhxB+/btkZ6eDltbW2zevBn9+/cHAFy5cgVNmjRBbGwsXn/9dezduxc9e/bE3bt3YW9vDwBYtWoVQkJCcP/+fSiVSoSEhGD37t24cOGCeK1BgwYhLS0N+/btK3F8/AQlIiIimQIY6H0ATxKyp4+cnJwSXT89PR0AYG1tDQA4ffo08vLy0KVLF7FO48aNUa9ePcTGxgIAYmNj4enpKSZPAODn54eMjAxcvHhRrPN0H4V1CvsoKSZQREREJCPouf5J+N8aKEdHR1haWopHeHj4c6+t0WgwduxY+Pj4wMPDAwCQnJwMpVIJKysrSV17e3skJyeLdZ5OngrPF57TVicjIwOPHz8u8e+HT+ERERFRubl9+7ZkCs/Y2Pi5bYKDg3HhwgUcP368PEPTCxMoIiIikimrbQxUKpVOa6BGjx6NXbt24ejRo6hbt65YrlarkZubi7S0NMkoVEpKCtRqtVjnv//9r6S/wqf0nq7z7JN7KSkpUKlUMDU1LXGcnMIjIiIimQLBQO9DF4IgYPTo0di+fTuio6Ph4uIiOd+qVSvUqFEDBw8eFMvi4+ORmJgIb29vAIC3tzfOnz+Pe/fuiXWioqKgUqng7u4u1nm6j8I6hX2UFEegiIiIqMIFBwdj8+bN+OWXX2BhYSGuWbK0tISpqSksLS0RFBSE8ePHw9raGiqVCp988gm8vb3x+uuvAwB8fX3h7u6O9957DwsWLEBycjKmTZuG4OBgcerwo48+wooVKzB58mQMHz4c0dHR2Lp1K3bv3q1TvEygiIiISEYDBTR6TFRpoNsuSStXrgQAdOzYUVK+bt06BAYGAgCWLFkCAwMD9OvXDzk5OfDz88M333wj1jU0NMSuXbswatQoeHt7w8zMDAEBAZg1a5ZYx8XFBbt378a4ceOwdOlS1K1bF99//z38/Px0ipf7QL1kuA8UvQy4DxRVVy9yH6j/O9cAZhaGpe4n62EB3m6WUK6xViR+ghIRERHpiFN4REREJFOaheDS9tV7gosJFBEREck8WQNV+m0M9GlbFXAKj4iIiEhHHIEiIiIiGc1T32dXuvacwiMiIqKXDNdAaccEioiIiGQ0MHih+0BVNVwDRURERKQjjkARERGRTIGgQIGgx5cJ69G2KmACRURERDIFei4iL+AUHhERERE9jSNQREREJKMRDKDR4yk8DZ/CIyIiopcNp/C04xQeERERkY44AkVEREQyGuj3JJ2m7EKplJhAERERkYz+G2lW70mu6n13REREROWAI1BEREQko/934VXvMRomUERERCSjgQIa6LMGijuRExER0UuGI1DaVe+7IyIiIioHHIEiIiIiGf030qzeYzRMoIiIiEhGIyig0WcfKD3aVgXVOz0kIiIiKgccgSIiIiIZjZ5TeNV9I00mUERERCSjEQyg0eNJOn3aVgXV++6IiIiIygFHoIiIiEimAAoU6LEZpj5tqwImUERERCTDKTztqvfdEREREZUDjkARERGRTAH0m4YrKLtQKiUmUERERCTDKTztqvfdERERUakUfpmwPoeujh49irfeegsODg5QKBTYsWOH5LxCoSjyWLhwoVjH2dlZdn7evHmSfs6dO4d27drBxMQEjo6OWLBggc6xMoEiIiKiSiErKwvNmzfH119/XeT5pKQkybF27VooFAr069dPUm/WrFmSep988ol4LiMjA76+vnBycsLp06excOFChIaGYvXq1TrFyik8IiIikhGggEaPNVBCKdp2794d3bt3L/a8Wq2WvP7ll1/QqVMn1K9fX1JuYWEhq1soIiICubm5WLt2LZRKJZo2bYq4uDgsXrwYH374YYlj5QgUERERyZTVFF5GRobkyMnJKZP4UlJSsHv3bgQFBcnOzZs3D7Vr10aLFi2wcOFC5Ofni+diY2PRvn17KJVKsczPzw/x8fF48OBBia/PBIqIiIjKjaOjIywtLcUjPDy8TPrdsGEDLCws0LdvX0n5mDFjEBkZiUOHDmHkyJGYO3cuJk+eLJ5PTk6Gvb29pE3h6+Tk5BJfn1N4REREJKMRFNAIpZ/CK2x7+/ZtqFQqsdzY2Fjv2ABg7dq1GDp0KExMTCTl48ePF39u1qwZlEolRo4cifDw8DK7NsAEioiIiIpQAAMU6DFRVdhWpVJJEqiycOzYMcTHx2PLli3PrdumTRvk5+fj5s2bcHNzg1qtRkpKiqRO4evi1k0VhVN4REREVKWsWbMGrVq1QvPmzZ9bNy4uDgYGBrCzswMAeHt74+jRo8jLyxPrREVFwc3NDbVq1SpxDEygiIiISKZwCk+fQ1eZmZmIi4tDXFwcAODGjRuIi4tDYmKiWCcjIwPbtm3DiBEjZO1jY2Px1Vdf4Y8//sD169cRERGBcePG4d133xWToyFDhkCpVCIoKAgXL17Eli1bsHTpUsnUX0lwCo+IiIhkNDCARo9xltK0PXXqFDp16iS+LkxqAgICsH79egBAZGQkBEHA4MGDZe2NjY0RGRmJ0NBQ5OTkwMXFBePGjZMkR5aWlti/fz+Cg4PRqlUr2NjYYMaMGTptYQAACkEQBJ3vkKqsjIwMWFpa4sGf9aGy4AAkVU/dXNpUdAhE5SJfyMOhnK1IT08v83VFhQo/J0Yf7wNj8xql7icnMw8r3therrFWJI5AERERkUyBoECBHk/h6dO2KmACRURERDJltY1BdcUEioiIiGQEwQCaUnwh8NPtq7PqfXdERERE5YAjUERERCRTAAUK9PgyYX3aVgVMoIiIiEhGI+i3jklTzZ/x5xQeERERkY44AkWkReRyO/y2xwq3rxlDaaKBe+tHCPr8Lhxdc8Q6e/5TG4e218K186Z4lGmIny6fh7llgXj+jxhzTO7vWmT/y/bEw83rMZJvKxHQxl12/qudf6JJq0dlf2NEOthwLA72dXNl5Ts32eHrGc4YM+cGvHwyUNs+F4+zDHH5jDnWzHPEX9dNKyBaKisaPReR69O2KmACVQKBgYFIS0vDjh07yrTu09asWYMtW7Zg//79JW7z+uuvY9KkSejXr59O16KSOxdrjrcC/0Yjr0coyAfWz6uDqYMb4LsjV2BSUwMAyH5sgNYdM9C6YwbWhjvI+nBvnYUf4i5IyjYsqIO44+Zo1PyxpHzelmtwcssWX6tq5ZfDXRHpZkyvpjAw+Hc+xtntMcL/E49ju60BAFcvmCH6l9q4f8cYFlb5eHfsHczdGI/A9s2h0VTvdTDVmQYKaPRYx6RP26qgQtPDwMBAKBQKzJs3T1K+Y8cOKBTl/4u/efMmFAqFeFhbW6NDhw44duyYpN7SpUvFLeTLQ3Z2NqZPn46ZM2dKyrdt24bGjRvDxMQEnp6e2LNnj+T8tGnT8Nlnn0Gj0ZRbbC+7uZuvw/edVDi7ZaNB02xM+CoR9+4ocfXcv/+y7vvBfbzzyT00LmakqIZSgLVdvnioauUj9lcVfN9JxbNvc1WtAkldo9JvAkxUZtJTa+DB30rxeO3NNNy9aYxzJy0AAHt/sMOF/6qQcscY1y6aYcOiurB7JRf2dXOe0zNR1VXh42smJiaYP38+Hjx4UGExHDhwAElJSTh69CgcHBzQs2dPpKSkiOctLS1hZWVVbtf/8ccfoVKp4OPjI5bFxMRg8ODBCAoKwtmzZ9G7d2/07t0bFy78O5LRvXt3PHz4EHv37i232EgqK8MQAGBhVfCcmsWL3W+Jhw+M4PtOquzczEAXDPRsivG9XBH7a/X76gOq+oxqaPBm73/w6zZboIgRBmPTAnTtfx9Jica4n6R88QFSmSnciVyfozqr8ASqS5cuUKvVCA8P11rvp59+QtOmTWFsbAxnZ2csWrRIct7Z2Rlz587F8OHDYWFhgXr16mH16tUliqF27dpQq9Xw8PDA1KlTkZGRgZMnT4rnAwMD0bt3b/H1jz/+CE9PT5iamqJ27dro0qULsrKyiuz7999/h62tLebPn1/s9SMjI/HWW29JypYuXYpu3bph0qRJaNKkCWbPno2WLVtixYoVYh1DQ0P06NEDkZGRJbpP0o9GA6ya+QqavpoJ58bZz29QjF9/qI1WHR/C1iFPLDOtWYAPZ97BtNU3MXvTdTR9LQthw12YRFGl4+37AOaqfET9aCMp7/luCrZfOIVfLp3Gqx3TMfU9N+TnVfhHDOmhcA2UPkd1VuF3Z2hoiLlz52L58uX466+/iqxz+vRpDBw4EIMGDcL58+cRGhqK6dOny6bVFi1ahNatW+Ps2bP4+OOPMWrUKMTHx5c4lsePH2Pjxo0AAKWy6H85JSUlYfDgwRg+fDguX76Mw4cPo2/fvijqO5mjo6PRtWtXzJkzByEhIcVe9/jx42jdurWkLDY2Fl26dJGU+fn5ITY2VlL22muvyaYcn5aTk4OMjAzJQaWzYmpd3Lpiiikrb5W6j/t3a+D0YQv4Df5HUm5ZuwD9Rt5H45aP4Ob1GEGfJ+HNfg+wbaWdvmETlaluA+/j9yNWSL0n/Tsy+pfaCO7pgYnvNMadGyaYuuIaaii5vICqr0qxiLxPnz7w8vLCzJkzsWbNGtn5xYsXo3Pnzpg+fToAoFGjRrh06RIWLlyIwMBAsV6PHj3w8ccfAwBCQkKwZMkSHDp0CG5ublqv37ZtWxgYGODRo0cQBAGtWrVC586di6yblJSE/Px89O3bF05OTgAAT09PWb3t27fj/fffx/fff4933nmn2GunpaUhPT0dDg7SxcfJycmwt7eXlNnb2yM5OVlS5uDggNu3b0Oj0cDAQJ4Ph4eHIywsrNjrU8msmPoKTkapsGj7NcnIka72b7GGRa18ePumP7du4xaPcPaoRamvRVTW7F7JgZdPBmaPaig79+ihER49NMLdmya4ctYcP8adgY/fAxzeWbsCIqWyoIGe34XHReQvxvz587FhwwZcvnxZdu7y5cuS9UEA4OPjg6tXr6Kg4N+1KM2aNRN/VigUUKvVuHfvHoAn64XMzc1hbm6Opk2bSvrasmULzp49i59++gmurq5Yv349atQoevVu8+bN0blzZ3h6emLAgAH47rvvZOu3Tp48iQEDBmDTpk1akyfgyagX8GQtWGmYmppCo9EgJ6foxZpTpkxBenq6eNy+fbtU13lZCcKT5ClmnyUWbLsGdT35o9y69LV/izW69H9QosXhCRdNYW1X+mSNqKz59r+P9H9q4L/RVlrrKRQAFOAIVBUn/O8pvNIeQjVPoCrFCBQAtG/fHn5+fpgyZYpkVEkXzyY9CoVCfELt+++/F5OVZ+s5OjqiYcOGaNiwIfLz89GnTx9cuHABxsbGsmsYGhoiKioKMTEx2L9/P5YvX47PP/8cJ0+ehIuLCwCgQYMGqF27NtauXQt/f/9ikzHgyforhUIhS8LUarVkITsApKSkQK1WS8pSU1NhZmYGU9Oi91sxNjYu8j6oZFZMrYtD22shdN11mJprkHrvyf8yZhYFMDZ9Mm2bes8ID+7VwN0bT6Y0blwxQU0zDWxfyYWq1r8JftxxcyQnGqPbkH9k14naWgtGNQQ08HjyHv1tryX2R1pj7JdMeKlyUCgEdB3wN6J+soGm4N8PRrVjNjr0TMXpY5ZITzWCjToX74xKQm62Av89bFVxAZPeNIKeI1BcRP7izJs3Dzt37pSt82nSpAl+++03Sdlvv/2GRo0awdDQsER9v/LKK3B1dYWrq6s49VaU/v37w8jICN98802xdRQKBXx8fBAWFoazZ89CqVRi+/bt4nkbGxtER0fj2rVrGDhwIPLyih9FUCqVcHd3x6VLlyTl3t7eOHjwoKQsKioK3t7ekrILFy6gRYsWxfZP+tm1wQZZGYaY1K8hBnt5iMeR/6sl1tm90QYf+7rhq0n1AAAT+zTEx75uOLHfUtLXvh9qw711Juo1LHq0cPNXaozu1gif9myE2F8tMXXVTfgNkj+pR1QRWryRAftXcrF/m3TxeG6OAZq++hCz18Vj7aFzmLo8AY8yDTG+vzvS/+E+HFR9VZoRKODJWqKhQ4di2bJlkvIJEybg1VdfxezZs/HOO+8gNjYWK1as0JrklJZCocCYMWMQGhqKkSNHombNmpLzJ0+exMGDB+Hr6ws7OzucPHkS9+/fR5MmTST17OzsEB0djU6dOmHw4MGIjIyEkVHRv24/Pz8cP34cY8eOFcs+/fRTdOjQAYsWLYK/vz8iIyNx6tQp2ZOFx44dg6+vb9ncPMn8ejfuuXXem5iM9yYmP7felG+KX3zedeADdB1YcVt5ED3PmWOW6Obymqw89Z4SM4ZrX2dKVRN3Iteu0t3drFmzZBtDtmzZElu3bkVkZCQ8PDwwY8YMzJo1q9RTfc8TEBCAvLw8yZYBhVQqFY4ePYoePXqgUaNGmDZtGhYtWoTu3bvL6qrVakRHR+P8+fMYOnSoZL3W04KCgrBnzx6kp/+7sLht27bYvHkzVq9ejebNm+PHH3/Ejh074OHhIda5c+cOYmJiMGzYsDK4ayIion8VTuHpc1RnCqGo5+/phRswYABatmyJKVOmlLhNSEgIHjx4UOL9rgAgIyMDlpaWePBnfagsKl3+TFQmurm0qegQiMpFvpCHQzlbkZ6eDpWqfPaJK/yc6LV/OGqYlX4z1LysXPziu7ZcY61I/AStJBYuXAhzc3Od2tjZ2WH27NnlFBEREb3M9HkCT9/v0asKKtUaqJeZs7MzPvnkE53aTJgwoZyiISKilx2fwtOOI1BEREREOuIIFBEREclwBEo7JlBEREQkwwRKO07hEREREemII1BEREQkwxEo7ZhAERERkYwA6LUVQXXfZJIJFBEREclwBEo7roEiIiIi0hFHoIiIiEiGI1DaMYEiIiIiGSZQ2nEKj4iIiCqFo0eP4q233oKDgwMUCgV27NghOR8YGAiFQiE5unXrJqmTmpqKoUOHQqVSwcrKCkFBQcjMzJTUOXfuHNq1awcTExM4OjpiwYIFOsfKBIqIiIhkCkeg9Dl0lZWVhebNm+Prr78utk63bt2QlJQkHj/88IPk/NChQ3Hx4kVERUVh165dOHr0KD788EPxfEZGBnx9feHk5ITTp09j4cKFCA0NxerVq3WKlVN4REREJCMICgh6TMOVpm337t3RvXt3rXWMjY2hVquLPHf58mXs27cPv//+O1q3bg0AWL58OXr06IEvv/wSDg4OiIiIQG5uLtauXQulUommTZsiLi4OixcvliRaz8MRKCIiIio3GRkZkiMnJ0ev/g4fPgw7Ozu4ublh1KhR+Oeff8RzsbGxsLKyEpMnAOjSpQsMDAxw8uRJsU779u2hVCrFOn5+foiPj8eDBw9KHAcTKCIiIpLRQKH3AQCOjo6wtLQUj/Dw8FLH1K1bN2zcuBEHDx7E/PnzceTIEXTv3h0FBQUAgOTkZNjZ2UnaGBkZwdraGsnJyWIde3t7SZ3C14V1SoJTeERERCRTVk/h3b59GyqVSiw3NjYudZ+DBg0Sf/b09ESzZs3QoEEDHD58GJ07dy51v6XBESgiIiIqNyqVSnLok0A9q379+rCxscG1a9cAAGq1Gvfu3ZPUyc/PR2pqqrhuSq1WIyUlRVKn8HVxa6uKwgSKiIiIZAoXketzlLe//voL//zzD+rUqQMA8Pb2RlpaGk6fPi3WiY6OhkajQZs2bcQ6R48eRV5enlgnKioKbm5uqFWrVomvzQSKiIiIZCpiG4PMzEzExcUhLi4OAHDjxg3ExcUhMTERmZmZmDRpEk6cOIGbN2/i4MGD6NWrF1xdXeHn5wcAaNKkCbp164YPPvgA//3vf/Hbb79h9OjRGDRoEBwcHAAAQ4YMgVKpRFBQEC5evIgtW7Zg6dKlGD9+vE6xcg0UERERyVTENganTp1Cp06dxNeFSU1AQABWrlyJc+fOYcOGDUhLS4ODgwN8fX0xe/ZsybRgREQERo8ejc6dO8PAwAD9+vXDsmXLxPOWlpbYv38/goOD0apVK9jY2GDGjBk6bWEAMIEiIiKiSqJjx44QBKHY87/++utz+7C2tsbmzZu11mnWrBmOHTumc3xPYwJFREREMoKeT+G9iDVQFYkJFBEREckIALQMBpWofXXGReREREREOuIIFBEREclooIACemykqUfbqoAJFBEREclUxFN4VQmn8IiIiIh0xBEoIiIiktEICijK4LvwqismUERERCQjCHo+hVfNH8PjFB4RERGRjjgCRURERDJcRK4dEygiIiKSYQKlHRMoIiIikuEicu24BoqIiIhIRxyBIiIiIhk+hacdEygiIiKSeZJA6bMGqgyDqYQ4hUdERESkI45AERERkQyfwtOOCRQRERHJCP879GlfnXEKj4iIiEhHHIEiIiIiGU7haccEioiIiOQ4h6cVEygiIiKS03MECtV8BIproIiIiIh0xBEoIiIikuFO5NoxgSIiIiIZLiLXjlN4RERERDriCBQRERHJCQr9FoJX8xEoJlBEREQkwzVQ2nEKj4iIiEhHHIEiIiIiOW6kqVWJEqj/+7//K3GHb7/9dqmDISIiosqBT+FpV6IEqnfv3iXqTKFQoKCgQJ94iIiIiCq9Eq2B0mg0JTqYPBEREVUjgh5HKRw9ehRvvfUWHBwcoFAosGPHDvFcXl4eQkJC4OnpCTMzMzg4OOD999/H3bt3JX04OztDoVBIjnnz5knqnDt3Du3atYOJiQkcHR2xYMECnWPVaxF5dna2Ps2JiIiokiqcwtPn0FVWVhaaN2+Or7/+Wnbu0aNHOHPmDKZPn44zZ87g559/Rnx8fJFLh2bNmoWkpCTx+OSTT8RzGRkZ8PX1hZOTE06fPo2FCxciNDQUq1ev1ilWnReRFxQUYO7cuVi1ahVSUlLw559/on79+pg+fTqcnZ0RFBSka5dERERU2VTAIvLu3buje/fuRZ6ztLREVFSUpGzFihV47bXXkJiYiHr16onlFhYWUKvVRfYTERGB3NxcrF27FkqlEk2bNkVcXBwWL16MDz/8sMSx6jwCNWfOHKxfvx4LFiyAUqkUyz08PPD999/r2h0RERFVYxkZGZIjJyenzPpOT0+HQqGAlZWVpHzevHmoXbs2WrRogYULFyI/P188Fxsbi/bt20tyGD8/P8THx+PBgwclvrbOCdTGjRuxevVqDB06FIaGhmJ58+bNceXKFV27IyIiokpJUQYH4OjoCEtLS/EIDw8vk+iys7MREhKCwYMHQ6VSieVjxoxBZGQkDh06hJEjR2Lu3LmYPHmyeD45ORn29vaSvgpfJycnl/j6Ok/h3blzB66urrJyjUaDvLw8XbsjIiKiyqiMpvBu374tSXCMjY31Cgt4sqB84MCBEAQBK1eulJwbP368+HOzZs2gVCoxcuRIhIeHl8m1C+k8AuXu7o5jx47Jyn/88Ue0aNGiTIIiIiKi6kGlUkkOfZOYwuTp1q1biIqKkiRnRWnTpg3y8/Nx8+ZNAIBarUZKSoqkTuHr4tZNFUXnEagZM2YgICAAd+7cgUajEVfBb9y4Ebt27dK1OyIiIqqMKuFO5IXJ09WrV3Ho0CHUrl37uW3i4uJgYGAAOzs7AIC3tzc+//xz5OXloUaNGgCAqKgouLm5oVatWiWORecRqF69emHnzp04cOAAzMzMMGPGDFy+fBk7d+5E165dde2OiIiIKiNBof+ho8zMTMTFxSEuLg4AcOPGDcTFxSExMRF5eXno378/Tp06hYiICBQUFCA5ORnJycnIzc0F8GSB+FdffYU//vgD169fR0REBMaNG4d3331XTI6GDBkCpVKJoKAgXLx4EVu2bMHSpUslU38lUarvwmvXrp3sUUIiIiIifZw6dQqdOnUSXxcmNQEBAQgNDRW/Ws7Ly0vS7tChQ+jYsSOMjY0RGRmJ0NBQ5OTkwMXFBePGjZMkR5aWlti/fz+Cg4PRqlUr2NjYYMaMGTptYQDo8WXCp06dwuXLlwE8WRfVqlWr0nZFRERElYwgPDn0aa+rjh07QtDSUNs5AGjZsiVOnDjx3Os0a9asyPXcutA5gfrrr78wePBg/Pbbb+K+C2lpaWjbti0iIyNRt25dvQIiIiKiSqASroGqTHReAzVixAjk5eXh8uXLSE1NRWpqKi5fvgyNRoMRI0aUR4xERERElYrOI1BHjhxBTEwM3NzcxDI3NzcsX74c7dq1K9PgiIiIqIKUciG4pH01pnMC5ejoWOSGmQUFBXBwcCiToIiIiKhiKYQnhz7tqzOdp/AWLlyITz75BKdOnRLLTp06hU8//RRffvllmQZHREREFUQog6MaK9EIVK1ataBQ/DsUl5WVhTZt2sDI6Enz/Px8GBkZYfjw4ejdu3e5BEpERERUWZQogfrqq6/KOQwiIiKqVLgGSqsSJVABAQHlHQcRERFVJtzGQKtSb6QJANnZ2eL26YWe96V+RERERFWdzovIs7KyMHr0aNjZ2cHMzAy1atWSHERERFQNcBG5VjonUJMnT0Z0dDRWrlwJY2NjfP/99wgLC4ODgwM2btxYHjESERHRi8YESiudp/B27tyJjRs3omPHjhg2bBjatWsHV1dXODk5ISIiAkOHDi2POImIiIgqDZ1HoFJTU1G/fn0AT9Y7paamAgDeeOMNHD16tGyjIyIioopR+BSePkc1pnMCVb9+fdy4cQMA0LhxY2zduhXAk5Gpwi8XJiIioqqtcCdyfY7qTOcEatiwYfjjjz8AAJ999hm+/vprmJiYYNy4cZg0aVKZB0hERERU2ei8BmrcuHHiz126dMGVK1dw+vRpuLq6olmzZmUaHBEREVUQ7gOllV77QAGAk5MTnJycyiIWIiIioiqhRAnUsmXLStzhmDFjSh0MERERVQ4K6LeOqXovIS9hArVkyZISdaZQKJhAERERUbVXogSq8Kk7qj76eb0GI4WyosMgKhdCzqOKDoGoXAhC3gu8GL9MWBu910ARERFRNcRF5FrpvI0BERER0cuOI1BEREQkxxEorZhAERERkYy+u4lzJ3IiIiIikihVAnXs2DG8++678Pb2xp07dwAAmzZtwvHjx8s0OCIiIqogQhkc1ZjOCdRPP/0EPz8/mJqa4uzZs8jJyQEApKenY+7cuWUeIBEREVUAJlBa6ZxAffHFF1i1ahW+++471KhRQyz38fHBmTNnyjQ4IiIiospI50Xk8fHxaN++vazc0tISaWlpZRETERERVTAuItdO5xEotVqNa9euycqPHz+O+vXrl0lQREREVMEKdyLX56jGdE6gPvjgA3z66ac4efIkFAoF7t69i4iICEycOBGjRo0qjxiJiIjoReMaKK10nsL77LPPoNFo0LlzZzx69Ajt27eHsbExJk6ciE8++aQ8YiQiIiKqVHQegVIoFPj888+RmpqKCxcu4MSJE7h//z5mz55dHvERERFRBShcA6XPoaujR4/irbfegoODAxQKBXbs2CE5LwgCZsyYgTp16sDU1BRdunTB1atXJXVSU1MxdOhQqFQqWFlZISgoCJmZmZI6586dQ7t27WBiYgJHR0csWLBA51hLvZGmUqmEu7s7XnvtNZibm5e2GyIiIqqMKmAKLysrC82bN8fXX39d5PkFCxZg2bJlWLVqFU6ePAkzMzP4+fkhOztbrDN06FBcvHgRUVFR2LVrF44ePYoPP/xQPJ+RkQFfX184OTnh9OnTWLhwIUJDQ7F69WqdYtV5Cq9Tp05QKIpfGBYdHa1rl0RERETo3r07unfvXuQ5QRDw1VdfYdq0aejVqxcAYOPGjbC3t8eOHTswaNAgXL58Gfv27cPvv/+O1q1bAwCWL1+OHj164Msvv4SDgwMiIiKQm5uLtWvXQqlUomnTpoiLi8PixYslidbz6DwC5eXlhebNm4uHu7s7cnNzcebMGXh6euraHREREVVG+k7f/W8EKiMjQ3IUbsCtqxs3biA5ORldunQRyywtLdGmTRvExsYCAGJjY2FlZSUmTwDQpUsXGBgY4OTJk2Kd9u3bQ6lUinX8/PwQHx+PBw8elDgenUeglixZUmR5aGiobI6RiIiIqih9n6T7X1tHR0dJ8cyZMxEaGqpzd8nJyQAAe3t7Sbm9vb14Ljk5GXZ2dpLzRkZGsLa2ltRxcXGR9VF4rlatWiWKR+cEqjjvvvsuXnvtNXz55Zdl1SURERFVcbdv34ZKpRJfGxsbV2A0ZafUi8ifFRsbCxMTk7LqjoiIiCpSGS0iV6lUkqO0CZRarQYApKSkSMpTUlLEc2q1Gvfu3ZOcz8/PR2pqqqROUX08fY2S0HkEqm/fvpLXgiAgKSkJp06dwvTp03XtjoiIiCqhyvZVLi4uLlCr1Th48CC8vLwAPFlfdfLkSXEjb29vb6SlpeH06dNo1aoVgCcPt2k0GrRp00as8/nnnyMvL0/8Tt+oqCi4ubmVePoOKEUCZWlpKXltYGAANzc3zJo1C76+vrp2R0RERAQAyMzMlHxd3I0bNxAXFwdra2vUq1cPY8eOxRdffIGGDRvCxcUF06dPh4ODA3r37g0AaNKkCbp164YPPvgAq1atQl5eHkaPHo1BgwbBwcEBADBkyBCEhYUhKCgIISEhuHDhApYuXVrsGu/i6JRAFRQUYNiwYfD09NQpSyMiIiJ6nlOnTqFTp07i6/HjxwMAAgICsH79ekyePBlZWVn48MMPkZaWhjfeeAP79u2TLCGKiIjA6NGj0blzZxgYGKBfv35YtmyZeN7S0hL79+9HcHAwWrVqBRsbG8yYMUOnLQwAQCEIgk6DbCYmJrh8+bJsBTtVDRkZGbC0tMSbNQfBSKF8fgOiKkjz6FFFh0BULvKFPBzGL0hPT5cszC5LhZ8TDabMhaEea5sLsrORED61XGOtSDovIvfw8MD169fLIxYiIiKqJCriq1yqEp0TqC+++AITJ07Erl27kJSUJNsgi4iIiKi6K/EaqFmzZmHChAno0aMHAODtt9+WfKWLIAhQKBQoKCgo+yiJiIjoxavmo0j6KHECFRYWho8++giHDh0qz3iIiIioMiijncirqxInUIVrzTt06FBuwRARERFVBTptY/D0lB0RERFVX5VtI83KRqcEqlGjRs9NolJTU/UKiIiIiCoBTuFppVMCFRYWJtuJnIiIiOhlo1MCNWjQINjZ2ZVXLERERFRJcApPuxInUFz/RERE9BLhFJ5WJd5IU8dvfCEiIiKqtko8AqXRaMozDiIiIqpMOAKllU5roIiIiOjlwDVQ2jGBIiIiIjmOQGml85cJExEREb3sOAJFREREchyB0ooJFBEREclwDZR2nMIjIiIi0hFHoIiIiEiOU3haMYEiIiIiGU7haccpPCIiIiIdcQSKiIiI5DiFpxUTKCIiIpJjAqUVp/CIiIiIdMQRKCIiIpJR/O/Qp311xgSKiIiI5DiFpxUTKCIiIpLhNgbacQ0UERERkY44AkVERERynMLTigkUERERFa2aJ0H64BQeERERkY44AkVEREQyXESuHUegiIiISE4og0MHzs7OUCgUsiM4OBgA0LFjR9m5jz76SNJHYmIi/P39UbNmTdjZ2WHSpEnIz88v7W9AK45AERERUYX7/fffUVBQIL6+cOECunbtigEDBohlH3zwAWbNmiW+rlmzpvhzQUEB/P39oVarERMTg6SkJLz//vuoUaMG5s6dW+bxMoEiIiIimRc9hWdrayt5PW/ePDRo0AAdOnQQy2rWrAm1Wl1k+/379+PSpUs4cOAA7O3t4eXlhdmzZyMkJAShoaFQKpU634M2nMIjIiIiuTKawsvIyJAcOTk5z710bm4u/vOf/2D48OFQKP79UpiIiAjY2NjAw8MDU6ZMwaNHj8RzsbGx8PT0hL29vVjm5+eHjIwMXLx4sfS/h2JwBIqIiIjKjaOjo+T1zJkzERoaqrXNjh07kJaWhsDAQLFsyJAhcHJygoODA86dO4eQkBDEx8fj559/BgAkJydLkicA4uvk5GT9b+QZTKCIiIhIpqym8G7fvg2VSiWWGxsbP7ftmjVr0L17dzg4OIhlH374ofizp6cn6tSpg86dOyMhIQENGjQofaClxCk8IiIikiujKTyVSiU5npdA3bp1CwcOHMCIESO01mvTpg0A4Nq1awAAtVqNlJQUSZ3C18Wtm9IHEygiIiKSe8HbGBRat24d7Ozs4O/vr7VeXFwcAKBOnToAAG9vb5w/fx737t0T60RFRUGlUsHd3b10wWjBKTwiIiKqFDQaDdatW4eAgAAYGf2boiQkJGDz5s3o0aMHateujXPnzmHcuHFo3749mjVrBgDw9fWFu7s73nvvPSxYsADJycmYNm0agoODSzRtqCsmUERERCRTETuRHzhwAImJiRg+fLikXKlU4sCBA/jqq6+QlZUFR0dH9OvXD9OmTRPrGBoaYteuXRg1ahS8vb1hZmaGgIAAyb5RZYkJFBEREcnpMQ0ntteRr68vBEHe0NHREUeOHHlueycnJ+zZs0f3C5cC10ARERER6YgjUERERCSjEAQoihgN0qV9dcYEioiIiOQqYAqvKuEUHhEREZGOOAJFREREMhXxFF5VwgSKiIiI5DiFpxWn8IiIiIh0xBEoIiIikuEUnnZMoIiIiEiOU3haMYEiIiIiGY5Aacc1UEREREQ64ggUERERyXEKTysmUERERFSk6j4Npw9O4RERERHpiCNQREREJCcITw592ldjTKCIiIhIhk/haccpPCIiIiIdcQSKiIiI5PgUnlZMoIiIiEhGoXly6NO+OuMUHhEREZGOOAJFVAZMzQrw/thEePumwqp2HhIumeHb2S7487z5/2oIeO/T2+j2zj2YqfJx6bQKK2a44O4t0wqNm6gk3hmdAp8e6XB0zUFutgEunaqJNXPq4K8EE0m9Jq2yEBiSjMYtH6GgALh+0RRTh9RHbjb/rV4lcQpPK76rn+PmzZtQKBSIi4sr07pPy83NhaurK2JiYkrc5tKlS6hbty6ysrJ0uhaVj0/nJqDFG+n4cmJDjPJvjjPHrTB34yXUts8BAAz48C7eDkjG8hn1MbafJ7IfG+CLdZdRQ1nNx7ipWmjmnYWd620wtmdDTBlUH4ZGAub+cB3GpgVinSatsjAn4jpOHzXHmB4NMaZHQ/zfOhsIfItXWYVP4elzVGcvdQIVGBgIhUIBhUKBGjVqwMXFBZMnT0Z2drZYx9HREUlJSfDw8Ci3OFatWgUXFxe0bdtWLJszZw7atm2LmjVrwsrKStbG3d0dr7/+OhYvXlxucVHJKI0L8IbfP1gz3wkXflch6ZYpIpY54u4tE/gPSQEgoHdgEiK/rosTB6xxM94MX050RW37XLTtmlrR4RM91+dD6yNqqzVu/WmC65dMsWhsPdjXzUPDZo/FOiND72LHGhtsXWGPW3+a4K8EExzdaYW83Jf6Y6ZqK9wHSp+jGnvp39ndunVDUlISrl+/jiVLluDbb7/FzJkzxfOGhoZQq9UwMiqf2U5BELBixQoEBQVJynNzczFgwACMGjWq2LbDhg3DypUrkZ+fXy6xUckYGj058nKk/zvlZhugaeuHUDvmwNouD2djLMVzjzKNEP+HORq3ePiiwyXSm5nqycjTwzRDAIBl7Tw0afUIaf8YYcn/XUXkHxex8KdraPpaZkWGSVSuXvoEytjYGGq1Go6Ojujduze6dOmCqKgo8fyz03IPHjzA0KFDYWtrC1NTUzRs2BDr1q0rsu+CggIMHz4cjRs3RmJiYpF1Tp8+jYSEBPj7+0vKw8LCMG7cOHh6ehYbe9euXZGamoojR44UWycnJwcZGRmSg8rW4yxDXDpjjsGj/4K1XS4MDAR06nUfjVs8hLVtLmrZ5AEAHvxdQ9Luwd9K1LLNq4iQiUpNoRDwUdgdXPhvTdyKf7KGr45TLgDgvfEp2BtRG58PdcG186aYt+U6HFxyKjJc0gOn8LR76ROop124cAExMTFQKpXF1pk+fTouXbqEvXv34vLly1i5ciVsbGxk9XJycjBgwADExcXh2LFjqFevXpH9HTt2DI0aNYKFhYXO8SqVSnh5eeHYsWPF1gkPD4elpaV4ODo66nwder4vJzaEQiEgIuY0/u/SCfR6PwlHdtlAo1FUdGhEZWr03DtwapyN8FFOYpnB/z5J9vynNvZvsUbChZr4NvQV/JVgDL9BnKausoQyOKqxl/4pvF27dsHc3Bz5+fnIycmBgYEBVqxYUWz9xMREtGjRAq1btwYAODs7y+pkZmbC398fOTk5OHToECwtLWV1Ct26dQsODg6ljt/BwQG3bt0q9vyUKVMwfvx48XVGRgaTqHKQlGiCyUM8YGxagJrmBXhwX4nPlv6J5NvG4shTLZs8PLj/b3JeyyYXCZfMKipkIp0Fz/kLbbpmYEKfBvg76d/38j8pTz5Kbv0pfSrv9jVj2L2S+0JjJHpRXvoRqE6dOiEuLg4nT55EQEAAhg0bhn79+hVbf9SoUYiMjISXlxcmT55c5JNzgwcPRlZWFvbv3681eQKAx48fw8TERGsdbUxNTfHo0aNizxsbG0OlUkkOKj85jw3x4L4S5qp8tGqXhhMHrJF82xip92rAq226WK+meT7cmmfiylndRx6JXjwBwXP+Qttu6Zg8oAFSbhtLzqbcVuLvJCPUbZAtKX+lfg7u/VX8iD5VbpzC0+6lT6DMzMzg6uqK5s2bY+3atTh58iTWrFlTbP3u3bvj1q1bGDduHO7evYvOnTtj4sSJkjo9evTAuXPnEBsb+9zr29jY4MGDB6WOPzU1Fba2tqVuT2WjZbs0tGr/APZ1s9HCJw3z/nMRf103xf6fbAEosGN9HQz6+C+06ZwK50ZZmLDwGv5JUSImyrqiQyd6rtFz7+DNvg8wL9gJjzMNUMs2D7Vs86A0KdyjQIEfV9qhd9DfeMM/DQ7OOXh/UhIcG+Rg3w98j1dZfApPq5d+Cu9pBgYGmDp1KsaPH48hQ4bA1LToTQ5tbW0REBCAgIAAtGvXDpMmTcKXX34pnh81ahQ8PDzw9ttvY/fu3ejQoUOx12zRogVWrlwJQRCgUOi+XubChQvo37+/zu2obJlZ5GPYxETYqHPxMM0Ix3+1xoZF9VCQ/+TfKNtWO8DEtABjvrgOc1U+Lp5SYfrwJnzEm6qEtwL/AQB8+XOCpPzLsY6I2vokQdr+vS1qmGjwUdhdWFgV4PolE0wZXB9Jt4xl/RFVB0ygnjFgwABMmjQJX3/9tWxkCQBmzJiBVq1aoWnTpsjJycGuXbvQpEkTWb1PPvkEBQUF6NmzJ/bu3Ys33nijyOt16tQJmZmZuHjxomSvqcTERKSmpiIxMREFBQXiU4Curq4wN3+yu/XNmzdx584ddOnSpQzunPRxbI8Nju2RP0zwLwU2La2HTUuLfpiAqDLzc2heonpbV9hj6wr7co6GXhR9p+E4hfeSMTIywujRo7FgwYIid/lWKpWYMmUKmjVrhvbt28PQ0BCRkZFF9jV27FiEhYWhR48exe4yXrt2bfTp0wcRERGS8hkzZqBFixaYOXMmMjMz0aJFC7Ro0QKnTp0S6/zwww/w9fWFk5PTs90SERHph0/haaUQhGo+SVkFnDt3Dl27dkVCQoI4uvQ8ubm5aNiwITZv3gwfH58SXysjIwOWlpZ4s+YgGCm4uJOqJ42WByuIqrJ8IQ+H8QvS09PL7aGgws8J726zYFSj9A855edlI3bfjBLHGhoairCwMEmZm5sbrly5AgDIzs7GhAkTEBkZiZycHPj5+eGbb76Bvf2/o56JiYkYNWoUDh06BHNzcwQEBCA8PLxcNsPmCFQl0KxZM8yfPx83btwocZvExERMnTpVp+SJiIiopCriKbymTZsiKSlJPI4fPy6eGzduHHbu3Ilt27bhyJEjuHv3Lvr27SueLygogL+/P3JzcxETE4MNGzZg/fr1mDFjRln8OmS4BqqSCAwM1Km+q6srXF1dyycYIiIijfDk0Ke9joyMjKBWq2Xl6enpWLNmDTZv3ow333wTALBu3To0adIEJ06cwOuvv479+/fj0qVLOHDgAOzt7eHl5YXZs2cjJCQEoaGhWjfJLg2OQBEREZFcGa2BevbrxHJyiv96n6tXr8LBwQH169fH0KFDxa9BO336NPLy8iQPTTVu3Bj16tUTtwyKjY2Fp6enZErPz88PGRkZuHjxYhn8QqSYQBEREVG5cXR0lHylWHh4eJH12rRpg/Xr12Pfvn1YuXIlbty4gXbt2uHhw4dITk6GUqmElZWVpI29vT2Sk5MBAMnJyZLkqfB84bmyxik8IiIiklFAz20M/vff27dvSxaRGxsXvTdY9+7dxZ+bNWuGNm3awMnJCVu3bi12X8aKxBEoIiIikiujncif/Tqx4hKoZ1lZWaFRo0a4du0a1Go1cnNzkZaWJqmTkpIirplSq9VISUmRnS88V9aYQBEREVGlk5mZiYSEBNSpUwetWrVCjRo1cPDgQfF8fHw8EhMT4e3tDQDw9vbG+fPnce/ePbFOVFQUVCoV3N3dyzw+TuERERGRzIveiXzixIl466234OTkhLt372LmzJkwNDTE4MGDYWlpiaCgIIwfPx7W1tZQqVT45JNP4O3tjddffx0A4OvrC3d3d7z33ntYsGABkpOTMW3aNAQHB5d41EsXTKCIiIhITt/dxHVs+9dff2Hw4MH4559/YGtrizfeeAMnTpyAra0tAGDJkiUwMDBAv379JBtpFjI0NMSuXbswatQoeHt7w8zMDAEBAZg1a5YeN1E87kT+kuFO5PQy4E7kVF29yJ3I3+gUCiMjPXYiz8/G8UOh5RprReIIFBEREckoBAEKPcZY9GlbFTCBIiIiIjnN/w592ldjfAqPiIiISEccgSIiIiIZTuFpxwSKiIiI5F7wU3hVDRMoIiIikntqN/FSt6/GuAaKiIiISEccgSIiIiKZF70TeVXDBIqIiIjkOIWnFafwiIiIiHTEESgiIiKSUWieHPq0r86YQBEREZEcp/C04hQeERERkY44AkVERERy3EhTKyZQREREJMOvctGOU3hEREREOuIIFBEREclxEblWTKCIiIhITgCgz1YE1Tt/YgJFREREclwDpR3XQBERERHpiCNQREREJCdAzzVQZRZJpcQEioiIiOS4iFwrTuERERER6YgjUERERCSnAaDQs301xgSKiIiIZPgUnnacwiMiIiLSEUegiIiISI6LyLViAkVERERyTKC04hQeERERkY44AkVERERyHIHSigkUERERyXEbA62YQBEREZEMtzHQjmugiIiIqMKFh4fj1VdfhYWFBezs7NC7d2/Ex8dL6nTs2BEKhUJyfPTRR5I6iYmJ8Pf3R82aNWFnZ4dJkyYhPz+/zOPlCBQRERHJveA1UEeOHEFwcDBeffVV5OfnY+rUqfD19cWlS5dgZmYm1vvggw8wa9Ys8XXNmjXFnwsKCuDv7w+1Wo2YmBgkJSXh/fffR40aNTB37tzS30sRmEARERGRnEYAFHokUBrd2u7bt0/yev369bCzs8Pp06fRvn17sbxmzZpQq9VF9rF//35cunQJBw4cgL29Pby8vDB79myEhIQgNDQUSqVS9/soBqfwiIiIqNxkZGRIjpycnBK1S09PBwBYW1tLyiMiImBjYwMPDw9MmTIFjx49Es/FxsbC09MT9vb2Ypmfnx8yMjJw8eLFMribf3EEioiIiOTKaArP0dFRUjxz5kyEhoZqbarRaDB27Fj4+PjAw8NDLB8yZAicnJzg4OCAc+fOISQkBPHx8fj5558BAMnJyZLkCYD4Ojk5ufT3UgQmUERERFQEPRMoPGl7+/ZtqFQqsdTY2Pi5LYODg3HhwgUcP35cUv7hhx+KP3t6eqJOnTro3LkzEhIS0KBBAz1i1R2n8IiIiKjcqFQqyfG8BGr06NHYtWsXDh06hLp162qt26ZNGwDAtWvXAABqtRopKSmSOoWvi1s3VVpMoIiIiEiucApPn0OnywkYPXo0tm/fjujoaLi4uDy3TVxcHACgTp06AABvb2+cP38e9+7dE+tERUVBpVLB3d1dp3ieh1N4REREJKcRUDgNV/r2JRccHIzNmzfjl19+gYWFhbhmydLSEqampkhISMDmzZvRo0cP1K5dG+fOncO4cePQvn17NGvWDADg6+sLd3d3vPfee1iwYAGSk5Mxbdo0BAcHl2jqUBccgSIiIqIKt3LlSqSnp6Njx46oU6eOeGzZsgUAoFQqceDAAfj6+qJx48aYMGEC+vXrh507d4p9GBoaYteuXTA0NIS3tzfeffddvP/++5J9o8oKR6CIiIhITtA8OfRpr0v150z5OTo64siRI8/tx8nJCXv27NHp2qXBBIqIiIjkXvBO5FUNEygiIiKSe8FroKoaroEiIiIi0hFHoIiIiEiOU3haMYEiIiIiOQF6JlBlFkmlxCk8IiIiIh1xBIqIiIjkOIWnFRMoIiIiktNoAOixD5RGj7ZVAKfwiIiIiHTEESgiIiKS4xSeVkygiIiISI4JlFacwiMiIiLSEUegiIiISI5f5aIVEygiIiKSEQQNBKH0T9Lp07YqYAJFREREcoKg3ygS10ARERER0dM4AkVERERygp5roKr5CBQTKCIiIpLTaACFHuuYqvkaKE7hEREREemII1BEREQkxyk8rZhAERERkYyg0UDQYwqvum9jwCk8IiIiIh1xBIqIiIjkOIWnFRMoIiIiktMIgIIJVHE4hUdERESkI45AERERkZwgANBnH6jqPQLFBIqIiIhkBI0AQY8pPIEJFBEREb10BA30G4HiNgZERERE9BSOQBEREZEMp/C0YwJFREREcpzC04oJ1Eum8F8E+UJeBUdCVH40fH9TNZWPJ+/tFzG6k488vfbRLIy1umIC9ZJ5+PAhAODo458qOBIiIiqthw8fwtLSslz6ViqVUKvVOJ68R+++1Go1lEplGURV+SiE6j5JSRIajQZ3796FhYUFFApFRYdT7WVkZMDR0RG3b9+GSqWq6HCIyhzf4y+WIAh4+PAhHBwcYGBQfs+BZWdnIzc3V+9+lEolTExMyiCiyocjUC8ZAwMD1K1bt6LDeOmoVCp+uFC1xvf4i1NeI09PMzExqbaJT1nhNgZEREREOmICRURERKQjJlBE5cjY2BgzZ86EsbFxRYdCVC74HqeXFReRExEREemII1BEREREOmICRURERKQjJlBEREREOmICRVTOAgMD0bt37zKv+7Q1a9bA19dXpzavv/46fvqJO9K/7G7evAmFQoG4uLgyrfu03NxcuLq6IiYmpsRtLl26hLp16yIrK0unaxG9KEygqMoKDAyEQqHAvHnzJOU7dux4IbusF36YFB7W1tbo0KEDjh07Jqm3dOlSrF+/vtziyM7OxvTp0zFz5kxJ+bZt29C4cWOYmJjA09MTe/ZIv5Zh2rRp+Oyzz6DRVO8v/HyZFf4/olAoUKNGDbi4uGDy5MnIzs4W6zg6OiIpKQkeHh7lFseqVavg4uKCtm3bimVz5sxB27ZtUbNmTVhZWcnauLu74/XXX8fixYvLLS4ifTCBoirNxMQE8+fPx4MHDyoshgMHDiApKQlHjx6Fg4MDevbsiZSUFPG8paVlkR8QZeXHH3+ESqWCj4+PWBYTE4PBgwcjKCgIZ8+eRe/evdG7d29cuHBBrNO9e3c8fPgQe/fuLbfYqOJ169YNSUlJuH79OpYsWYJvv/1WkmwbGhpCrVbDyKh8vphCEASsWLECQUFBkvLc3FwMGDAAo0aNKrbtsGHDsHLlSuTn55dLbET6YAJFVVqXLl2gVqsRHh6utd5PP/2Epk2bwtjYGM7Ozli0aJHkvLOzM+bOnYvhw4fDwsIC9erVw+rVq0sUQ+3ataFWq+Hh4YGpU6ciIyMDJ0+eFM8/Oy33448/wtPTE6ampqhduza6dOlS7DTF77//DltbW8yfP7/Y60dGRuKtt96SlC1duhTdunXDpEmT0KRJE8yePRstW7bEihUrxDqGhobo0aMHIiMjS3SfVDUZGxtDrVbD0dERvXv3RpcuXRAVFSWef3Za7sGDBxg6dChsbW1hamqKhg0bYt26dUX2XVBQgOHDh6Nx48ZITEwsss7p06eRkJAAf39/SXlYWBjGjRsHT0/PYmPv2rUrUlNTceTIER3vmqj8MYGiKs3Q0BBz587F8uXL8ddffxVZ5/Tp0xg4cCAGDRqE8+fPIzQ0FNOnT5dNqy1atAitW7fG2bNn8fHHH2PUqFGIj48vcSyPHz/Gxo0bAaDYbx9PSkrC4MGDMXz4cFy+fBmHDx9G3759UdR2bNHR0ejatSvmzJmDkJCQYq97/PhxtG7dWlIWGxuLLl26SMr8/PwQGxsrKXvttddkU45UfV24cAExMTHFvj8BYPr06bh06RL27t2Ly5cvY+XKlbCxsZHVy8nJwYABAxAXF4djx46hXr16RfZ37NgxNGrUCBYWFjrHq1Qq4eXlxfcoVUr8MmGq8vr06QMvLy/MnDkTa9askZ1fvHgxOnfujOnTpwMAGjVqhEuXLmHhwoUIDAwU6/Xo0QMff/wxACAkJARLlizBoUOH4ObmpvX6bdu2hYGBAR49egRBENCqVSt07ty5yLpJSUnIz89H37594eTkBABF/gt8+/bteP/99/H999/jnXfeKfbaaWlpSE9Ph4ODg6Q8OTkZ9vb2kjJ7e3skJydLyhwcHHD79m1oNJpy/WZ3qji7du2Cubk58vPzkZOTAwMDA8lI5LMSExPRokULMSl3dnaW1cnMzIS/vz9ycnJw6NAhrV9ue+vWLdn7UxcODg64detWqdsTlRf+jUnVwvz587FhwwZcvnxZdu7y5cuS9UEA4OPjg6tXr6KgoEAsa9asmfizQqGAWq3GvXv3ADxZL2Rubg5zc3M0bdpU0teWLVtw9uxZ/PTTT3B1dcX69etRo0aNIuNs3rw5OnfuDE9PTwwYMADfffedbP3WyZMnMWDAAGzatElr8gQ8GfUCUOpvTTc1NYVGo0FOTk6p2lPl16lTJ8TFxeHkyZMICAjAsGHD0K9fv2Lrjxo1CpGRkfDy8sLkyZOLfHJu8ODByMrKwv79+7UmT8CT92hp35/Ak/foo0ePSt2eqLwwgaJqoX379vDz88OUKVNK3cezSY9CoRCfUPv+++8RFxeHuLg42dNsjo6OaNiwIfr06YO5c+eiT58+xSYkhoaGiIqKwt69e+Hu7o7ly5fDzc0NN27cEOs0aNAAjRs3xtq1a5GXl6c15tq1a0OhUMiSMLVaLVnIDgApKSlQq9WSstTUVJiZmcHU1FTrdajqMjMzg6urK5o3b461a9fi5MmTRY7UFurevTtu3bqFcePG4e7du+jcuTMmTpwoqdOjRw+cO3dONiVcFBsbG70e8khNTYWtrW2p2xOVFyZQVG3MmzcPO3fulP2l3qRJE/z222+Sst9++w2NGjWCoaFhifp+5ZVX4OrqCldXV3HqrSj9+/eHkZERvvnmm2LrKBQK+Pj4ICwsDGfPnoVSqcT27dvF8zY2NoiOjsa1a9cwcOBArUmUUqmEu7s7Ll26JCn39vbGwYMHJWVRUVHw9vaWlF24cAEtWrQotn+qXgwMDDB16lRMmzZNHL0siq2tLQICAvCf//wHX331leyBilGjRmHevHl4++23n7vAu0WLFrhy5UqR6/xKgu9RqqyYQFG14enpiaFDh2LZsmWS8gkTJuDgwYOYPXs2/vzzT2zYsAErVqyQ/au6LCgUCowZMwbz5s0rctrh5MmTmDt3Lk6dOoXExET8/PPPuH//Ppo0aSKpZ2dnh+joaFy5cgWDBw/W+hi3n58fjh8/Lin79NNPsW/fPixatAhXrlxBaGgoTp06hdGjR0vqHTt2TOcNOKlqGzBgAAwNDfH1118XeX7GjBn45ZdfcO3aNVy8eBG7du2SvT8B4JNPPsEXX3yBnj17yt5/T+vUqRMyMzNx8eJFSXliYiLi4uKQmJiIgoICcYQ3MzNTrHPz5k3cuXNH9kAEUWXABIqqlVmzZsk2hmzZsiW2bt2KyMhIeHh4YMaMGZg1a5ZkAXlZCggIQF5eXpELdVUqFY4ePYoePXqgUaNGmDZtGhYtWoTu3bvL6qrVakRHR+P8+fMYOnSoZL3W04KCgrBnzx6kp6eLZW3btsXmzZuxevVqNG/eHD/++CN27Ngh2Szxzp07iImJwbBhw8rgrqmqMDIywujRo7FgwYIit89QKpWYMmUKmjVrhvbt28PQ0LDYrS7Gjh2LsLAw9OjRo9hdxmvXro0+ffogIiJCUj5jxgy0aNECM2fORGZmJlq0aIEWLVrg1KlTYp0ffvgBvr6+Wkd9iSqKQijtuCoRVRoDBgxAy5YtdVoDFhISggcPHpR4vyui0jp37hy6du2KhIQEmJubl6hNbm4uGjZsiM2bN8seAiGqDDgCRVQNLFy4sMQfTIXs7Owwe/bscoqI6F/NmjXD/PnzJQ9LPE9iYiKmTp3K5IkqLY5AEREREemII1BEREREOmICRURERKQjJlBEREREOmICRURERKQjJlBEREREOmICRUQvXGBgIHr37i2+7tixI8aOHfvC4zh8+DAUCgXS0tKKraNQKLBjx44S9xkaGgovLy+94rp58yYUCgXi4uL06oeIyg8TKCIC8CSpUSgUUCgUUCqVcHV1xaxZs7R+jUxZ+fnnn0u8J1VJkh4iovJmVNEBEFHl0a1bN6xbtw45OTnYs2cPgoODUaNGjSJ3OM/NzYVSqSyT61pbW5dJP0RELwpHoIhIZGxsDLVaDScnJ4waNQpdunTB//3f/wH4d9ptzpw5cHBwgJubGwDg9u3bGDhwIKysrGBtbY1evXrh5s2bYp8FBQUYP348rKysULt2bUyePBnP7t/77BReTk4OQkJC4OjoCGNjY7i6umLNmjW4efMmOnXqBACoVasWFAqF+J2GGo0G4eHhcHFxgampqfgdgE/bs2cPGjVqBFNTU3Tq1EkSZ0mFhISgUaNGqFmzJurXr4/p06cjLy9PVu/bb7+Fo6MjatasiYEDB0q+qxAAvv/+ezRp0gQmJiZo3LgxvvnmG51jIaKKwwSKiIplamqK3Nxc8fXBgwcRHx+PqKgo7Nq1C3l5efDz84OFhQWOHTuG3377Debm5ujWrZvYbtGiRVi/fj3Wrl2L48ePIzU1Fdu3b9d63ffffx8//PADli1bhsuXL+Pbb7+Fubk5HB0d8dNPPwEA4uPjkZSUhKVLlwIAwsPDsXHjRqxatQoXL17EuHHj8O677+LIkSMAniR6ffv2xVtvvYW4uDiMGDECn332mc6/EwsLC6xfvx6XLl3C0qVL8d1332HJkiWSOteuXcPWrVuxc+dO7Nu3D2fPnsXHH38sno+IiMCMGTMwZ84cXL58GXPnzsX06dOxYcMGneMhogoiEBEJghAQECD06tVLEARB0Gg0QlRUlGBsbCxMnDhRPG9vby/k5OSIbTZt2iS4ubkJGo1GLMvJyRFMTU2FX3/9VRAEQahTp46wYMEC8XxeXp5Qt25d8VqCIAgdOnQQPv30U0EQBCE+Pl4AIERFRRUZ56FDhwQAwoMHD8Sy7OxsoWbNmkJMTIykblBQkDB48GBBEARhypQpgru7u+R8SEiIrK9nARC2b99e7PmFCxcKrVq1El/PnDlTMDQ0FP766y+xbO/evYKBgYGQlJQkCIIgNGjQQNi8ebOkn9mzZwve3t6CIAjCjRs3BADC2bNni70uEVUsroEiItGuXbtgbm6OvLw8aDQaDBkyBKGhoeJ5T09PybqnP/74A9euXYOFhYWkn+zsbCQkJCA9PR1JSUlo06aNeM7IyAitW7eWTeMViouLg6GhITp06FDiuK9du4ZHjx6ha9eukvLc3Fy0aNECAHD58mVJHADg7e1d4msU2rJlC5YtW4aEhARkZmYiPz8fKpVKUqdevXp45ZVXJNfRaDSIj4+HhYUFEhISEBQUhA8++ECsk5+fD0tLS53jIaKKwQSKiESdOnXCypUroVQq4eDgACMj6V8RZmZmkteZmZlo1aoVIiIiZH3Z2tqWKgZTU1Od22RmZgIAdu/eLUlcgCfruspKbGwshg4dirCwMPj5+cHS0hKRkZFYtGiRzrF+9913soTO0NCwzGIlovLFBIqIRGZmZnB1dS1x/ZYtW2LLli2ws7OTjcIUqlOnDk6ePIn27dsDeDLScvr0abRs2bLI+p6entBoNDhy5Ai6dOkiO184AlZQUCCWubu7w9jYGImJicWOXDVp0kRcEF/oxIkTz7/Jp8TExMDJyQmff/65WHbr1i1ZvcTERNy9excODg7idQwMDODm5gZ7e3s4ODjg+vXrGDp0qE7XJ6LKg4vIiajUhg4dChsbG/Tq1QvHjh3DjRs3cPjwYYwZMwZ//fUXAODTTz/FvHnzsGPHDly5cgUff/yx1j2cnJ2dERAQgOHDh2PHjh1in1u3bgUAODk5QaFQYNeuXbh//z4yMzNhYWGBiRMnYty4cdiwYQMSEhJw5swZLF++XFyY/dFHH+Hq1auYNGkS4uPjsXnzZqxfv16n+23YsCESExMRGRmJhIQELFu2rMgF8SYmJggICMAff/yBY8eOYcyYMRg4cCDUajUAICwsDOHh4Vi2bBn+/PNPnD9/HuvWrcPixYt1ioeIKg4TKCIqtZo1a+Lo0aOoV68e+vbtiyZNmiAoKAjZ2dniiNSECRPw3nvvISAgAN7e3rCwsECfPn209rty5Ur0798fH3/8MRo3bowPPvgAWVlZAIBXXnkFYWFh+Oyzz2Bvb4/Ro0cDAGbPno3p06cjPDwcTZo0Qbdu3bB79264uLgAeLIu6aeffsKOHTvQvHlzrFq1CnPnztXpft9++22MGzcOo0ePhpeXF2JiYjB9+nRZPVdXV/Tt2xc9evSAr68vmjVrJtmmYMSIEfj++++xbt06eHp6okOHDli/fr0YKxFVfgqhuJWcRERERFQkjkARERER6YgJFBEREZGOmEARERER6YgJFBEREZGOmEARERER6YgJFBEREZGOmEARERER6YgJFBEREZGOmEARERER6YgJFBEREZGOmEARERER6YgJFBEREZGO/h/IKvbKu6Hv+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Normalized):\n",
      "[[0.96752669 0.03247331]\n",
      " [0.77586207 0.22413793]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, test_preds)\n",
    "\n",
    "print(\"\\nConfusion Matrix (Counts):\")\n",
    "print(cm)\n",
    "\n",
    "# Plot the matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Risk (0)\", \"Risk (1)\"])\n",
    "plt.figure(figsize=(5,5))\n",
    "disp.plot(values_format='d')\n",
    "plt.title(\"Confusion Matrix  Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Normalized version\n",
    "cm_norm = confusion_matrix(all_labels, test_preds, normalize='true')\n",
    "print(\"\\nConfusion Matrix (Normalized):\")\n",
    "print(cm_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edyOj19O-8-Z",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /content/drive/MyDrive/NLP/respect-cfpb/outputs/models/finbert_full_results.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'finbert_full_finetuned',\n",
       " 'threshold': 0.448,\n",
       " 'performance': {'test': {'roc_auc': 0.777,\n",
       "   'precision_risk': 0.252,\n",
       "   'recall_risk': 0.224,\n",
       "   'f1_risk': 0.237,\n",
       "   'accuracy': 0.929,\n",
       "   'support_risk': 116}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Build results dictionary\n",
    "finbert_results = {\n",
    "    \"model_name\": \"finbert_full_finetuned\",\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"performance\": {\n",
    "        \"test\": {\n",
    "            \"roc_auc\": float(np.round(roc_auc_score(all_labels, all_probs), 3)),\n",
    "            \"precision_risk\": float(np.round(classification_report(all_labels, preds_test, output_dict=True)['1']['precision'], 3)),\n",
    "            \"recall_risk\": float(np.round(classification_report(all_labels, preds_test, output_dict=True)['1']['recall'], 3)),\n",
    "            \"f1_risk\": float(np.round(classification_report(all_labels, preds_test, output_dict=True)['1']['f1-score'], 3)),\n",
    "            \"accuracy\": float(np.round(classification_report(all_labels, preds_test, output_dict=True)['accuracy'], 3)),\n",
    "            \"support_risk\": int(classification_report(all_labels, preds_test, output_dict=True)['1']['support']),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "output_path = \"/content/drive/MyDrive/NLP/respect-cfpb/outputs/models/finbert_full_results.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(finbert_results, f, indent=4)\n",
    "\n",
    "print(\"Saved:\", output_path)\n",
    "finbert_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IgV0nfKEEYTG",
   "metadata": {
    "id": "IgV0nfKEEYTG"
   },
   "source": [
    "# Model Analysis\n",
    "\n",
    "### Threshold sweep on test set\n",
    "The sweep generates:\n",
    "* F1-score for class 1\n",
    "* Precision and recall at each threshold\n",
    "* PR-AUC and ROC-AUC on the test set\n",
    "* A clear understanding of how sensitive the model is to threshold shifts\n",
    "\n",
    "At the test-set best F1 threshold (0.25):\n",
    "* F1 = 0.275\n",
    "* Recall = 0.379\n",
    "* Precision = 0.216\n",
    "* ROC-AUC = 0.777\n",
    "* PR-AUC = 0.184\n",
    "\n",
    "These numbers confirm the model is learning a real signal despite the challenging imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "qhM540HgDSAL",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean prob(class=1) on test: 0.0673\n",
      "Min prob(class=1): 0.0054\n",
      "Max prob(class=1): 0.7468\n",
      "t\tF1_1\tP_1\tR_1\n",
      "0.050\t0.224\t0.137\t0.612\n",
      "0.100\t0.260\t0.171\t0.543\n",
      "0.150\t0.260\t0.182\t0.457\n",
      "0.200\t0.261\t0.194\t0.397\n",
      "0.250\t0.275\t0.216\t0.379\n",
      "0.300\t0.270\t0.225\t0.336\n",
      "0.350\t0.267\t0.240\t0.302\n",
      "0.400\t0.261\t0.254\t0.267\n",
      "0.450\t0.244\t0.268\t0.224\n",
      "0.500\t0.211\t0.270\t0.172\n",
      "0.550\t0.185\t0.281\t0.138\n",
      "0.600\t0.143\t0.289\t0.095\n",
      "0.650\t0.058\t0.190\t0.034\n",
      "0.700\t0.033\t0.286\t0.017\n",
      "0.750\t0.000\t0.000\t0.000\n",
      "0.800\t0.000\t0.000\t0.000\n",
      "0.850\t0.000\t0.000\t0.000\n",
      "0.900\t0.000\t0.000\t0.000\n",
      "\n",
      "Best threshold on test: 0.25 Best F1_1: 0.275\n",
      "Test ROC-AUC: 0.777\n",
      "Test PR-AUC: 0.184\n",
      "\n",
      "Classification report at best threshold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.967     0.929     0.947      2248\n",
      "           1      0.216     0.379     0.275       116\n",
      "\n",
      "    accuracy                          0.902      2364\n",
      "   macro avg      0.591     0.654     0.611      2364\n",
      "weighted avg      0.930     0.902     0.914      2364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc as sk_auc,\n",
    ")\n",
    "\n",
    "# Get raw model outputs on the test set\n",
    "test_preds = trainer.predict(test_dataset)\n",
    "logits = torch.tensor(test_preds.predictions)\n",
    "probs_test = torch.softmax(logits, dim=1)[:, 1].numpy()  # P(risk_flag = 1)\n",
    "y_test = np.array(test_preds.label_ids)\n",
    "\n",
    "print(f\"Mean prob(class=1) on test: {probs_test.mean():.4f}\")\n",
    "print(f\"Min prob(class=1): {probs_test.min():.4f}\")\n",
    "print(f\"Max prob(class=1): {probs_test.max():.4f}\")\n",
    "\n",
    "# Define thresholds to evaluate\n",
    "thresholds = np.linspace(0.05, 0.9, 18)  # 0.05, 0.10, ..., 0.90\n",
    "\n",
    "results = []\n",
    "best_f1_1 = -1\n",
    "best_t = None\n",
    "\n",
    "print(\"t\\tF1_1\\tP_1\\tR_1\")\n",
    "for t in thresholds:\n",
    "    preds = (probs_test >= t).astype(int)\n",
    "\n",
    "    p1 = precision_score(y_test, preds, pos_label=1, zero_division=0)\n",
    "    r1 = recall_score(y_test, preds, pos_label=1, zero_division=0)\n",
    "    f1_1 = f1_score(y_test, preds, pos_label=1, zero_division=0)\n",
    "\n",
    "    results.append((t, f1_1, p1, r1))\n",
    "    print(f\"{t:.3f}\\t{f1_1:.3f}\\t{p1:.3f}\\t{r1:.3f}\")\n",
    "\n",
    "    if f1_1 > best_f1_1:\n",
    "        best_f1_1 = f1_1\n",
    "        best_t = t\n",
    "\n",
    "# Global metrics\n",
    "roc_auc = roc_auc_score(y_test, probs_test)\n",
    "prec_curve, rec_curve, _ = precision_recall_curve(y_test, probs_test)\n",
    "pr_auc = sk_auc(rec_curve, prec_curve)\n",
    "\n",
    "print(\"\\nBest threshold on test:\", best_t, \"Best F1_1:\", best_f1_1)\n",
    "print(\"Test ROC-AUC:\", round(roc_auc, 3))\n",
    "print(\"Test PR-AUC:\", round(pr_auc, 3))\n",
    "\n",
    "# Detailed report at best threshold\n",
    "best_preds = (probs_test >= best_t).astype(int)\n",
    "print(\"\\nClassification report at best threshold:\")\n",
    "print(classification_report(y_test, best_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3CuUTGrTFKxN",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77, 14), (90, 14))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuned threshold from validation set sweep\n",
    "best_threshold = 0.448\n",
    "\n",
    "# Get predicted probabilities using the model\n",
    "test_model.eval()\n",
    "test_texts = test_df[\"clean_text\"].tolist()\n",
    "\n",
    "probs_test = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_texts), 32):\n",
    "        batch = test_texts[i:i+32] #batch 32 at a time\n",
    "        # tokenize batch\n",
    "        enc = tokenizer(batch, truncation=True, padding=True, max_length=256, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        # compute logits and apply softmax\n",
    "        logits = test_model(**enc).logits\n",
    "        p = torch.softmax(logits, dim=1)[:, 1]\n",
    "        probs_test.extend(p.cpu().numpy())\n",
    "\n",
    "probs_test = np.array(probs_test)\n",
    "#convert probabilities to predicted class\n",
    "preds_test = (probs_test >= best_threshold).astype(int)\n",
    "\n",
    "# attach probabilities and predictions to the df\n",
    "test_df[\"prob\"] = probs_test\n",
    "test_df[\"pred\"] = preds_test\n",
    "\n",
    "# True label\n",
    "y_true = test_df[\"risk_flag\"]\n",
    "\n",
    "# Identify FS and FN\n",
    "false_positives = test_df[(test_df[\"pred\"] == 1) & (y_true == 0)]\n",
    "false_negatives = test_df[(test_df[\"pred\"] == 0) & (y_true == 1)]\n",
    "\n",
    "false_positives.shape, false_negatives.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KQJHsJgMzN9q",
   "metadata": {
    "id": "KQJHsJgMzN9q"
   },
   "source": [
    "### Analysis of Top False Positives (FPs)\n",
    "\n",
    "A review of the highest-probability false positives shows a clear pattern:  \n",
    "these complaints **look legitimately serious**, even though they are labeled as non-risk.\n",
    "\n",
    "The model is not failing randomly. It is responding to strong textual signals that indicate real compliance risk.\n",
    "\n",
    "-  Many FP complaints involve repeated servicing failures, incorrect fees, lost paperwork, foreclosure threats, or major financial harm.  \n",
    "  These patterns closely resemble true risk cases.\n",
    "\n",
    "- Terms like *misconduct*, *negligence*, *violation*, *illegal*, *compensation*, and repeated references to *CFPB* or *FHA guidelines* strongly push the model toward a risk prediction.\n",
    "\n",
    "- Some cases involve genuine hardship, but the institutions response was technically correct under policy, creating text that sounds risky even when labeled non-risk.\n",
    "\n",
    "The model has learned a *broader textual signature of risk* than the strict SME definition used in labeling.  \n",
    "High-probability FPs often contain real distress signals, which explains why the model elevates them even when the ground truth label is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "jBDWY-cyxoo6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top FP: \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"fp_top[[\\\"clean_text\\\", \\\"prob\\\"]]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"i am writing to file a second formal complaint against the u s bank assumption department and the u s bank underwriting department due to their persistent negligence and misconduct in handling our assumable mortgage application despite our previous complaints the issues have not been resolved and our application process has been closed prematurely for a third time in our previous complaint we specifically requested that u s bank not close our application prior to obtaining all necessary information from us unfortunately they have closed our application yet again causing significant distress and inconvenience we are now in our third attempt to secure an assumable mortgage with u s bank and the process has been exceedingly difficult due to the bank s negligence and failure to adhere to fha guidelines they have told us the previous two times that it is just a timing issue and it is out of our hands there needs to be accountability and there needs to be compensation we have been nothing but diligent and punctual every step of the way they have refunded us the cost of the credit checks which is appreciated they have also refunded us the application fee each time that we apply to the next application this does not make up for the pain and suffering this process has caused my family and i the second time they denied us of this application they sent us an email saying my income was not sustainable and we can t continue with the process i have a base salary which has never changed except for raises with additional overtime income that is consistent for the past years they didn t try to ask questions or seek any information from me which was just a misunderstanding on their part this inevitably lead to the closing of our second application the stress this has caused my wife and i has been unfathomable as a with an annual income exceeding and with both my wife and i having credit scores above there should be no reason for these repeated issues i have maintained continuous employment as a salary based employee for the past years without any breaks in income overtime or benefits we have no delinquencies on our record and yet we continue to face unwarranted obstacles in this process while we acknowledge that the bank has been slightly more helpful each time the recurring premature closures of our application are causing unnecessary delays and increased costs for my family and me as we attempt to purchase this home every month that this process is extended adds to our financial burden we humbly request the consumer financial protection bureau cfpb to intervene once more and guide us through the remainder of this process to ensure there is no further negligence or malfeasance by u s bank we are seeking your assistance to ensure our application is handled fairly and in accordance with all relevant guidelines we are also requesting that we are financially compensated for the multiple delays in this already long and arduous process the previous complaint id number is below attached is an email i received at the end of their work day stating sorry cant continue with no attempt to gather further information also attached is a photo of a wrongly addressed letter to us after they told us we cant get ahold of you and closed us out for the first time thank you for your attention to this matter we appreciate your support in resolving this issue sincerely\",\n          \"my husband passed away on he had a first loan and a second loan on the house the second us bank i have been having difficulty with communication us bank said they needed in to bring it current i sent us bank a cashiers check via overnight mail weeks went by and i received nothing by mail i contacted them and they said i should receive something in the mail i wait in i called and inquired again about the sent and they could not talk to me because i was not on the loan i said well you took my to bring the loan current they said sorry you are not on the loan but we can accept the money to bring the loan current by this time they stopped sending statements in the mail in possibly the i came home to a notice of sale on my door set for i immediately called them back and they said yes i spoke with a gentleman named he said that us bank did not file a paper that stopped the foreclosure when the account was brought current in the meantime i had to contact the us bank attorney to try to get it stopped i received a letter of rescission on at that time i applied for assistance the bank responded by mail they are reviewing it and could take up to days last week i received a letter saying they have closed the application for assistance due to successor in interest has not been established this is so frustrating that they can not just let me know they need documents that i have they closed the case as of i am currently seeking an attorney or other guidance\",\n          \"subject violation of privacy act of and consumer bill of rights dear cfpb i am writing to report a violation of the privacy act of and my consumer bill of rights by u s bank national association specifically i was asked to provide my social security number ssn by representative without being informed if it was mandatory or voluntary or if any statutory or regulatory authority authorizes the collection of my ssn and the uses that will be made of it this violates cfr on i interacted with via email and he informed me that we can not proceed without my ssn however he failed to provide the necessary disclosures required by law as a result i was denied my right to be informed my right to safety and my right to service i am disappointed and frustrated with the services provided by u s bank specifically with regards to my recent application process unfortunately my experience has fallen short of my expectations due to inadequate communication lack of transparency and insufficient knowledge displayed by i kindly request the cfpb to investigate this issue and take necessary actions to ensure compliance with the privacy act of and the consumer bill of rights i request that u s bank provide clear disclosure on the requirement and usage of social security numbers for applications and offer alternative methods for verification if available i have attached my communication records with via email for your reference please contact me at to discuss this matter further i appreciate your prompt attention to this issue and look forward to a resolution sincerely\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.757488489151001,\n          0.6422116160392761,\n          0.6455258131027222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-fa7e9842-3c13-4fbd-895b-935e2da22022\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>i am writing to file a second formal complaint...</td>\n",
       "      <td>0.757488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>as a result of a that did not involve our home...</td>\n",
       "      <td>0.728943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>i received a letter from the bank telling me t...</td>\n",
       "      <td>0.709417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>i am submitting this complaint due to ongoing ...</td>\n",
       "      <td>0.708257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>i was working with a loan officer from bank of...</td>\n",
       "      <td>0.706659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>in my home was flooded due to burst pipes impa...</td>\n",
       "      <td>0.706141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>i ve my mortgage loan with the fifth third ban...</td>\n",
       "      <td>0.703671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>in may i paid a fee up front to have escrow se...</td>\n",
       "      <td>0.698233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>on i called bank of america to apply for a hom...</td>\n",
       "      <td>0.667456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>i held a mortgage with us bank for years in go...</td>\n",
       "      <td>0.667078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>subject urgent assistance required regarding m...</td>\n",
       "      <td>0.664198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>on my wife and i applied for a home equity lin...</td>\n",
       "      <td>0.657255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>the home equity line of credit loan is held wi...</td>\n",
       "      <td>0.656883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>i took out a construction loan with the bank t...</td>\n",
       "      <td>0.652212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>i have been attempting to assume my fha home l...</td>\n",
       "      <td>0.650762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>subject violation of privacy act of and consum...</td>\n",
       "      <td>0.645526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>i have had a mortgage with bank of america loa...</td>\n",
       "      <td>0.645197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>my husband passed away on he had a first loan ...</td>\n",
       "      <td>0.642212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>we are very frustrated with the way that us ba...</td>\n",
       "      <td>0.638369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>i am writing to file a formal complaint agains...</td>\n",
       "      <td>0.627585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa7e9842-3c13-4fbd-895b-935e2da22022')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-fa7e9842-3c13-4fbd-895b-935e2da22022 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-fa7e9842-3c13-4fbd-895b-935e2da22022');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-0037ee00-fa11-42d0-bec4-f6071f12a664\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0037ee00-fa11-42d0-bec4-f6071f12a664')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-0037ee00-fa11-42d0-bec4-f6071f12a664 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                             clean_text      prob\n",
       "1436  i am writing to file a second formal complaint...  0.757488\n",
       "486   as a result of a that did not involve our home...  0.728943\n",
       "2025  i received a letter from the bank telling me t...  0.709417\n",
       "1793  i am submitting this complaint due to ongoing ...  0.708257\n",
       "706   i was working with a loan officer from bank of...  0.706659\n",
       "440   in my home was flooded due to burst pipes impa...  0.706141\n",
       "1455  i ve my mortgage loan with the fifth third ban...  0.703671\n",
       "259   in may i paid a fee up front to have escrow se...  0.698233\n",
       "437   on i called bank of america to apply for a hom...  0.667456\n",
       "1875  i held a mortgage with us bank for years in go...  0.667078\n",
       "1338  subject urgent assistance required regarding m...  0.664198\n",
       "1349  on my wife and i applied for a home equity lin...  0.657255\n",
       "710   the home equity line of credit loan is held wi...  0.656883\n",
       "981   i took out a construction loan with the bank t...  0.652212\n",
       "856   i have been attempting to assume my fha home l...  0.650762\n",
       "2178  subject violation of privacy act of and consum...  0.645526\n",
       "1700  i have had a mortgage with bank of america loa...  0.645197\n",
       "1874  my husband passed away on he had a first loan ...  0.642212\n",
       "502   we are very frustrated with the way that us ba...  0.638369\n",
       "35    i am writing to file a formal complaint agains...  0.627585"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_top = false_positives.sort_values(\"prob\", ascending=False).head(10)\n",
    "print(\"Top FP: \\n\")\n",
    "fp_top[[\"clean_text\", \"prob\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x6_8NuPx1_dd",
   "metadata": {
    "id": "x6_8NuPx1_dd"
   },
   "source": [
    "### Analysis of Top False Negatives (FNs)\n",
    "\n",
    "The model appears conservative when assigning the risk label. Many FN complaints describe situations that are regulatory violations or high-impact servicing failures, but they are written in a calm, factual, or procedural tone. Because of this, the model tends to overlook them.\n",
    "\n",
    "Two key failure patterns emerge:\n",
    "\n",
    "- Many FN cases involve forced-placed insurance, escrow misapplication, missing documentation, loan assumption errors, or improper delinquency reporting.  \n",
    "These may feel like administrative mishaps to the consumerbut regulations often prohibit these practices, and they are legitimate high-risk servicing errors.  \n",
    "The model misses these because they lack dramatic language or explicit emotional harm.\n",
    "\n",
    "- When complaints are phrased calmly or without strong accusatory wording, the model underestimates risk even if the underlying facts represent violations (e.g., RESPA, FCRA, loss-mitigation rules).\n",
    "\n",
    "Overall, the model misclassifies cases where the harm is real and regulatory in nature but the narrative is mild, causing risk to be underestimated despite clear servicing failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hqAJi7nFxkZR",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top FN: \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"fn_top[[\\\"clean_text\\\", \\\"prob\\\"]]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"scrub i was contacted by phone by amerisave in regards to a loan for a home i recently purchased i was made under the impression amerisave was the mortgage company the realtor during the open house was referring to that worked directly with the company building my new home in new jersey representative phone number charged me as an application fee to sign up for a loan i didnt need they refuse to refund my money he refuses to answer my phone calls i have e mail him and he continues to give me the run around i reported them as fraud to the credit card i was billed on and they rebilled me multiple employees have tried to help me dispute their charges after they noticed online that multiple other people have also felt as though theyve been scammed by amerisave\",\n          \"on i made a payment to rocket mortgage over the phone with a live representative unbeknownst to me the representative used the wrong checking number to process the payment my husband and i only have one checking account number i called rocket mortgage on to see if the payment went through they reassured me that the payment would go through i called my bank on they said get the ach trace number from rocket mortgage i called rocket mortgage and they could not supply me with that number then rocket mortgage realized they used the wrong checking number we do not want to get a late payment because of this\",\n          \"i wanted to provide you with some feedback on rocket mortgage who is servicing my loan in short it has been a terrible experience from my first call to my current situation highlights are below in my first call to determine the loan assumption process a rocket representative told me that loan assumptions dont exist further he talked down to me even when i brought up the va website and process if the previous owner a lawyer had not intervened this assumption would not have gone through rocket incorrectly calculated my escrow and undercharged me for a year this was based on their faulty calculation of county taxes based on the previous owners payment i was held responsible for all of the fees not paid with no other recourse from rocket rocket told me different stories on the method they used for calculating escrow i fully paid the county taxes for the past year i have not had online access to my account rocket insists that i dont have access because the loan is in the previous owners name this is obviously not true this month i finally gained access only to find there is an erroneous late charge from the previous owner that can not be cleared i have strongly voiced my concerns to rocket to various contacts and have been consistently rebuffed with trite apologies or outright ghosting rocket fails to take responsibility for their failures their staff have told me that they arent familiar with loan assumptions and they are in a learning process i pointed out to them that i bear the brunt of their failures during their learning process i realize rocket is a large corporation and my loan is one of thousands however i believe that if rocket feels it is ok to treat a customer a veteran this way then they will continue to treat others this way\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.009389356710016727,\n          0.006691221613436937,\n          0.00879131630063057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6f9f6ad8-29f6-487f-9c33-eed0c89dc05e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>discover home loans wrote me several letters s...</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>on i made a payment to rocket mortgage over th...</td>\n",
       "      <td>0.006691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>it all started when i changed insurance compan...</td>\n",
       "      <td>0.007436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>i will upload a prepared letter and documentat...</td>\n",
       "      <td>0.007530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>i called pennymac with concerns about my upcom...</td>\n",
       "      <td>0.008591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>i wanted to provide you with some feedback on ...</td>\n",
       "      <td>0.008791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>my loan was sold from my loan originator to in...</td>\n",
       "      <td>0.009190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>dear sir madam i am writing to formally lodge ...</td>\n",
       "      <td>0.009273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>scrub i was contacted by phone by amerisave in...</td>\n",
       "      <td>0.009389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>midland mortgage is holding my loss draft mone...</td>\n",
       "      <td>0.009797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f9f6ad8-29f6-487f-9c33-eed0c89dc05e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6f9f6ad8-29f6-487f-9c33-eed0c89dc05e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6f9f6ad8-29f6-487f-9c33-eed0c89dc05e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-71f773a6-3823-49d9-aae8-9bf77a94d8c2\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71f773a6-3823-49d9-aae8-9bf77a94d8c2')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-71f773a6-3823-49d9-aae8-9bf77a94d8c2 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                             clean_text      prob\n",
       "1775  discover home loans wrote me several letters s...  0.006255\n",
       "1398  on i made a payment to rocket mortgage over th...  0.006691\n",
       "1315  it all started when i changed insurance compan...  0.007436\n",
       "1221  i will upload a prepared letter and documentat...  0.007530\n",
       "1785  i called pennymac with concerns about my upcom...  0.008591\n",
       "1952  i wanted to provide you with some feedback on ...  0.008791\n",
       "959   my loan was sold from my loan originator to in...  0.009190\n",
       "157   dear sir madam i am writing to formally lodge ...  0.009273\n",
       "1809  scrub i was contacted by phone by amerisave in...  0.009389\n",
       "2145  midland mortgage is holding my loss draft mone...  0.009797"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_top = false_negatives.sort_values(\"prob\", ascending=True).head(10)\n",
    "print(\"Top FN: \\n\")\n",
    "fn_top[[\"clean_text\", \"prob\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T3myIbx_9glf",
   "metadata": {
    "id": "T3myIbx_9glf"
   },
   "source": [
    "### Uncertainty Analysis (Distance From 0.5)\n",
    "\n",
    "The table highlights complaints with predicted probabilities closest to 0.5, meaning the model is most unsure about these cases. These typically involve long, complex, and procedural disputes. For example, miscommunication, escrow errors, document handling issues, or administrative mishaps. In such scenarios, the distinction between poor customer service and actual compliance or regulatory risk is subtle, even for human reviewers.\n",
    "\n",
    "The fact that the model expresses the highest uncertainty on these borderline cases suggests that it is appropriately calibrated:  \n",
    "- High confidence on clearly compliant or clearly risky cases  \n",
    "- Low confidence on cases where even humans would debate the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "-khzHl5-xTcD",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"hard_cases[[\\\"clean_text\\\", \\\"prob\\\", \\\"uncertainty\\\", \\\"risk_flag\\\"]]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"i have had numerous difficulties resolving delays in processing my mortgage with navy federal i received my closing disclosure on for a closing on with a cash to close amount of on i wired to the closing firm on the date of closing i received a new closing disclosure with a cash to close amount of they refused to honor a lender s closing credit for increases in closing costs above the legal limit\",\n          \"in late year i dropped a check in a blue public mailbox to pay my property taxes the check was made using my credit union checking account around the same date i scheduled a mortgage payment for for year the last date that i could make my payment without incurring a late fee a few days later i left the country for a nearly month long trip overseas and i would not return until year while i was traveling my bank s fraud department attempted to contact me to inform me that someone cashed a suspicious check against my bank account and as a consequence they would be rejecting all future payments scheduled from that account and removing online access to my account the bank rep did leave a voice message on my phone but since i was overseas and using a different phone number i did not get the message right away but once i realized that some of my online payments were being rejected by my bank i took measures to access my home phone number and was able to receive the voice message i then called my bank and learned that someone had made a fake check using all of the same information on my original property tax check even the same amount but for a different recipient and had cashed that check presumably whoever did this managed to steal the check from the public mailbox i dropped the check into the result of this was that my bank rejected a couple of credit card payments and my roundpoint mortgage payment i was unable to resolve the situation until i returned home from my trip once i did i immediately went to the bank on year where i opened a new account and signed an affidavit attesting to the fact that i did not write the check that was cashed against my account i am able to provide copies of the signed and notarized affidavit a copy of the fake check and a blank original check from the same checkbook as the check that was stolen so that one can validate that there are differences between the fake check and the original check on year after setting up my new bank account i made my missed payments but in the meantime i had incurred late fees including a late fee from roundpoint mortgage i proceeded to contact my various creditors to explain the extenuating circumstances and detail that my bank rejected these payments because of suspected and later confirmed fraudulent banking activity against my account all of those creditors have either waived those fees or are still in the adjudications process to determine if the fees will be waived except for one roundpoint mortgage when i contacted roundpoint on year they directed me to request a late fee waiver via email to and recommended that i provide a copy of the signed and notarized affidavit attesting to the check fraud when i filed the request on year i explained in detail what had occurred and included a copy of the affidavit in that request on year i received a response from roundpoint denying my request to have the late fee waived the only explanation provided was fees will only be waived in the event of a roundpoint error on either year or year i called roundpoint again to complain that they had denied my request and informed that if they were unwilling to remove the fee i would be filing complaints with the cfpb and the better business bureau they informed me that they would take a second look at my complaint and get back to me on year i still had not received a response so i sent another email to explaining that was still awaiting a response to my second request to have the fee waived finally on year i received an email response once again denying my request to have the fee waived stating the following please note that your request for a late fee waiver has been denied as we have confirmed that the late fee was applied accurately as a result i am now going to cfpb in the hopes that you are able to help get this fee waived and also to help spread the word that roundpoint mortgage is unsympathetic to customer s that are victims of financial fraud i went through a big ordeal as a result of the fraud committed against me but my other creditors have all been understanding of the circumstances and have agreed to waive any resultant late fees only roundpoint has been more concerned with collecting their fee than in doing the right thing to help ensure that customers are not victimized by fraud please feel free to contact me if you would like more details\",\n          \"i am writing to express my deep dissatisfaction regarding the handling of my tax refund for the tax abatement on my property despite providing ample evidence of payment and eligibility i have yet to receive any resolution or acknowledgment from your company on year i contacted your office to address the issue of the outstanding tax refund owed to me i provided documentation confirming the payment made from the escrow account as well as proof of eligibility for the tax abatement however to my dismay there has been no progress or communication since then repeated attempts to follow up on the matter have been met with silence and my concerns seem to have been disregarded this lack of responsiveness and accountability is unacceptable especially considering the significant financial impact this refund has on my finances i urge you to take immediate action to rectify this situation i expect a thorough investigation into the status of my refund and a clear explanation for the delay furthermore i demand a concrete timeline for when i can expect to receive the refund owed to me i trust that you will treat this matter with the seriousness and urgency it deserves i look forward to a swift resolution and the timely receipt of my tax refund\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.49450695514678955,\n          0.4987698793411255,\n          0.49507689476013184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"uncertainty\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.005493044853210449,\n          0.0012301206588745117,\n          0.004923105239868164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-13c4f988-0b59-44e3-b192-6476f05afb2d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>prob</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>my wife and i took out a residential construct...</td>\n",
       "      <td>0.499903</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>in late year i dropped a check in a blue publi...</td>\n",
       "      <td>0.498770</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>i am writing to file a formal complaint agains...</td>\n",
       "      <td>0.498740</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>i did not originally initiate my mortgage with...</td>\n",
       "      <td>0.497497</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>in my realtor contacted me to share that i was...</td>\n",
       "      <td>0.497160</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>i am writing to express my deep dissatisfactio...</td>\n",
       "      <td>0.495077</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>due to the loss of a job of fifteen years we i...</td>\n",
       "      <td>0.494931</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>in filed a complaint with the cfpb regarding c...</td>\n",
       "      <td>0.505389</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>i have had numerous difficulties resolving del...</td>\n",
       "      <td>0.494507</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>i am compelled to extend my initial complaint ...</td>\n",
       "      <td>0.506450</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13c4f988-0b59-44e3-b192-6476f05afb2d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-13c4f988-0b59-44e3-b192-6476f05afb2d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-13c4f988-0b59-44e3-b192-6476f05afb2d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-02820624-0fbf-4113-a67d-9c003331251b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02820624-0fbf-4113-a67d-9c003331251b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-02820624-0fbf-4113-a67d-9c003331251b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                             clean_text      prob  \\\n",
       "1735  my wife and i took out a residential construct...  0.499903   \n",
       "182   in late year i dropped a check in a blue publi...  0.498770   \n",
       "20    i am writing to file a formal complaint agains...  0.498740   \n",
       "460   i did not originally initiate my mortgage with...  0.497497   \n",
       "2230  in my realtor contacted me to share that i was...  0.497160   \n",
       "822   i am writing to express my deep dissatisfactio...  0.495077   \n",
       "593   due to the loss of a job of fifteen years we i...  0.494931   \n",
       "1086  in filed a complaint with the cfpb regarding c...  0.505389   \n",
       "1309  i have had numerous difficulties resolving del...  0.494507   \n",
       "677   i am compelled to extend my initial complaint ...  0.506450   \n",
       "\n",
       "      uncertainty  risk_flag  \n",
       "1735     0.000097          0  \n",
       "182      0.001230          0  \n",
       "20       0.001260          0  \n",
       "460      0.002503          1  \n",
       "2230     0.002840          0  \n",
       "822      0.004923          0  \n",
       "593      0.005069          1  \n",
       "1086     0.005389          0  \n",
       "1309     0.005493          1  \n",
       "677      0.006450          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df[\"uncertainty\"] = np.abs(test_df[\"prob\"] - 0.5)\n",
    "hard_cases = test_df.sort_values(\"uncertainty\").head(10)\n",
    "hard_cases[[\"clean_text\", \"prob\", \"uncertainty\", \"risk_flag\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d91144",
   "metadata": {
    "id": "40d91144"
   },
   "source": [
    "# Validation and Comparison of Baseline and Improved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e97649c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison (Test Set)\n",
      "\n",
      "            Metric  Baseline (TF-IDF + LogReg)  FinBERT Full Fine-tune\n",
      "          Accuracy                       0.788                   0.929\n",
      "Precision (risk=1)                       0.129                   0.252\n",
      "   Recall (risk=1)                       0.578                   0.224\n",
      "       F1 (risk=1)                       0.211                   0.237\n",
      "           ROC-AUC                       0.785                   0.777\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Load saved results\n",
    "with open(\"/content/drive/MyDrive/NLP/respect-cfpb/outputs/models/baseline_tfidf_logreg_results.json\") as f:\n",
    "    baseline = json.load(f)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/NLP/respect-cfpb/outputs/models/finbert_full_results.json\") as f:\n",
    "    finbert_full = json.load(f)\n",
    "\n",
    "# Extract metrics\n",
    "baseline_metrics = baseline[\"performance\"][\"test\"]\n",
    "finbert_metrics = finbert_full[\"performance\"][\"test\"]\n",
    "\n",
    "# Build comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision (risk=1)\", \"Recall (risk=1)\", \"F1 (risk=1)\", \"ROC-AUC\"],\n",
    "    \"Baseline (TF-IDF + LogReg)\": [\n",
    "        baseline_metrics[\"accuracy\"],\n",
    "        baseline_metrics[\"precision_risk\"],\n",
    "        baseline_metrics[\"recall_risk\"],\n",
    "        baseline_metrics[\"f1_risk\"],\n",
    "        baseline_metrics[\"roc_auc\"]\n",
    "    ],\n",
    "    \"FinBERT Full Fine-tune\": [\n",
    "        finbert_metrics[\"accuracy\"],\n",
    "        finbert_metrics[\"precision_risk\"],\n",
    "        finbert_metrics[\"recall_risk\"],\n",
    "        finbert_metrics[\"f1_risk\"],\n",
    "        finbert_metrics[\"roc_auc\"]\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display results\n",
    "print(\"Model Performance Comparison (Test Set)\\n\")\n",
    "print(comparison_df.to_string(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zLvapEy8bxZS",
   "metadata": {
    "id": "zLvapEy8bxZS"
   },
   "source": [
    "**Overall improvement**  \n",
    "- FinBERT dramatically improves overall accuracy*(0.929  +14%) and precision for risk cases (0.252  +12.3 pp).  \n",
    "- This means it produces fewer false alarms and is far better at identifying truly clean complaints.\n",
    "\n",
    "**Trade-off: recall dropped (0.578  0.224)**  \n",
    "- The baseline catches more of the risky cases, but at the cost of very high false positives.\n",
    "- FinBERT is more conservative and avoids over-flagging.\n",
    "\n",
    "**F1 improved slightly**  \n",
    "- FinBERT: 0.237  \n",
    "- Baseline: 0.211  \n",
    "- This indicates the precision gain outweighs the recall loss.\n",
    "\n",
    "**ROC-AUC nearly identical**  \n",
    "- Suggests both models separate the classes similarly in terms of raw score distributions.\n",
    "- The performance differences come from how sharply they draw the classification boundary, not their ranking ability.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- The FinBERT model is far more reliable for operational use because it avoids noisy false positives.\n",
    "- The baseline model results in lots of recall but extremely poor precision.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
